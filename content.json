{"meta":{"title":"冰梨","subtitle":null,"description":null,"author":"rim-wood","url":"https://www.icepear.cn"},"pages":[{"title":"个人简介","date":"2020-03-20T07:25:13.031Z","updated":"2020-03-20T07:25:13.031Z","comments":true,"path":"about/index.html","permalink":"https://www.icepear.cn/about/index.html","excerpt":"","text":"&emsp;吴黎明，Rim·Wood，95后，软件工程专业，本科毕业于湖南长沙大学，16年毕业从事儿童机器人行业，现在医疗健康领域从事java开发&emsp;熟悉面向对象的设计原则，熟悉设计模式；熟悉集合框架、多线程、NIO、等java技术。熟悉springboot、mybatis、dubbo等，springcloud有一定了解。&emsp;数据库掌握mysql、oracle以及常用的缓存redis。消息队列熟悉kafka、rabbitmq。熟悉容器技术docker，compose;熟悉git，jenkins，junit等常规devops技术&emsp;平时喜欢户外、摄影、阅读、吉他、自驾游。&emsp;喜欢折腾，对未知事物充满好奇心。"},{"title":"分类","date":"2017-10-09T03:04:58.294Z","updated":"2017-10-09T03:04:58.294Z","comments":true,"path":"categories/index.html","permalink":"https://www.icepear.cn/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2017-10-09T03:04:58.295Z","updated":"2017-10-09T03:04:58.295Z","comments":true,"path":"tags/index.html","permalink":"https://www.icepear.cn/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"spring cloud gateway 2.2.2 中文文档","slug":"springcloud/springcloudgateway","date":"2020-05-14T13:30:02.000Z","updated":"2020-05-14T10:42:43.474Z","comments":true,"path":"2020/05/14/springcloud/springcloudgateway/","link":"","permalink":"https://www.icepear.cn/2020/05/14/springcloud/springcloudgateway/","excerpt":"本文档基于官网()[https://cloud.spring.io/spring-cloud-static/spring-cloud-gateway/2.2.2.RELEASE/reference/html/] 2.2.2.RELEASE版本进行翻译，中间按照自己的理解并不是全文照搬。","text":"本文档基于官网()[https://cloud.spring.io/spring-cloud-static/spring-cloud-gateway/2.2.2.RELEASE/reference/html/] 2.2.2.RELEASE版本进行翻译，中间按照自己的理解并不是全文照搬。 1. 怎样引入 Spring Cloud Gateway要在项目中引入Spring Cloud Gateway，需要引用 group org.springframework.cloud 和 artifact id为spring-cloud-starter-gateway starter。最新的Spring Cloud Release 构建信息，请参阅(Spring Cloud Project page)[https://spring.io/projects/spring-cloud]。 如果应用了该starter，但由于某种原因不希望启用网关，请进行设置spring.cloud.gateway.enabled=false。 1234警告：Spring Cloud Gateway基于Spring Boot 2.x，Spring WebFlux和Project Reactor构建。当您使用Spring Cloud Gateway时，许多您熟悉的同步库（例如，Spring Data和Spring Security）和模式可能不适用。如果您对这些项目不熟悉，建议您在使用Spring Cloud Gateway之前先阅读它们的文档以熟悉一些新概念。 12警告：Spring Cloud Gateway依赖Spring Boot和Spring Webflux提供的Netty runtime。它不能在传统的Servlet容器中工作或构建为WAR 2. 核心关键字 Route 路由：gateway的基本构建模块。它由ID、目标URI、断言集合和过滤器集合组成。如果聚合断言结果为真，则匹配到该路由。 Predicate 断言：这是一个Java 8 Function Predicate。输入类型是 Spring Framework ServerWebExchange。这允许开发人员可以匹配来自HTTP请求的任何内容，例如Header或参数。 Filter 过滤器：这些是使用特定工厂构建的 Spring FrameworkGatewayFilter实例。所以可以在返回请求之前或之后修改请求和响应的内容。 3. 工作原理下图从总体上概述了Spring Cloud Gateway的工作方式： !()[https://cloud.spring.io/spring-cloud-static/spring-cloud-gateway/2.2.2.RELEASE/reference/html/images/spring_cloud_gateway_diagram.png] 客户端向Spring Cloud Gateway发出请求。 如果网关处理程序映射确定请求与路由匹配，则将其发送到网关Web处理程序。 该处理程序通过特定于请求的过滤器链来运行请求。 筛选器由虚线分隔的原因是，筛选器可以在发送代理请求之前和之后运行逻辑。 所有“前置”过滤器逻辑均被执行。 然后发出代理请求。 发出代理请求后，将运行“后”过滤器逻辑。 在没有端口的路由中定义的URI，HTTP和HTTPS URI的默认端口值分别为80和443。 4. 配置路由断言工厂和过滤器工厂的方式有两种配置断言和过滤器的方法,下面的大多数示例都使用快捷方式。名称和参数名称将在每个部分的第一个或两个句子中以代码形式列出。参数通常按快捷方式配置所需的顺序列出。 4.1 快捷方式快捷方式配置由过滤器名称识别，后跟一个等号（=），然后是由逗号分隔的参数值（，）例如 12345678spring: cloud: gateway: routes: - id: after_route uri: https://example.org predicates: - Cookie=mycookie,mycookievalue 4.2 完全扩展的参数。完全扩展的参数看起来更像带有名称/值对的标准Yaml配置。通常，将有一个名称键和一个args键。args键是用于配置谓词或过滤器的键值对的映射1234567891011spring: cloud: gateway: routes: - id: after_route uri: https://example.org predicates: - name: Cookie args: name: mycookie regexp: mycookievalue 5. 路由断言工厂5.1. The After Route Predicate FactoryAfter Route Predicate Factory采用一个参数——日期时间。在该日期时间之后发生的请求都将被匹配。 12345678spring: cloud: gateway: routes: - id: after_route uri: https://example.org predicates: - After=2017-01-20T17:42:47.789-07:00[America/Denver] 5.2. The Before Route Predicate FactoryBefore Route Predicate Factory采用一个参数——日期时间。在该日期时间之前发生的请求都将被匹配。 12345678spring: cloud: gateway: routes: - id: before_route uri: https://example.org predicates: - Before=2017-01-20T17:42:47.789-07:00[America/Denver] 5.3. The Between Route Predicate FactoryBetween 路由断言 Factory有两个参数，datetime1和datetime2。在datetime1和datetime2之间的请求将被匹配。datetime2参数的实际时间必须在datetime1之后。 12345678spring: cloud: gateway: routes: - id: between_route uri: https://example.org predicates: - Between=2017-01-20T17:42:47.789-07:00[America/Denver], 2017-01-21T17:42:47.789-07:00[America/Denver] 5.4. The Cookie Route Predicate FactoryCookie 路由断言有两个参数，cookie名称和regexp正则表达式。请求包含次cookie名称且正则表达式为真的将会被匹配。 12345678spring: cloud: gateway: routes: - id: cookie_route uri: https://example.org predicates: - Cookie=chocolate, ch.p 5.5. The Header Route Predicate FactoryHeader 路由断言有两个参数，header名称和regexp正则表达式。请求包含次header名称且正则表达式为真的将会被匹配。 12345678spring: cloud: gateway: routes: - id: header_route uri: https://example.org predicates: - Header=X-Request-Id, \\d+ 5.6. The Host Route Predicate FactoryHost 路由断言包括一个参数：主机名模式列表patterns。使用Ant路径匹配规则，.作为分隔符 12345678spring: cloud: gateway: routes: - id: host_route uri: https://example.org predicates: - Host=**.somehost.org,**.anotherhost.org 5.7. The Method Route Predicate FactoryMethod 路由断言只包含一个参数: 需要匹配的HTTP请求方式 12345678spring: cloud: gateway: routes: - id: method_route uri: https://example.org predicates: - Method=GET,POST 5.8. The Path Route Predicate Factory路径路由断言使用两个参数：Spring PathMatcher模式列表和一个称为matchOptionalTrailingSeparator的可选标志。 12345678spring: cloud: gateway: routes: - id: path_route uri: https://example.org predicates: - Path=/red/&#123;segment&#125;,/blue/&#123;segment&#125; 如果请求路径为例如/red/1或/red/blue或/blue/green，则此路由匹配。要获取segment的值可以采用 123Map&lt;String, String&gt; uriVariables = ServerWebExchangeUtils.getPathPredicateVariables(exchange);String segment = uriVariables.get(\"segment\"); 5.9. The Query Route Predicate FactoryQuery 路由断言 Factory 有2个参数: 必选项 param 和可选项 regexp. 12345678spring: cloud: gateway: routes: - id: query_route uri: https://example.org predicates: - Query=green 如果请求包含green查询参数，则上述路由匹配。 12345678spring: cloud: gateway: routes: - id: query_route uri: https://example.org predicates: - Query=red, gree. 如果请求包含red查询参数，并且值包含gree正则规则的，则上述路由匹配。 5.10. The RemoteAddr Route Predicate FactoryRemoteAddr 路由断言的参数为 一个CIDR符号（IPv4或IPv6）字符串的列表，最小值为1，例如192.168.0.1/16（其中192.168.0.1是IP地址并且16是子网掩码）。 12345678spring: cloud: gateway: routes: - id: remoteaddr_route uri: https://example.org predicates: - RemoteAddr=192.168.1.1/24 如果请求的远程地址是例如192.168.1.10，则此路由匹配。 5.11. The Weight Route Predicate Factory权重路由断言的参数为：group 和 weight ，权重按组计算 123456789101112spring: cloud: gateway: routes: - id: weight_high uri: https://weighthigh.org predicates: - Weight=group1, 8 - id: weight_low uri: https://weightlow.org predicates: - Weight=group1, 2 这条路线会将约80％的流量转发至weighthigh.org，并将约20％的流量转发至weightlow.org。 5.11.1 修改远程地址的解析方式默认情况下，RemoteAddr 路由断言使用传入请求中的remote address。如果Spring Cloud Gateway位于代理层后面，也就是说网关前面还配置了一个Nginx之类的反向代理，则可能与实际客户端IP地址不匹配。 可以通过设置自定义RemoteAddressResolver来自定义解析远程地址的方式。Spring Cloud Gateway网关附带一个非默认远程地址解析程序，它基于X-Forwarded-For header, XForwardedRemoteAddressResolver. XForwardedRemoteAddressResolver 有两个静态构造函数方法，采用不同的安全方法： XForwardedRemoteAddressResolver:：TrustAll返回一个RemoteAddressResolver，它始终采用X-Forwarded-for头中找到的第一个IP地址。这种方法容易受到欺骗，因为恶意客户端可能会为解析程序接受的“x-forwarded-for”设置初始值。 XForwardedRemoteAddressResolver:：MaxTrustedIndex获取一个索引，会在X-Forwarded-For信息里面，从右到左选择信任最多maxTrustedIndex个ip，因为X-Forwarded-For是越往右是越接近gateway的代理机器ip，所以是越往右的ip，信任度是越高的。那么如果前面只是挡了一层Nginx的话，如果只需要Nginx前面客户端的ip，则maxTrustedIndex取1，就可以比较安全地获取真实客户端ip,如果在访问Spring Cloud Gateway之前需要两个受信任的基础代理点，那么应该使用2。 例如索引是下面这样的值： 1X-Forwarded-For: 0.0.0.1, 0.0.0.2, 0.0.0.3 那么当我们使用下面的maxTrustedIndex值将生成以下远程地址: maxTrustedIndex result [Integer.MIN_VALUE,0] (invalid, IllegalArgumentException during initialization) 1 0.0.0.3 2 0.0.0.2 3 0.0.0.1 [4, Integer.MAX_VALUE] 0.0.0.1 Java 配置方式: GatewayConfig.java 123456789101112RemoteAddressResolver resolver = XForwardedRemoteAddressResolver .maxTrustedIndex(1);....route(\"direct-route\", r -&gt; r.remoteAddr(\"10.1.1.1\", \"10.10.1.1/24\") .uri(\"https://downstream1\").route(\"proxied-route\", r -&gt; r.remoteAddr(resolver, \"10.10.1.1\", \"10.10.1.1/24\") .uri(\"https://downstream2\")) 6. 路由过滤器路由过滤器允许以某种方式修改传入的HTTP请求或传出的HTTP响应。路由过滤器适用于特定路由。Spring Cloud Gateway包括许多内置的GatewayFilter工厂。下面一一列举：详细的使用说明请参考测试代码 6.1 AddRequestHeader GatewayFilter Factory添加请求头的过滤器，有两个参数，name和value。 12345678spring: cloud: gateway: routes: - id: add_request_header_route uri: https://example.org filters: - AddRequestHeader=X-Request-red, blue 将在请求头里面加入 X-Request-red:blue 这样的参数进去，下游就可以通过新的请求头拿到对应的值。 当然也可以使用参数注入的方式，例如下面这样，将path路径上的参数，放入到header中： 12345678910spring: cloud: gateway: routes: - id: add_request_header_route uri: https://example.org predicates: - Path=/red/&#123;segment&#125; filters: - AddRequestHeader=X-Request-Red, Blue-&#123;segment&#125; 6.2. The AddRequestParameter GatewayFilter Factory添加参数的过滤器，有两个参数，name和value。 12345678spring: cloud: gateway: routes: - id: add_request_parameter_route uri: https://example.org filters: - AddRequestParameter=red, blue 这会将red = blue添加到所有匹配请求的下游请求的查询字符串中。 同样的也可以采用参数注入的方式，例如下面这样，将Host的参数，放入到查询字符串中： 12345678910spring: cloud: gateway: routes: - id: add_request_parameter_route uri: https://example.org predicates: - Host: &#123;segment&#125;.myhost.org filters: - AddRequestParameter=foo, bar-&#123;segment&#125; 6.3. The AddResponseHeader GatewayFilter Factory添加返回头过滤器，有两个参数，name和value。跟上面差不多，不写了。 6.4. The DedupeResponseHeader GatewayFilter Factory重复参数返回头删除过滤器，有两个参数 name 和 strategy ，name是返回头中的参数名称，strategy是策略，包含三种策略：RETAIN_FIRST (默认), RETAIN_LAST, RETAIN_UNIQUE. 12345678spring: cloud: gateway: routes: - id: dedupe_response_header_route uri: https://example.org filters: - DedupeResponseHeader=Access-Control-Allow-Credentials Access-Control-Allow-Origin 这个例子表示当网关CORS逻辑和下游逻辑都将它们添加时，这将删除Access-Control-Allow-Credentials和Access-Control-Allow-Origin响应标头的重复值。 6.5. The Hystrix GatewayFilter FactoryHystrix 是Netflix开源的断路器组件。Hystrix GatewayFilter允许你向网关路由引入断路器，保护你的服务不受级联故障的影响，并允许你在下游故障时提供fallback响应。 要在项目中启用Hystrix网关过滤器，需要添加对 spring-cloud-starter-netflix-hystrix的依赖 Hystrix GatewayFilter Factory 需要一个name参数，即HystrixCommand的名称。 12345678spring: cloud: gateway: routes: - id: hystrix_route uri: https://example.org filters: - Hystrix=myCommandName 这将剩余的过滤器包装在命令名为“myCommandName”的HystrixCommand中。 hystrix过滤器还可以接受可选的fallbackUri 参数。目前，仅支持forward: 预设的URI，如果调用fallback，则请求将转发到与URI匹配的控制器。 1234567891011121314spring: cloud: gateway: routes: - id: hystrix_route uri: lb://backing-service:8088 predicates: - Path=/consumingserviceendpoint filters: - name: Hystrix args: name: fallbackcmd fallbackUri: forward:/incaseoffailureusethis - RewritePath=/consumingserviceendpoint, /backingserviceendpoint 当调用hystrix fallback时，这将转发到/incaseoffailureusethis。注意，这个示例还演示了（可选）通过目标URI上的’lb`前缀,使用Spring Cloud Netflix Ribbon 客户端负载均衡。 主要场景是使用fallbackUri 到网关应用程序中的内部控制器或处理程序。但是，也可以将请求重新路由到外部应用程序中的控制器或处理程序，如： 1234567891011121314151617spring: cloud: gateway: routes: - id: ingredients uri: lb://ingredients predicates: - Path=//ingredients/** filters: - name: Hystrix args: name: fetchIngredients fallbackUri: forward:/fallback - id: ingredients-fallback uri: http://localhost:9994 predicates: - Path=/fallback 在上面例子中，gateway应用程序中没有 fallback 实现，但是另一个应用程序中有一个接口实现，注册为“http://localhost:9994”。 在将请求转发到fallback的情况下，Hystrix Gateway过滤还支持直接抛出Throwable 。它被作为ServerWebExchangeUtils.HYSTRIX_EXECUTION_EXCEPTION_ATTR属性添加到ServerWebExchange中，可以在处理网关应用程序中的fallback时使用。 对于外部控制器/处理程序方案，可以添加带有异常详细信息的header。可以在下面6.7的 FallbackHeaders GatewayFilter Factory section.中找到有关它的更多信息。 hystrix配置参数（如 timeouts）可以使用全局默认值配置，也可以使用Hystrix wiki中所述属性进行配置。 要为上面的示例路由设置5秒超时，将使用以下配置： 1hystrix.command.fallbackcmd.execution.isolation.thread.timeoutInMilliseconds: 5000 6.6. Spring Cloud CircuitBreaker GatewayFilter FactorySpring Cloud CircuitBreaker 使用Spring Cloud CircuitBreaker API将网关路由包装在断路器中。Spring Cloud CircuitBreaker支持可与Spring Cloud Gateway一起使用的两个库Hystrix和Resilience4J。由于Netflix已将Hystrix置于仅维护模式，因此建议您使用Resilience4J。 要启用Spring Cloud CircuitBreaker过滤器，您需要在类路径上放置spring-cloud-starter-circuitbreaker-reactor-resilience4j或spring-cloud-starter-netflix-hystrix。 以下示例配置了一个Spring Cloud CircuitBreaker GatewayFilter：12345678spring: cloud: gateway: routes: - id: circuitbreaker_route uri: https://example.org filters: - CircuitBreaker=myCircuitBreaker 要配置断路器，请参阅所使用的基础断路器实现的配置。 Resilience4J Documentation Hystrix Documentation Spring Cloud CircuitBreaker过滤器还可以接受可选的fallbackUri参数。当前，仅支持转发：计划的URI。如果调用了fallback，则请求将转发到与URI匹配的控制器。以下示例配置了这种fallback1234567891011121314spring: cloud: gateway: routes: - id: circuitbreaker_route uri: lb://backing-service:8088 predicates: - Path=/consumingServiceEndpoint filters: - name: CircuitBreaker args: name: myCircuitBreaker fallbackUri: forward:/inCaseOfFailureUseThis - RewritePath=/consumingServiceEndpoint, /backingServiceEndpoint 用java代码实现 12345678@Beanpublic RouteLocator routes(RouteLocatorBuilder builder) &#123; return builder.routes() .route(\"circuitbreaker_route\", r -&gt; r.path(\"/consumingServiceEndpoint\") .filters(f -&gt; f.circuitBreaker(c -&gt; c.name(\"myCircuitBreaker\").fallbackUri(\"forward:/inCaseOfFailureUseThis\")) .rewritePath(\"/consumingServiceEndpoint\", \"/backingServiceEndpoint\")).uri(\"lb://backing-service:8088\") .build();&#125; 当调用断路器回退时，此示例转发到/ inCaseofFailureUseThis URI。请注意，此示例还演示了（可选）Spring Cloud Netflix Ribbon负载平衡（由目标URI上的lb前缀定义）。 主要方案是使用fallbackUri在网关应用程序内定义内部控制器或处理程序。但是，您还可以将请求重新路由到外部应用程序中的控制器或处理程序，如下所示： 1234567891011121314151617spring: cloud: gateway: routes: - id: ingredients uri: lb://ingredients predicates: - Path=//ingredients/** filters: - name: CircuitBreaker args: name: fetchIngredients fallbackUri: forward:/fallback - id: ingredients-fallback uri: http://localhost:9994 predicates: - Path=/fallback 6.7. The FallbackHeaders GatewayFilter FactoryFallbackHeaders允许在转发到外部应用程序中的FallbackUri的请求的header中添加Hystrix异常详细信息，如下所示： 123456789101112131415161718192021spring: cloud: gateway: routes: - id: ingredients uri: lb://ingredients predicates: - Path=//ingredients/** filters: - name: CircuitBreaker args: name: fetchIngredients fallbackUri: forward:/fallback - id: ingredients-fallback uri: http://localhost:9994 predicates: - Path=/fallback filters: - name: FallbackHeaders args: executionExceptionTypeHeaderName: Test-Header 在本例中，在运行HystrixCommand发生执行异常后，请求将被转发到 localhost:9994应用程序中的 fallback终端或程序。异常类型、消息（如果可用）cause exception类型和消息的头，将由FallbackHeaders filter添加到该请求中。 通过设置下面列出的参数值及其默认值，可以在配置中覆盖headers的名称： executionExceptionTypeHeaderName (“Execution-Exception-Type”) executionExceptionMessageHeaderName (“Execution-Exception-Message”) rootCauseExceptionTypeHeaderName (“Root-Cause-Exception-Type”) rootCauseExceptionMessageHeaderName (“Root-Cause-Exception-Message”) Hystrix 如何实现的更多细节可以参考 Hystrix GatewayFilter Factory section或者Spring Cloud CircuitBreaker Factory section.. 6.8. The MapRequestHeader GatewayFilter FactoryMapRequestHeader过滤器有fromHeader和toHeader两个参数。它创建一个新的命名头（toHeader），然后从传入的HTTP请求中将其值从现有的命名头（fromHeader）中提取出来。如果输入标头不存在，则过滤器不起作用。如果新的命名报头已经存在，则其值将使用新值进行扩充。 12345678spring: cloud: gateway: routes: - id: map_request_header_route uri: https://example.org filters: - MapRequestHeader=Blue, X-Request-Red 这会将X-Request-Red：标头添加到下游请求中，这个值就是来自传入HTTP请求的Blue标头的值。 6.9. The PrefixPath GatewayFilter FactoryPrefixPath GatewayFilter 只有一个 prefix 参数.12345678spring: cloud: gateway: routes: - id: prefixpath_route uri: https://example.org filters: - PrefixPath=/mypath 这会将/mypath作为所有匹配请求的路径的前缀。因此，对/hello的请求将发送到/mypath/hello。 6.10. The PreserveHostHeader GatewayFilter Factory该filter没有参数。设置了该Filter后，当客户端通过Gateway访问服务时，服务中获取到Host头。如果经过此过滤器，则服务端获取到的是客户端请求网关的Host；如果未经过此过滤器，则服务端获取到的是网关请求服务端的Host。 12345678spring: cloud: gateway: routes: - id: preserve_host_route uri: https://example.org filters: - PreserveHostHeader 6.11. The RequestRateLimiter GatewayFilter FactoryRequestRateLimiter使用RateLimiter实现是否允许继续执行当前请求。如果不允许继续执行，则返回HTTP 429 - Too Many Requests （默认情况下）。 这个过滤器可以配置一个可选的keyResolver 参数和rate limiter参数（见下文）。 keyResolver 是 KeyResolver 接口的实现类.在配置中，按名称使用SpEL引用bean。#{@myKeyResolver} 是引用名为’myKeyResolver’的bean的SpEL表达式。以下代码显示了KeyResolver接口 123public interface KeyResolver &#123; Mono&lt;String&gt; resolve(ServerWebExchange exchange);&#125; KeyResolver接口允许使用可插拔策略来派生限制请求的key。在未来的里程碑版本中，将有一些KeyResolver实现。 KeyResolver的默认实现是PrincipalNameKeyResolver，它从ServerWebExchange检索Principal并调用Principal.getName()。 默认情况下，如果KeyResolver 没有获取到key，请求将被拒绝。此行为可以使用 spring.cloud.gateway.filter.request-rate-limiter.deny-empty-key (true or false) 和 spring.cloud.gateway.filter.request-rate-limiter.empty-key-status-code属性进行调整。 该过滤器不能使用快捷表示法，例如1spring.cloud.gateway.routes[0].filters[0]=RequestRateLimiter=2, 2, #&#123;@userkeyresolver&#125; 6.11.1 Redis RateLimiterredis实现基于Stripe完成的工作。 它需要使用spring-boot-starter-data-redis-active。 算法使用的是令牌桶算法Token Bucket Algorithm. redis-rate-limiter.replenishRate是您希望允许用户每秒执行多少请求，而不会丢弃任何请求。 这是令牌桶填充的速率。 redis-rate-limiter.burstCapacity是用户在一秒钟内允许执行的最大请求数。 这是令牌桶可以容纳的令牌数。 将此值设置为零将阻止所有请求。 redis-rate-limiter.requestedTokens属性是一个请求要花费多少个令牌。这是每个请求从存储桶中获取的令牌数，默认为1。 通过在replenishRate和burstCapacity中设置相同的值来实现稳定的速率。通过将burstCapacity设置为高于replenishRate，可以允许临时突发流量。在这种情况下，需要在两次突发之间允许速率限制器留出一段时间（根据replenishRate），因为连续2次突发将导致请求被丢弃（HTTP 429 - Too Many Requests）。 通过将replenishRate设置为所需的请求数，将requestTokens设置为以秒为单位的时间跨度并将burstCapacity设置为replenishRate和requestedToken的乘积，例如1，可以达到以下1个请求的速率限制。设置replenishRate = 1，requestedTokens = 60和burstCapacity = 60将导致限制为每分钟1个请求。 123456789101112spring: cloud: gateway: routes: - id: requestratelimiter_route uri: https://example.org filters: - name: RequestRateLimiter args: redis-rate-limiter.replenishRate: 10 redis-rate-limiter.burstCapacity: 20 redis-rate-limiter.requestedTokens: 1 以下示例在Java中配置KeyResolver： 1234@BeanKeyResolver userKeyResolver() &#123; return exchange -&gt; Mono.just(exchange.getRequest().getQueryParams().getFirst(\"user\"));&#125; 这定义了每个用户10的请求速率限制。允许突发20，但是在下一秒中，只有10个请求可用。这个userKeyResolver是获取user请求参数的简单方法（请注意，不建议在生产环境中使用此参数）。 您还可以将速率限制器定义为实现RateLimiter接口的Bean。在配置中，可以使用SpEL按名称引用Bean。＃{@ myRateLimiter}是一个SpEL表达式，它引用名为myRateLimiter的bean。 以下清单定义了一个速率限制器，该限制器使用前面清单中定义的KeyResolver： 1234567891011spring: cloud: gateway: routes: - id: requestratelimiter_route uri: https://example.org filters: - name: RequestRateLimiter args: rate-limiter: \"#&#123;@myRateLimiter&#125;\" key-resolver: \"#&#123;@userKeyResolver&#125;\" 6.12. The RedirectTo GatewayFilter FactoryRedirectTo GatewayFilter Factory 包含status 参数和url参数。 状态参数必须是300系列的重定向http状态码，例如301。地址必须有效，这是Location标头的值。对于相对重定向，您应该使用uri：no：// op作为路由定义的uri。下面的清单配置一个RedirectTo12345678spring: cloud: gateway: routes: - id: prefixpath_route uri: https://example.org filters: - RedirectTo=302, https://acme.org 这将发送带有Location：https：//acme.org标头的状态302以执行重定向。 6.13. The RemoveRequestHeader GatewayFilter FactoryRemoveRequestHeader 过滤器只有一个参数 name，用来删除请求头header中的参数 12345678spring: cloud: gateway: routes: - id: removerequestheader_route uri: https://example.org filters: - RemoveRequestHeader=X-Request-Foo 这将删除X-Request-Foo标头，然后将其发送到下游。 6.14. RemoveResponseHeader GatewayFilter FactoryRemoveResponseHeader 过滤器只有一个参数 name，用来删除返回头header中的参数 12345678spring: cloud: gateway: routes: - id: removeresponseheader_route uri: https://example.org filters: - RemoveResponseHeader=X-Response-Foo 这将从响应中删除X-Response-Foo标头，然后将其返回到网关客户端。要删除任何类型的敏感标头，您应该为可能要执行此操作的所有路由配置此过滤器.另外，您可以使用s pring.cloud.gateway.default-filters 一次配置此过滤器，并将其应用于所有路由。 6.15. The RemoveRequestParameter GatewayFilter FactoryRemoveRequestParameter 过滤器有一个参数 name ，它用来删除的查询参数。 12345678spring: cloud: gateway: routes: - id: removerequestparameter_route uri: https://example.org filters: - RemoveRequestParameter=red 这将删除red参数，然后再将其发送到下游。 6.16. The RewritePath GatewayFilter FactoryRewritePath 过滤器有两个参数 regexp 正则规则 和 replacement 参数，这使用Java正则表达式来灵活地重写请求路径. 12345678910spring: cloud: gateway: routes: - id: rewritepath_route uri: https://example.org predicates: - Path=/red/** filters: - RewritePath=/red/(?&lt;segment&gt;/?.*), /$\\&#123;segment&#125; 对于/red/blue的请求路径，这会在发出下游请求之前将路径设置为/blue。请注意，由于YAML规范，应将$替换为$\\。 6.17. RewriteLocationResponseHeader GatewayFilter FactoryRewriteLocationResponseHeader 过滤器用于修改返回头中的Location，通常用于摆脱后端特定的细节。它有stripVersionMode, locationHeaderName, hostValue, protocolsRegex四个参数1234567891011121314151617181920212223242526272829303132333435spring: cloud: gateway: routes: - id: rewritelocationresponseheader_route uri: http://example.org filters: - RewriteLocationResponseHeader=AS_IN_REQUEST, Location, ,``` 对于POST api.example.com/some/object/name的请求，如果返回头中的location的值为object-service.prod.example.net/v2/some/object/id，将被重写为api.example.com/some/object/id。stripVersionMode参数具有以下可能的值：NEVER_STRIP，AS_IN_REQUEST（默认值）和ALWAYS_STRIP，用来是否剥离出/v1或者/v2这类接口版本路径- NEVER_STRIP：即使原始请求路径不包含任何版本，也不会剥离该版本。- AS_IN_REQUEST 仅当原始请求路径不包含任何版本时，才剥离该版本。- ALWAYS_STRIP 即使原始请求路径包含版本，也始终剥离版本。hostValue参数（如果提供）用于替换响应Location标头的 host:port 部分。如果未提供，则使用主机请求标头的值。protocolRegex参数必须是有效的正则表达式字符串，协议名称与之匹配。如果不匹配，则过滤器不执行任何操作。默认值为http | https | ftp | ftps## 6.18. The RewriteResponseHeader GatewayFilter FactoryRewriteResponseHeader 过滤器包含 name, regexp和 replacement 参数.。通过使用Java正则表达式灵活地重写响应头的值```yamlspring: cloud: gateway: routes: - id: rewriteresponseheader_route uri: https://example.org filters: - RewriteResponseHeader=X-Response-Red, , password=[^&amp;]+, password=*** 对于一个/42?user=ford&amp;password=omg!what&amp;flag=true的header值，在做下游请求时将被设置为/42?user=ford&amp;password=***&amp;flag=true，由于YAML规范，请使用 $\\替换 $ 6.19. The SaveSession GatewayFilter FactorySaveSession GatewayFilter Factory将调用转发到下游之前强制执行WebSession::save 操作。这在使用 Spring Session 之类时特别有用，需要确保会话状态在进行转发调用之前已保存。 12345678910spring: cloud: gateway: routes: - id: save_session uri: https://example.org predicates: - Path=/foo/** filters: - SaveSession 如果您将Spring Security与Spring Session集成在一起，并想确保安全性详细信息已转发到远程进程，那么这一点至关重要。 6.20. The SecureHeaders GatewayFilter Factory根据此博客文章中的建议，SecureHeaders GatewayFilter工厂将许多headers添加到响应中。 添加了以下标头（以其默认值显示): X-Xss-Protection:1 (mode=block) Strict-Transport-Security (max-age=631138519) X-Frame-Options (DENY) X-Content-Type-Options (nosniff) Referrer-Policy (no-referrer) Content-Security-Policy (default-src ‘self’ https:; font-src ‘self’ https: data:; img-src ‘self’ https: data:; object-src ‘none’; script-src https:; style-src ‘self’ https: ‘unsafe-inline)’ X-Download-Options (noopen) X-Permitted-Cross-Domain-Policies (none) 要更改默认值，请在spring.cloud.gateway.filter.secure-headers命名空间中设置适当的属性。可以使用以下属性： xss-protection-header strict-transport-security x-frame-options x-content-type-options referrer-policy content-security-policy x-download-options x-permitted-cross-domain-policies 要禁用默认值，请设置spring.cloud.gateway.filter.secure-headers.disable属性，并用逗号分隔值。 以下示例显示了如何执行此操作： 1spring.cloud.gateway.filter.secure-headers.disable=x-frame-options,strict-transport-security 6.21. The SetPath GatewayFilter FactorySetPath GatewayFilter 采用 template路径参数。它提供了一种通过允许路径的模板化segments来操作请求路径的简单方法。使用Spring Framework中的URI模板，允许多个匹配segments。 12345678910spring: cloud: gateway: routes: - id: setpath_route uri: https://example.org predicates: - Path=/red/&#123;segment&#125; filters: - SetPath=/&#123;segment&#125; 对于一个 /red/blue 请求，在做下游请求前，路径将被设置为/blue 6.22. The SetRequestHeader GatewayFilter FactorySetRequestHeader 有两个参数 name 和 value,用来修改请求头中参数的值 12345678spring: cloud: gateway: routes: - id: setrequestheader_route uri: https://example.org filters: - SetRequestHeader=X-Request-Red, Blue 该GatewayFilter用给定名称替换（而不是添加）所有header。因此，如果下游服务器响应 X-Request-Red:1234，则将其替换为 X-Request-Red:Blue，这是下游服务将收到的内容。 SetRequestHeader知道用于匹配路径或主机的URI变量。URI变量可以在值中使用，并在运行时扩展。以下示例配置使用变量的SetRequestHeader GatewayFilter： 12345678910spring: cloud: gateway: routes: - id: setrequestheader_route uri: https://example.org predicates: - Host: &#123;segment&#125;.myhost.org filters: - SetRequestHeader=foo, bar-&#123;segment&#125; 6.23. The SetResponseHeader GatewayFilter Factory与SetRequestHeader大同小异，只是这是修改返回头的参数的值 6.24. The SetStatus GatewayFilter FactorySetStatus GatewayFilter Factory 包括唯一的 status 参数.必须是一个可用的 Spring HttpStatus。它可以是整数值404或字符串枚举NOT_FOUND。 123456789101112spring: cloud: gateway: routes: - id: setstatusstring_route uri: https://example.org filters: - SetStatus=BAD_REQUEST - id: setstatusint_route uri: https://example.org filters: - SetStatus=401 无论哪种情况，响应的HTTP状态都设置为401。 您可以将SetStatus GatewayFilter配置为在响应的header中从代理请求返回原始HTTP状态代码。 如果使用以下属性配置header，则会将其添加到响应中： 12345spring: cloud: gateway: set-status: original-status-header-name: original-http-status 6.25. The StripPrefix GatewayFilter FactoryStripPrefix GatewayFilter Factory 包括一个parts参数。 parts参数指示在将请求发送到下游之前，要从请求中去除的路径的层数。 12345678910spring: cloud: gateway: routes: - id: nameRoot uri: https://nameservice predicates: - Path=/name/** filters: - StripPrefix=2 通过网关对/name/blue/red的请求时，对nameservice的请求看起来像 http://nameservice/red。 6.26. The Retry GatewayFilter FactoryRetry GatewayFilter Factory包括 retries, statuses, methods和 series 参数. retries: 应尝试的重试次数 statuses: 应该重试的HTTP状态代码，用org.springframework.http.HttpStatus标识 methods: 应该重试的HTTP方法，用 org.springframework.http.HttpMethod标识 series: 要重试的一系列状态码，用 org.springframework.http.HttpStatus.Series标识 exceptions：应该重试的引发异常的列表。 backoff：为重试配置的指数补偿。在firstBackoff （factor ^ n）的退避间隔之后执行重试，其中n是迭代。如果配置了maxBackoff，则将应用的最大退避限制为maxBackoff。如果basedOnPreviousValue为true，则使用prevBackoff factor计算退避量。 如果启用了以下默认值，则为“重试”筛选器配置： retries: Three times series: 5XX series methods: GET method exceptions: IOException and TimeoutException backoff: disabled 例子 12345678910111213141516171819spring: cloud: gateway: routes: - id: retry_test uri: http://localhost:8080/flakey predicates: - Host=*.retry.com filters: - name: Retry args: retries: 3 statuses: BAD_GATEWAY methods: GET,POST backoff: firstBackoff: 10ms maxBackoff: 50ms factor: 2 basedOnPreviousValue: false 当将重试过滤器与带有forward转发URL一起使用时，应仔细编写目标端点，以便在发生错误的情况下，它不会做任何可能导致响应发送到客户端并提交的操作。例如，如果目标端点是带注释的控制器，则目标控制器方法不应返回带有错误状态代码的ResponseEntity。相反，它应该引发Exception或发出错误信号（例如，通过Mono.error（ex）返回值），可以将重试过滤器配置为通过重试来处理。 当将重试过滤器与任何具有主体的HTTP方法一起使用时，主体将被缓存，并且网关将受到内存的限制。正文缓存在ServerWebExchangeUtils.CACHED_REQUEST_BODY_ATTR定义的请求属性中。对象的类型是org.springframework.core.io.buffer.DataBuffer。 6.27. The RequestSize GatewayFilter Factory当请求大小大于允许的限制时，RequestSize GatewayFilter Factory可以限制请求不到达下游服务。过滤器以RequestSize作为参数，这是定义请求的允许大小限制(以字节为单位)。 123456789101112spring: cloud: gateway: routes: - id: request_size_route uri: http://localhost:8080/upload predicates: - Path=/upload filters: - name: RequestSize args: maxSize: 5000000 当请求因大小而被拒绝时， RequestSize GatewayFilter Factory 将响应状态设置为413 Payload Too Large，并带有额外的header errorMessage 。下面是一个 errorMessage的例子。 1errorMessage : Request size is larger than permissible limit. Request size is 6.0 MB where permissible limit is 5.0 MB 如果未在路由定义中作为过滤器参数提供，则默认请求大小将设置为5 MB。 6.28. Modify a Request Body GatewayFilter Factory您可以使用ModifyRequestBody筛选器筛选器来修改请求主体，然后将其由网关向下游发送。 只能使用Java DSL来配置此过滤器 123456789101112131415161718192021222324252627@Beanpublic RouteLocator routes(RouteLocatorBuilder builder) &#123; return builder.routes() .route(\"rewrite_request_obj\", r -&gt; r.host(\"*.rewriterequestobj.org\") .filters(f -&gt; f.prefixPath(\"/httpbin\") .modifyRequestBody(String.class, Hello.class, MediaType.APPLICATION_JSON_VALUE, (exchange, s) -&gt; return Mono.just(new Hello(s.toUpperCase())))).uri(uri)) .build();&#125;static class Hello &#123; String message; public Hello() &#123; &#125; public Hello(String message) &#123; this.message = message; &#125; public String getMessage() &#123; return message; &#125; public void setMessage(String message) &#123; this.message = message; &#125;&#125; 6.29. Modify a Response Body GatewayFilter Factory您可以使用ModifyResponseBody筛选器来修改响应正文，然后将其发送回客户端。 只能使用Java DSL来配置此过滤器 123456789@Beanpublic RouteLocator routes(RouteLocatorBuilder builder) &#123; return builder.routes() .route(\"rewrite_response_upper\", r -&gt; r.host(\"*.rewriteresponseupper.org\") .filters(f -&gt; f.prefixPath(\"/httpbin\") .modifyResponseBody(String.class, String.class, (exchange, s) -&gt; Mono.just(s.toUpperCase()))).uri(uri) .build();&#125; 6.30. Default Filters要添加过滤器并将其应用于所有路由，可以使用spring.cloud.gateway.default-filters。此属性采用过滤器列表。以下例子定义了一组默认过滤器 123456spring: cloud: gateway: default-filters: - AddResponseHeader=X-Response-Default-Red, Default-Blue - PrefixPath=/httpbin 7. 全局过滤器GlobalFilter接口与GatewayFilter具有相同的签名。是有条件地应用于所有路由的特殊过滤器。 7.1. Combined Global Filter and GatewayFilter Ordering当请求进入（并与路由匹配）时，筛选Web Handler 会将GlobalFilter的所有实例和所有的GatewayFilter特定实例添加到 filter chain。filter组合的排序由org.springframework.core.Ordered接口决定，可以通过实现getOrder()方法或使用@Order注释来设置。 由于Spring Cloud Gateway将用于执行过滤器逻辑区分为“pre”和“post”阶段，具有最高优先级的过滤器将是“pre”阶段的第一个，而“后置”阶段优先级最高的是最后一个。 123456789101112131415161718@Beanpublic GlobalFilter customFilter() &#123; return new CustomGlobalFilter();&#125;public class CustomGlobalFilter implements GlobalFilter, Ordered &#123; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; log.info(\"custom global filter\"); return chain.filter(exchange); &#125; @Override public int getOrder() &#123; return -1; &#125;&#125; 7.2. Forward Routing FilterForwardRoutingFilter在交换属性ServerWebExchangeUtils.GATEWAY_REQUEST_URL_ATTR中查找URI。如果URL具有转发方案（例如forward:///localendpoint），则它将使用Spring DispatcherHandler来处理请求。请求URL的路径部分被转发URL中的路径覆盖。未经修改的原始URL会附加到ServerWebExchangeUtils.GATEWAY_ORIGINAL_REQUEST_URL_ATTR属性中的列表中。 7.3. The LoadBalancerClient FilterLoadBalancerClientFilter在名为ServerWebExchangeUtils.GATEWAY_REQUEST_URL_ATTR的交换属性中查找URI。如果URL的方案为lb（例如lb//myservice），它将使用Spring Cloud LoadBalancerClient将名称（在本例中为myservice）解析为实际的主机和端口，并替换同一属性中的URI。未经修改的原始URL会附加到ServerWebExchangeUtils.GATEWAY_ORIGINAL_REQUEST_URL_ATTR属性中的列表中。筛选器还会在ServerWebExchangeUtils.GATEWAY_SCHEME_PREFIX_ATTR属性中查找其是否等于lb。如果是，则应用相同的规则。 12345678spring: cloud: gateway: routes: - id: myRoute uri: lb://service predicates: - Path=/service/** 默认情况下，当在LoadBalancer中找不到服务实例时，将返回503。您可以通过设置spring.cloud.gateway.loadbalancer.use404 = true将网关配置为返回404。 从LoadBalancer返回的ServiceInstance的isSecure值将覆盖对网关的请求中指定的方案。例如，如果请求通过HTTPS进入网关，但ServiceInstance指示它不安全，则下游请求通过HTTP发出。相反的情况也可以适用。但是，如果在网关配置中为路由指定了GATEWAY_SCHEME_PREFIX_ATTR，则会删除前缀，并且路由URL产生的方案将覆盖ServiceInstance配置 LoadBalancerClientFilter底层使用blocking ribbon LoadBalancerClient。我们建议您改用ReactiveLoadBalancerClientFilter。您可以通过将spring.cloud.loadbalancer.ribbon.enabled的值设置为false来切换到它。 7.4. The ReactiveLoadBalancerClientFilterReactiveLoadBalancerClientFilter在名为ServerWebExchangeUtils.GATEWAY_REQUEST_URL_ATTR的交换属性中查找URI。如果URL具有lb方案（例如lb//myservice），它将使用Spring Cloud ReactorLoadBalancer将名称（在本示例中为myservice）解析为实际的主机和端口，并替换同一属性中的URI。未经修改的原始URL会附加到ServerWebExchangeUtils.GATEWAY_ORIGINAL_REQUEST_URL_ATTR属性中的列表中。筛选器还会在ServerWebExchangeUtils.GATEWAY_SCHEME_PREFIX_ATTR属性中查找其是否等于lb。如果是，则应用相同的规则。 12345678spring: cloud: gateway: routes: - id: myRoute uri: lb://service predicates: - Path=/service/** 默认情况下，当ReactorLoadBalancer无法找到服务实例时，将返回503。您可以通过设置spring.cloud.gateway.loadbalancer.use404 = true将网关配置为返回404。 从ReactiveLoadBalancerClientFilter返回的ServiceInstance的isSecure值将覆盖对网关的请求中指定的方案。例如，如果请求通过HTTPS进入网关，但ServiceInstance指示它不安全，则下游请求通过HTTP发出。相反的情况也可以适用。但是，如果在网关配置中为路由指定了GATEWAY_SCHEME_PREFIX_ATTR，则会删除前缀，并且路由URL产生的方案将覆盖ServiceInstance配置。 7.5. The Netty Routing Filter如果位于ServerWebExchangeUtils.GATEWAY_REQUEST_URL_ATTR交换属性中的URL具有http或https方案，则将运行Netty路由筛选器。它使用Netty HttpClient发出下游代理请求。响应被放入ServerWebExchangeUtils.CLIENT_RESPONSE_ATTR交换属性中，以供后面的过滤器使用。（还有一个实验性的WebClientHttpRoutingFilter，它执行相同的功能，但不需要Netty。） 7.6. The Netty Write Response Filter如果ServerWebExchangeUtils.CLIENT_RESPONSE_ATTR交换属性中存在Netty HttpClientResponse，则NettyWriteResponseFilter将运行。它在所有其他筛选器完成后运行，并将代理响应写回到网关客户端响应。（还有一个实验性的WebClientWriteResponseFilter执行相同的功能，但不需要Netty。） 7.7. The RouteToRequestUrl Filter如果ServerWebExchangeUtils.GATEWAY_ROUTE_ATTR交换属性中有一个Route对象，则RouteToRequestUrlFilter将运行。它基于请求URI创建一个新URI，但使用Route对象的URI属性进行更新。新的URI放置在ServerWebExchangeUtils.GATEWAY_REQUEST_URL_ATTR交换属性中。如果URI具有方案前缀（例如lb:ws://serviceid），则将从URI中剥离lb方案，并将其放置在ServerWebExchangeUtils.GATEWAY_SCHEME_PREFIX_ATTR中，以供稍后在过滤器链中使用。 7.8. The Websocket Routing Filter如果位于ServerWebExchangeUtils.GATEWAY_REQUEST_URL_ATTR交换属性中的URL具有ws或wss方案，则将运行websocket路由过滤器。它使用Spring WebSocket基础结构向下游转发websocket请求。您可以通过为URI加上lb前缀来平衡websocket的负载，例如lb:ws://serviceid。 如果将SockJS用作常规HTTP的fallback ，则应配置常规HTTP路由以及websocket路由。 1234567891011121314spring: cloud: gateway: routes: # SockJS route - id: websocket_sockjs_route uri: http://localhost:3001 predicates: - Path=/websocket/info/** # Normal Websocket route - id: websocket_route uri: ws://localhost:3001 predicates: - Path=/websocket/** 7.9. The Gateway Metrics Filter要启用网关指标，请添加spring-boot-starter-actuator作为项目依赖项。然后，默认情况下，只要未将spring.cloud.gateway.metrics.enabled属性设置为false，网关度量过滤器就会运行。此过滤器添加名为“gateway.requests”的计时器指标，并带有以下标记： routeId: 路由 ID. routeUri: API路由到的URI. outcome: 结果，按HttpStatus.Series分类 status: 请求的HTTP状态返回给客户端 httpStatusCode: 请求的HTTP状态码返回给客户端 httpMethod: 用于请求的HTTP方法。 这些指标可以从/actuator/metrics/gateway.requests中获取，可以很容易地与Prometheus集成以创建Grafana dashboard. 注意要将pometheus启用，需要添加 micrometer-registry-prometheus为项目依赖。 7.10. Marking An Exchange As Routed网关路由ServerWebExchange之后，它将通过向Exchange属性添加gatewayAlreadyRouted，将该exchange标记为“routed”。一旦一个请求被标记为routed，其他路由过滤器将不会再次路由该请求，将跳过该过滤器。有一些方便的方法可以用来将exchange标记为routed，或者检查exchange是否已经routed。 ServerWebExchangeUtils.isAlreadyRouted获取ServerWebExchange对象，并检查其是否已“routed”。ServerWebExchangeUtils.setAlreadyRouted接收一个ServerWebExchange对象，并将其标记为“routed”。 8. 请求头过滤器HttpHeadersFilters应用于请求，然后再向下游发送请求，例如在NettyRoutingFilter中。 8.1. Forwarded Headers FilterForwarded Headers 过滤器创建Forwarded header以发送到下游服务。它将当前请求的HOST，scheme和port添加到任何现有的Forwarded header中。 8.2. RemoveHopByHop Headers FilterRemoveHopByHop Headers 过滤器可从转发的请求中删除标头。被删除的标头的默认列表来自IETF。 默认删除的标题是： Connection Keep-Alive Proxy-Authenticate Proxy-Authorization TE Trailer Transfer-Encoding Upgrade 要更改此设置，请将spring.cloud.gateway.filter.remove-non-proxy-headers.headers属性设置为要删除的标头名称列表。 8.3. XForwarded Headers FilterXForwarded标头过滤器创建各种X-Forwarded-* headers，以发送到下游服务。它使用当前请求的Host，scheme，port 和path 来创建各种headers. 可以通过以下布尔属性（默认为true）控制单个标题的创建: spring.cloud.gateway.x-forwarded.for.enabled spring.cloud.gateway.x-forwarded.host.enabled spring.cloud.gateway.x-forwarded.port.enabled spring.cloud.gateway.x-forwarded.proto.enabled spring.cloud.gateway.x-forwarded.prefix.enabled 可以通过以下布尔属性（默认为true）控制附加标头： spring.cloud.gateway.x-forwarded.for.append spring.cloud.gateway.x-forwarded.host.append spring.cloud.gateway.x-forwarded.port.append spring.cloud.gateway.x-forwarded.proto.append spring.cloud.gateway.x-forwarded.prefix.append 9. TLS and SSL通过遵循常规的Spring服务器配置，网关可以侦听HTTPS上的请求。以下示例显示了如何执行此操作 1234567server: ssl: enabled: true key-alias: scg key-store-password: scg1234 key-store: classpath:scg-keystore.p12 key-store-type: PKCS12 您可以将网关路由路由到HTTP和HTTPS后端。如果要路由到HTTPS后端，则可以使用以下配置将网关配置为信任所有下游证书： 123456spring: cloud: gateway: httpclient: ssl: useInsecureTrustManager: true 使用不安全的信任管理器不适用于生产。对于生产部署，可以使用以下配置为网关配置一组可以信任的已知证书： 12345678spring: cloud: gateway: httpclient: ssl: trustedX509Certificates: - cert1.pem - cert2.pem 如果未为Spring Cloud Gateway提供受信任的证书，则使用默认的信任库（您可以通过设置javax.net.ssl.trustStore系统属性来覆盖它）。 9.1. TLS Handshake网关维护一个用于路由到后端的client池。当通过HTTPS通信时，客户端启动一个TLS握手，其中可能会有很多超时。这些超时可以这样配置（显示默认值）： 12345678spring: cloud: gateway: httpclient: ssl: handshake-timeout-millis: 10000 close-notify-flush-timeout-millis: 3000 close-notify-read-timeout-millis: 0 10. 配置Spring Cloud Gateway的配置由一组RouteDefinitionLocator实例驱动。 RouteDefinitionLocator.java123public interface RouteDefinitionLocator &#123; Flux&lt;RouteDefinition&gt; getRouteDefinitions();&#125; 默认情况下，PropertiesRouteDefinitionLocator通过使用Spring Boot的@ConfigurationProperties机制加载属性。 以下两个示例是等效的。1234567891011121314spring: cloud: gateway: routes: - id: setstatus_route uri: https://example.org filters: - name: SetStatus args: status: 401 - id: setstatusshortcut_route uri: https://example.org filters: - SetStatus=401 对于网关的某些用法，属性是足够的，但是某些生产用例会受益于从外部源（例如数据库）加载配置。未来的里程碑版本将基于Spring数据存储库（例如Redis，MongoDB和Cassandra）使用RouteDefinitionLocator实现。 11. 路由原数据配置您可以使用元数据为每个路由配置其他参数，如下所示： 1234567891011spring: cloud: gateway: routes: - id: route_with_metadata uri: https://example.org metadata: optionName: \"OptionValue\" compositeObject: name: \"value\" iAmNumber: 1 您可以从exchange获取所有元数据属性，如下所示： 12345Route route = exchange.getAttribute(GATEWAY_ROUTE_ATTR);// get all metadata propertiesroute.getMetadata();// get a single metadata propertyroute.getMetadata(someKey); 12. Http超时配置可以为所有路由配置Http超时（响应和连接），并为每个特定路由覆盖Http超时。 12.1. Global timeouts要配置全局http超时：connect-timeout必须以毫秒为单位指定。必须将response-timeout指定为java.time.Duration123456spring: cloud: gateway: httpclient: connect-timeout: 1000 response-timeout: 5s 12.2. Per-route timeouts要配置每个路由超时：connect-timeout必须以毫秒为单位指定。必须以毫秒为单位指定response-timeout。 通过配置每个路由的HTTP超时123456789- id: per_route_timeouts uri: https://example.org predicates: - name: Path args: pattern: /delay/&#123;timeout&#125; metadata: response-timeout: 200 connect-timeout: 200 使用java代码配置123456789101112131415import static org.springframework.cloud.gateway.support.RouteMetadataUtils.CONNECT_TIMEOUT_ATTR;import static org.springframework.cloud.gateway.support.RouteMetadataUtils.RESPONSE_TIMEOUT_ATTR; @Bean public RouteLocator customRouteLocator(RouteLocatorBuilder routeBuilder)&#123; return routeBuilder.routes() .route(\"test1\", r -&gt; &#123; return r.host(\"*.somehost.org\").and().path(\"/somepath\") .filters(f -&gt; f.addRequestHeader(\"header1\", \"header-value-1\")) .uri(\"http://someuri\") .metadata(RESPONSE_TIMEOUT_ATTR, 200) .metadata(CONNECT_TIMEOUT_ATTR, 200); &#125;) .build(); &#125; 12.3. Fluent Java Routes API为了允许在Java中进行简单配置，RouteLocatorBuilder bean包含了一个流畅的API。以下清单显示了它的工作方式： GatewaySampleApplication.java1234567891011121314151617181920212223242526// static imports from GatewayFilters and RoutePredicates@Beanpublic RouteLocator customRouteLocator(RouteLocatorBuilder builder, ThrottleGatewayFilterFactory throttle) &#123; return builder.routes() .route(r -&gt; r.host(\"**.abc.org\").and().path(\"/image/png\") .filters(f -&gt; f.addResponseHeader(\"X-TestHeader\", \"foobar\")) .uri(\"http://httpbin.org:80\") ) .route(r -&gt; r.path(\"/image/webp\") .filters(f -&gt; f.addResponseHeader(\"X-AnotherHeader\", \"baz\")) .uri(\"http://httpbin.org:80\") .metadata(\"key\", \"value\") ) .route(r -&gt; r.order(-1) .host(\"**.throttle.org\").and().path(\"/get\") .filters(f -&gt; f.filter(throttle.apply(1, 1, 10, TimeUnit.SECONDS))) .uri(\"http://httpbin.org:80\") .metadata(\"key\", \"value\") ) .build();&#125; 此样式还允许更多自定义自定义断言。由RouteDefinitionLocator Bean定义的断言使用逻辑and进行组合。通过使用流畅的Java API，可以在Predicate类上使用and（），or（）和negate（）运算符 12.4. The DiscoveryClient Route Definition Locator您可以将网关配置为基于在DiscoveryClient兼容服务注册表中注册的服务来创建路由。要启用此功能，请设置spring.cloud.gateway.discovery.locator.enabled = true并确保在类路径上启用了DiscoveryClient实现（例如Netflix Eureka，Consul或Zookeeper）。 12.4.1. Configuring Predicates and Filters For DiscoveryClient Routes默认情况下，网关为通过DiscoveryClient创建的路由定义单个断言和过滤器。 默认断言是使用/serviceId/**定义的path断言，其中serviceId是DiscoveryClient中服务的ID。 默认过滤器是使用正则表达式 /serviceId/(?.*)和替换的/${remaining}进行重写。这只是在请求被发送到下游之前从路径中截取掉 service id 。 可以通过设置spring.cloud.gateway.discovery.locator.predicates[x] and spring.cloud.gateway.discovery.locator.filters[y]来实现自定义DiscoveryClient路由使用的断言and/or过滤器。当你这样做时，如果你想要保留这个功能，你需要确保包括上面的默认断言和过滤器。下面是这样一个例子。 application.properties123456789spring.cloud.gateway.discovery.locator.predicates[0].name: Pathspring.cloud.gateway.discovery.locator.predicates[0].args[pattern]: &quot;&apos;/&apos;+serviceId+&apos;/**&apos;&quot;spring.cloud.gateway.discovery.locator.predicates[1].name: Hostspring.cloud.gateway.discovery.locator.predicates[1].args[pattern]: &quot;&apos;**.foo.com&apos;&quot;spring.cloud.gateway.discovery.locator.filters[0].name: Hystrixspring.cloud.gateway.discovery.locator.filters[0].args[name]: serviceIdspring.cloud.gateway.discovery.locator.filters[1].name: RewritePathspring.cloud.gateway.discovery.locator.filters[1].args[regexp]: &quot;&apos;/&apos; + serviceId + &apos;/(?&lt;remaining&gt;.*)&apos;&quot;spring.cloud.gateway.discovery.locator.filters[1].args[replacement]: &quot;&apos;/$&#123;remaining&#125;&apos;&quot; 13. Reactor Netty 访问日志要启用Reactor Netty访问日志，请设置-Dreactor.netty.http.server.accessLogEnabled = true。 它必须是Java系统属性，而不是Spring Boot属性。 您可以将日志记录系统配置为具有单独的访问日志文件。以下示例创建一个Logback配置：logback.xml12345678910111213&lt;appender name=\"accessLog\" class=\"ch.qos.logback.core.FileAppender\"&gt; &lt;file&gt;access_log.log&lt;/file&gt; &lt;encoder&gt; &lt;pattern&gt;%msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;appender name=\"async\" class=\"ch.qos.logback.classic.AsyncAppender\"&gt; &lt;appender-ref ref=\"accessLog\" /&gt; &lt;/appender&gt; &lt;logger name=\"reactor.netty.http.server.AccessLog\" level=\"INFO\" additivity=\"false\"&gt; &lt;appender-ref ref=\"async\"/&gt; &lt;/logger&gt; 14. CORS 配置您可以配置网关以控制CORS行为。“global” CORS配置是URL模式到Spring Framework CorsConfiguration的映射。以下示例配置了CORS：application.yml123456789spring: cloud: gateway: globalcors: cors-configurations: '[/**]': allowedOrigins: \"https://docs.spring.io\" allowedMethods: - GET 在前面的示例中，对于所有GET请求的路径，允许来自docs.spring.io的请求中的CORS请求。 要为未由某些网关路由断言处理的请求提供相同的CORS配置，请将spring.cloud.gateway.globalcors.add-to-simple-url-handler-mapping属性设置为true。当您尝试支持CORS预检请求并且您的路由断言未评估为true时，这很有用，因为HTTP方法是options。 15. Actuator API(执行器API)通过/gateway执行器端点，您可以监视Spring Cloud Gateway应用程序并与之交互。为了可远程访问，必须在应用程序属性中通过HTTP或JMX启用和公开端点。以下清单显示了如何执行此操作：application.properties12management.endpoint.gateway.enabled=true # default valuemanagement.endpoints.web.exposure.include=gateway 15.1. Verbose Actuator Format这是一个新的，更详细的格式，已添加到Spring Cloud Gateway。它为每个路由添加了更多详细信息，使您可以查看与每个路由关联的断言和过滤器以及任何可用的配置。以下示例配置/actuator/gateway/routes：12345678910111213[ &#123; \"predicate\": \"(Hosts: [**.addrequestheader.org] &amp;&amp; Paths: [/headers], match trailing slash: true)\", \"route_id\": \"add_request_header_test\", \"filters\": [ \"[[AddResponseHeader X-Response-Default-Foo = 'Default-Bar'], order = 1]\", \"[[AddRequestHeader X-Request-Foo = 'Bar'], order = 1]\", \"[[PrefixPath prefix = '/httpbin'], order = 2]\" ], \"uri\": \"lb://testservice\", \"order\": 0 &#125;] 默认情况下启用此功能。要禁用它，请设置以下属性application.properties1spring.cloud.gateway.actuator.verbose.enabled=false 在将来的版本中，它将默认为true 15.2. Retrieving Route Filters本节详细介绍如何检索路由过滤器，包括： 15.2.1. Global Filters要检索应用于所有路由的全局过滤器，请向/actuator/gateway/globalfilters发出GET请求。产生的响应类似于以下内容：12345678910&#123; \"org.springframework.cloud.gateway.filter.LoadBalancerClientFilter@77856cc5\": 10100, \"org.springframework.cloud.gateway.filter.RouteToRequestUrlFilter@4f6fd101\": 10000, \"org.springframework.cloud.gateway.filter.NettyWriteResponseFilter@32d22650\": -1, \"org.springframework.cloud.gateway.filter.ForwardRoutingFilter@106459d9\": 2147483647, \"org.springframework.cloud.gateway.filter.NettyRoutingFilter@1fbd5e0\": 2147483647, \"org.springframework.cloud.gateway.filter.ForwardPathFilter@33a71d23\": 0, \"org.springframework.cloud.gateway.filter.AdaptCachedBodyGlobalFilter@135064ea\": 2147483637, \"org.springframework.cloud.gateway.filter.WebsocketRoutingFilter@23c05889\": 2147483646&#125; 该响应包含已到位的全局筛选器的详细信息。对于每个全局过滤器，过滤器对象都有一个字符串表示形式（例如org.springframework.cloud.gateway.filter.LoadBalancerClientFilter@77856cc5）以及过滤器链中的相应顺序。} 15.2.2. Route Filters要检索应用于路由的GatewayFilter工厂，请向/actuator/gateway/routefilters发出GET请求。产生的响应类似于以下内容： 12345&#123; \"[AddRequestHeaderGatewayFilterFactory@570ed9c configClass = AbstractNameValueGatewayFilterFactory.NameValueConfig]\": null, \"[SecureHeadersGatewayFilterFactory@fceab5d configClass = Object]\": null, \"[SaveSessionGatewayFilterFactory@4449b273 configClass = Object]\": null&#125; 该响应包含应用于任何特定路由的GatewayFilter工厂的详细信息。对于每个工厂，都有一个对应对象的字符串表示形式（例如[SecureHeadersGatewayFilterFactory @ fceab5d configClass = Object]）。请注意，空值是由于端点控制器的实现不完整而引起的，因为它试图设置对象在过滤器链中的顺序，该顺序不适用于GatewayFilter工厂对象。 15.3. Refreshing the Route Cache要清除路由缓存，请向/actuator/gateway/refresh发出POST请求。该请求返回200，但没有响应正文。 15.4. Retrieving the Routes Defined in the Gateway要检索网关中定义的路由，请向/actuator/gateway/routes发出GET请求。产生的响应类似于以下内容：123456789101112131415161718[&#123; \"route_id\": \"first_route\", \"route_object\": &#123; \"predicate\": \"org.springframework.cloud.gateway.handler.predicate.PathRoutePredicateFactory$$Lambda$432/1736826640@1e9d7e7d\", \"filters\": [ \"OrderedGatewayFilter&#123;delegate=org.springframework.cloud.gateway.filter.factory.PreserveHostHeaderGatewayFilterFactory$$Lambda$436/674480275@6631ef72, order=0&#125;\" ] &#125;, \"order\": 0&#125;,&#123; \"route_id\": \"second_route\", \"route_object\": &#123; \"predicate\": \"org.springframework.cloud.gateway.handler.predicate.PathRoutePredicateFactory$$Lambda$432/1736826640@cd8d298\", \"filters\": [] &#125;, \"order\": 0&#125;] 该响应包含网关中定义的所有路由的详细信息。下表描述了响应的每个元素（每个是一条路线）的结构： Path 类型 描述 route_id String 路由ID route_object.predicate Object 路由断言. route_object.filters Array 路由依赖的过滤器链 order Number 路由的优先级 15.5. Retrieving Information about a Particular Route要检索有关单个路由的信息，请向/actuator/gateway/routes/{id}（例如，/actuator/gateway/routes/first_route）发出GET请求。产生的响应类似于以下内容： 12345678910[&#123; \"id\": \"first_route\", \"predicates\": [&#123; \"name\": \"Path\", \"args\": &#123;\"_genkey_0\":\"/first\"&#125; &#125;], \"filters\": [], \"uri\": \"https://www.uri-destination.org\", \"order\": 0&#125;] 下表描述了响应的结构： Path 类型 描述 id String 路由ID predicates Array 路由断言.每个项目都定义给定断言的名称和自变量。 filters Array 路由依赖的过滤器链 uri String 路由的目标URI。 order Number 路由的优先级 15.6. Creating and Deleting a Particular Route要创建路由，请使用指定路由字段的JSON主体向/gateway/routes/{id_route_to_create}发出POST请求（请参阅检索有关特定路由的信息）。 要删除路线，请向/gateway/routes/{id_route_to_delete}发出DELETE请求。 15.7. Recap: The List of All endpoints下表总结了Spring Cloud Gateway执行器端点（请注意，每个端点都将/actuator/gateway作为基本路径）： ID HTTP Method 描述 globalfilters GET 显示应用于路由的全局过滤器列表。 routefilters GET 显示应用于特定路由的GatewayFilter工厂列表。 refresh POST 清除路由缓存。 routes GET 显示网关中定义的路由列表 routes/{id} GET 显示有关特定路线的信息 routes/{id} POST 将新路由添加到网关。 routes/{id} DELETE 从网关中删除现有路由。 16. 故障排除本部分介绍使用Spring Cloud Gateway时可能出现的常见问题。 16.1. 日志级别以下记录器可能包含 DEBUG 和 TRACE 级别的重要疑难解答信息： org.springframework.cloud.gateway org.springframework.http.server.reactive org.springframework.web.reactive org.springframework.boot.autoconfigure.web reactor.netty redisratelimiter 16.2. 监听Reactor Netty HttpClient和HttpServer可以启用窃听。与react.netty日志级别设置为DEBUG或TRACE结合使用时，它将启用信息记录，例如通过电线发送和接收的标头和正文。要启用窃听，请分别为HttpServer和HttpClient设置spring.cloud.gateway.httpserver.wiretap = true或spring.cloud.gateway.httpclient.wiretap = true。 17. 开发者向导这些是编写网关的某些自定义组件的基本指南。 17.1. 编写自定义的断言Factories为了编写Route Predicate，您将需要实现RoutePredicateFactory。您可以扩展一个名为AbstractRoutePredicateFactory的抽象类。 1234567891011121314151617181920212223public class MyRoutePredicateFactory extends AbstractRoutePredicateFactory&lt;HeaderRoutePredicateFactory.Config&gt; &#123; public MyRoutePredicateFactory() &#123; super(Config.class); &#125; @Override public Predicate&lt;ServerWebExchange&gt; apply(Config config) &#123; // grab configuration from Config object return exchange -&gt; &#123; //grab the request ServerHttpRequest request = exchange.getRequest(); //take information from the request to see if it //matches configuration. return matches(config, request); &#125;; &#125; public static class Config &#123; //Put the configuration properties for your filter here &#125;&#125; 17.2. 编写自定义的路由Factories要编写GatewayFilter，必须实现GatewayFilterFactory。您可以扩展一个名为AbstractGatewayFilterFactory的抽象类。以下示例显示了如何执行此操作： PreGatewayFilterFactory.java1234567891011121314151617181920212223public class PreGatewayFilterFactory extends AbstractGatewayFilterFactory&lt;PreGatewayFilterFactory.Config&gt; &#123; public PreGatewayFilterFactory() &#123; super(Config.class); &#125; @Override public GatewayFilter apply(Config config) &#123; // grab configuration from Config object return (exchange, chain) -&gt; &#123; //If you want to build a \"pre\" filter you need to manipulate the //request before calling chain.filter ServerHttpRequest.Builder builder = exchange.getRequest().mutate(); //use builder to manipulate the request return chain.filter(exchange.mutate().request(request).build()); &#125;; &#125; public static class Config &#123; //Put the configuration properties for your filter here &#125;&#125; PostGatewayFilterFactory.java12345678910111213141516171819202122public class PostGatewayFilterFactory extends AbstractGatewayFilterFactory&lt;PostGatewayFilterFactory.Config&gt; &#123; public PostGatewayFilterFactory() &#123; super(Config.class); &#125; @Override public GatewayFilter apply(Config config) &#123; // grab configuration from Config object return (exchange, chain) -&gt; &#123; return chain.filter(exchange).then(Mono.fromRunnable(() -&gt; &#123; ServerHttpResponse response = exchange.getResponse(); //Manipulate the response in some way &#125;)); &#125;; &#125; public static class Config &#123; //Put the configuration properties for your filter here &#125;&#125; 17.3. 编写自定义的全局路由要编写自定义全局过滤器，必须实现GlobalFilter接口。这会将过滤器应用于所有请求。以下示例显示如何分别设置全局前置和后置过滤器： 12345678910111213141516171819202122232425@Beanpublic GlobalFilter customGlobalFilter() &#123; return (exchange, chain) -&gt; exchange.getPrincipal() .map(Principal::getName) .defaultIfEmpty(\"Default User\") .map(userName -&gt; &#123; //adds header to proxied request exchange.getRequest().mutate().header(\"CUSTOM-REQUEST-HEADER\", userName).build(); return exchange; &#125;) .flatMap(chain::filter);&#125;@Beanpublic GlobalFilter customGlobalPostFilter() &#123; return (exchange, chain) -&gt; chain.filter(exchange) .then(Mono.just(exchange)) .map(serverWebExchange -&gt; &#123; //adds header to response serverWebExchange.getResponse().getHeaders().set(\"CUSTOM-RESPONSE-HEADER\", HttpStatus.OK.equals(serverWebExchange.getResponse().getStatusCode()) ? \"It worked\": \"It did not work\"); return serverWebExchange; &#125;) .then();&#125; 18. 使用 Spring MVC 或 Webflux创建一个简单的路由Spring Cloud Gateway提供了一个名为ProxyExchange的实用程序对象。您可以在常规的Spring Web处理程序中使用它作为方法参数。它通过镜像HTTP动词的方法支持基本的下游HTTP交换。使用MVC，它还支持通过forward（）方法转发到本地处理程序。要使用ProxyExchange，请在类路径中包含正确的模块（spring-cloud-gateway-mvc或spring-cloud-gateway-webflux）。 以下MVC示例代理了对/ test到远程服务器下游的请求：12345678910111213@RestController@SpringBootApplicationpublic class GatewaySampleApplication &#123; @Value(\"$&#123;remote.home&#125;\") private URI home; @GetMapping(\"/test\") public ResponseEntity&lt;?&gt; proxy(ProxyExchange&lt;byte[]&gt; proxy) throws Exception &#123; return proxy.uri(home.toString() + \"/image/png\").get(); &#125;&#125; 以下示例对Webflux执行相同的操作：12345678910111213@RestController@SpringBootApplicationpublic class GatewaySampleApplication &#123; @Value(\"$&#123;remote.home&#125;\") private URI home; @GetMapping(\"/test\") public Mono&lt;ResponseEntity&lt;?&gt;&gt; proxy(ProxyExchange&lt;byte[]&gt; proxy) throws Exception &#123; return proxy.uri(home.toString() + \"/image/png\").get(); &#125;&#125; ProxyExchange上的便捷方法使处理程序方法可以发现并增强传入请求的URI路径。例如，您可能想要提取路径的尾随元素以将它们传递到下游：12345@GetMapping(\"/proxy/path/**\")public ResponseEntity&lt;?&gt; proxyPath(ProxyExchange&lt;byte[]&gt; proxy) throws Exception &#123; String path = proxy.path(\"/proxy/path/\"); return proxy.uri(home.toString() + \"/foos/\" + path).get();&#125; 网关处理程序方法可以使用Spring MVC和Webflux的所有功能。结果，例如，您可以注入请求标头和查询参数，并且可以使用映射批注中的声明来约束传入的请求。有关这些功能的更多详细信息，请参见Spring MVC中有关@RequestMapping的文档。 您可以使用ProxyExchange上的header（）方法将标头添加到下游响应中。 您还可以通过将映射器添加到get（）方法（和其他方法）来操纵响应头（以及响应中您喜欢的任何其他内容）。映射器是一个函数，它接收传入的ResponseEntity并将其转换为传出的实体。 对不传递到下游的“sensitive” headers （默认情况下为cookie和authorization）和“proxy”（x-forwarded- *）标头提供一流的支持。 19. 配置属性表要查看所有与Spring Cloud Gateway相关的配置属性的列表，请参阅附录。","categories":[{"name":"springcloud","slug":"springcloud","permalink":"https://www.icepear.cn/categories/springcloud/"}],"tags":[{"name":"Spring Cloud Gateway","slug":"Spring-Cloud-Gateway","permalink":"https://www.icepear.cn/tags/Spring-Cloud-Gateway/"}]},{"title":"关于《奔涌吧！后浪》我的一些看法","slug":"read/houlang","date":"2020-05-04T15:30:02.000Z","updated":"2020-05-13T01:29:17.416Z","comments":true,"path":"2020/05/04/read/houlang/","link":"","permalink":"https://www.icepear.cn/2020/05/04/read/houlang/","excerpt":"关于《奔涌吧！后浪》我的一些看法","text":"关于《奔涌吧！后浪》我的一些看法今天是五·四青年节，各类新闻和视频宣传片充斥着新闻主页以及朋友圈。有一个有意思的现象是：B站凭借着在年轻人圈子的影响力，商业演讲主题片《后浪》被迅速转发宣传开来，我的朋友圈也不乏被这个短片刷屏，评论转发有正面的也有反对的。但对于这次的主题片在今天这个日子发布我是不敢恭维的。 首先我已经表明了我的态度，但我必须辩证的来看待这次被推上风口浪尖的演讲片。 从正面来看，对B站来说这是一次很成功的商业营销，文本技术上确实很煽情，很鸡汤，满满的正能量，甚至有点缺乏社会毒打的意思，尤其是在何冰字正腔圆铿锵有力的朗读加持下，这鸡血不上头都不行。视频中的二次元文化、美食、旅游、电竞等等题材都将B站的特点表现的淋漓尽致，相比较于抖音快手这类平台的“精神小伙”、“美女小姐姐”、“闺蜜舞”等等标签来说，我还是更推崇B站的文化。对用户来讲，B站确实也是一个比较完善的大众学习交流分享的平台，片中也有提到“自由学习一门语言、学习一门手艺、欣赏一部电影、去遥远的地方旅行”，这些美妙生活的场景确实能让不少人感到激情澎湃，尤其B站的用户更能get到它所表达的追求梦想，勇敢体验，接纳多元文化的重点，从效果而言，着实达到了让老用户感动一把巩固心理地位，新用户兴奋三十秒引流的目的这短片要是选择在过年投放出来，一大段拜年恭候的话语，那效果和舆论肯定都是齐刷刷的：B站NB 但是它偏偏在五四这一天投放出来了，就是有点欠锤的意思。 我先占用一点空间给历史不好的同学或者有些淡忘的同学介绍一下五四青年节的由来：第一次世界大战期间，欧洲列强无暇东顾，日本乘机加强对中国的侵略，严重损害了中国的主权。中国人民的反日情绪日渐增长。1919年巴黎和会上中国外交的失败，引发了伟大的五四运动。这是直接导火索，主要原因还是由于新文化运动从思想、文化领域激发和影响了中国人尤其是中国青年的爱国救国热情，学生、工人纷纷罢工罢课高举德先生和赛先生两面旗帜站上了街头。 但这次《后浪》的主体中又有那一项是五四精神的传承呢？“自由”？“大气”？还是“赞美与鼓励”？。通篇都充斥着“自由选择爱好的权利，享受物质带来的乐趣”，可这些都是前浪那些青年用热血换来的啊，他们想要的权利难道仅仅只是是想买什么就能买什么，想去哪玩就去哪玩的权利吗？仔细思考一下，结合中国现在大部分青年的现实情况来讲，在买房、育儿、养老等因素的影响下你真的还有多少选择的权利呢。更搞笑的是后浪说的不惑之年居然是不惑于喜欢什么，不喜欢什么这种浮浅层次的认知。 得不到的我们都会向往，所以我们会幻想，习总也说过当前中国社会矛盾是：人民日益增长的美好生活需要和不平衡不充分的发展之间的矛盾。社会资源集中化，高速发展的红利时代即将落幕，行业分配机制不合理等等问题都逼迫我们往现实里看。一个很有意思的现象：大学几乎所有本专业的学生都不会推荐后面的人学本专业，IT和金融除外，因为正处于行业红利期。而视频中的青年不是国外旅行、就是vr设备、跳伞、或是穿着cos服在上海China joy中各种秀、更夸张的是还有直升机停机坪跳舞，这些东西真的是大部分青年都有能力去体验的吗？难道送外卖的小哥、搞基建的农民工、住着廉价出租房的小白领就不是中国青年？视频中的场景确实梦幻，就像是一剂肾上腺素注入身体；像是多巴胺在不断分泌；以至于不少人兴奋双击加转发。 1.在我看来这只是制片方在为少数的红利既得者或者富二代们跪舔，以小众的案例囊括大众的生活。 2.“弱小的人，才习惯嘲讽与否定，内心强大的人，从不吝啬赞美与鼓励”。我今天就是锤他了，所以我是弱小的人？难道不是弱小的人才不断需要赞美与鼓励吗？难道真的要让青年们丧失判断力和批判力。只要给他们流量明星、抖音快手、华丽服饰，岁月静好。无须让他们有独立思考的能力，从出生就根植服从心。让他们对批判国家、社会和领袖抱着一种憎恶，让他们深信那是少数罪恶派和境外势力的谋合，让他们个个都成为“战狼”。 3.年轻人当然需要爱好，能将自己的爱好变为事业也是我想要达到的理想工作。但是我们必须结合现实，不能一味的夸夸奇谈，不能仅仅是享受，我们应该去发倔和分享，当我们在经历了生活的捶打还能坚持自己的热爱，当我们在万众偕同的环境中还保留自己的见解认知，我认为我们才是新青年 4.今天谈的是五四精神其实是跟物质生活相关但又不相关的东西。五四青年的特征我认为是但不局限：民主、自由、科学。这也是我推崇的思想。所以我认为跟物质没有关系，但是我们都需要工作，都在为生活奔波，都在创造自我的价值，这些特征会让我们的变得更加有创造力，我们会更深层次的去看待问题，解决问题。 5.管他前浪后浪，我只是希望往后不必再有996；只是希望安得广厦千万间，大庇天下寒士俱欢颜；希望能够享受自己的生活，享受创造带来的乐趣，享受帮助别人的快乐·····。真正成为一群心里有火，眼里有光，会独立自由思考的青年。 行文最后，我还是想引用鲁迅先生的一段话：“愿中国青年都摆脱冷气，只是向上走，不必听自暴自弃者流的话。能做事的做事，能发声的发声。有一分热，发一分光，就令萤火一般，也可以在黑暗里发一点光，不必等候炬火。此后如竟没有炬火：我便是唯一的光。”","categories":[{"name":"read","slug":"read","permalink":"https://www.icepear.cn/categories/read/"}],"tags":[]},{"title":"mysql 部署在k8s时出现问题","slug":"mysql/k8s-deploy","date":"2020-05-02T06:30:02.000Z","updated":"2020-05-12T08:43:44.995Z","comments":true,"path":"2020/05/02/mysql/k8s-deploy/","link":"","permalink":"https://www.icepear.cn/2020/05/02/mysql/k8s-deploy/","excerpt":"最近对mysql部署到k8s时，碰到一个问题，报错说，数据库初始化时，目录文件中存在文件。辗转issue、StackOverflow都没有解决，最后采取蠢办法解决，在此记录一下过程","text":"最近对mysql部署到k8s时，碰到一个问题，报错说，数据库初始化时，目录文件中存在文件。辗转issue、StackOverflow都没有解决，最后采取蠢办法解决，在此记录一下过程 story故事因为要将应用使用helm快捷部署至k8s，所以必不可少的需要mysql，就找到helm官方的mysql charts.链接但是在官方charts中并未发现有storageclass存在，但是看说明又是支持storageclass的，所以就自己定义了一个storageclass，而pv的提供者是自己用nfs-client-provisioner搭建的共享存储。然后错误就出现了 重现下载charts找到官方的charts源码，并下载，然后在templates文件夹下建立storageclass.yaml 123456789101112&#123;&#123;- if and .Values.persistence.enabled (not .Values.persistence.existingClaim) -&#125;&#125;apiVersion: storage.k8s.io/v1kind: StorageClassmetadata: name: &#123;&#123; .Values.persistence.storageClass.storageClassName &#125;&#125;provisioner: &#123;&#123; toYaml .Values.persistence.storageClass.provisioner | indent 2 &#125;&#125;parameters:&#123;&#123; toYaml .Values.persistence.storageClass.classParameters | indent 2 &#125;&#125;reclaimPolicy: RetainallowVolumeExpansion: true&#123;&#123;- end &#125;&#125; 启动 启动 1$ helm install --namespace mysql-dev --name mysql-01 ./ 查看pod 1$ kubectl get pods -n mysql-dev 发现pod一直处于CrashLoopBackOff的状态， 查看日志 1$ kubectl logs pod名称 发现提示错误 12[ERROR] --initialize specified but the data directory has files in it. Aborting.[ERROR] Aborting 搜索然后就开始了一些列的搜索，首先到官方github上提issue，然后Stack Overflow上找找找····，结果还是没有解决办法。 解决万念俱灰的时候，想到是否可以尝试手动创建pv的方式，是否真的是nfs-client-provisioner创建的pv有问题，跟mysql不兼容。 然后我就手动创建了hostpath方式的一个pv 12345678910111213apiVersion: v1kind: PersistentVolumemetadata: name: mysql-pvspec: capacity: storage: 10Gi volumeMode: Filesystem accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Recycle hostpath: path: \"/data/k8s/mysql\" 然后把pvc改成pv的方式，不用storageclass，发现部署成功了。难道真的是nfs方式不支持吗？小伙伴不知道有没有同样的情况，欢迎评论区交流。 最后，是不是说像mysql这类存储型的中间件，采取hostpath的方式对于I/O来说其实是最优的选择？","categories":[{"name":"mysql","slug":"mysql","permalink":"https://www.icepear.cn/categories/mysql/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://www.icepear.cn/tags/k8s/"},{"name":"Mysql","slug":"Mysql","permalink":"https://www.icepear.cn/tags/Mysql/"}]},{"title":"k8s storageclass 自动创建pv","slug":"k8s/storageclass","date":"2020-04-30T12:30:02.000Z","updated":"2020-05-12T08:43:44.986Z","comments":true,"path":"2020/04/30/k8s/storageclass/","link":"","permalink":"https://www.icepear.cn/2020/04/30/k8s/storageclass/","excerpt":"在k8s运维的过程中，针对于各种应用都会产生数据，而数据挂载需要pv来存储，我们必须一个一个手动来创建pv，这对运维来说是不够合理，storageclass正好就是干这事的，就是根据pvc的要求，结合第三方应用自动创建合适的pv","text":"在k8s运维的过程中，针对于各种应用都会产生数据，而数据挂载需要pv来存储，我们必须一个一个手动来创建pv，这对运维来说是不够合理，storageclass正好就是干这事的，就是根据pvc的要求，结合第三方应用自动创建合适的pv StorageClass 前面讲的 PV 都是静态的，意思就是我要使用的一个 PVC 的话就必须手动去创建一个 PV，我们也说过这种方式在很大程度上并不能满足我们的需求，比如我们有一个应用需要对存储的并发度要求比较高，而另外一个应用对读写速度又要求比较高，特别是对于 StatefulSet 类型的应用简单的来使用静态的 PV 就很不合适了，这种情况下我们就需要用到动态 PV，也就是StorageClass。 安装要使用StorageClass自动创建pv，就得安装对应的自动配置程序。这个程序叫做 nfs-client-provisioner，需要结合我们上面讲的nfs来使用，创建pv的时候有两个特性 自动创建的 PV 以${namespace}-${pvcName}-${pvName}这样的命名格式创建在 NFS 服务器上的共享数据目录中 而当这个 PV 被回收后会以archieved-${namespace}-${pvcName}-${pvName}这样的命名格式存在 NFS 服务器上。 下面我们分三步来创建这个自动配置程序： 1.创建 ServiceAccount现在的 Kubernetes 集群大部分是基于 RBAC 的权限控制，所以创建一个一定权限的 ServiceAccount 与后面要创建的 “NFS Provisioner” 绑定，赋予一定的权限。 nfs-rbac.yaml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657kind: ServiceAccountapiVersion: v1metadata: name: nfs-client-provisioner---kind: ClusterRoleapiVersion: rbac.authorization.k8s.io/v1metadata: name: nfs-client-provisioner-runnerrules: - apiGroups: [\"\"] resources: [\"persistentvolumes\"] verbs: [\"get\", \"list\", \"watch\", \"create\", \"delete\"] - apiGroups: [\"\"] resources: [\"persistentvolumeclaims\"] verbs: [\"get\", \"list\", \"watch\", \"update\"] - apiGroups: [\"storage.k8s.io\"] resources: [\"storageclasses\"] verbs: [\"get\", \"list\", \"watch\"] - apiGroups: [\"\"] resources: [\"events\"] verbs: [\"create\", \"update\", \"patch\"]---kind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: run-nfs-client-provisionersubjects: - kind: ServiceAccount name: nfs-client-provisioner namespace: default #替换成你要部署NFS Provisioner的 NamespaceroleRef: kind: ClusterRole name: nfs-client-provisioner-runner apiGroup: rbac.authorization.k8s.io---kind: RoleapiVersion: rbac.authorization.k8s.io/v1metadata: name: leader-locking-nfs-client-provisionerrules: - apiGroups: [\"\"] resources: [\"endpoints\"] verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\"]---kind: RoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: leader-locking-nfs-client-provisionersubjects: - kind: ServiceAccount name: nfs-client-provisioner namespace: default #替换成你要部署NFS Provisioner的 NamespaceroleRef: kind: Role name: leader-locking-nfs-client-provisioner apiGroup: rbac.authorization.k8s.io 创建 RBAC1$ kubectl apply -f nfs-rbac.yaml 2.部署nfs-client-provisioner的Deploymentnfs-provisioner-deploy.yaml1234567891011121314151617181920212223242526272829303132kind: DeploymentapiVersion: extensions/v1beta1metadata: name: nfs-client-provisionerspec: replicas: 1 strategy: type: Recreate #---设置升级策略为删除再创建(默认为滚动更新) template: metadata: labels: app: nfs-client-provisioner spec: serviceAccountName: nfs-client-provisioner containers: - name: nfs-client-provisioner image: quay.io/external_storage/nfs-client-provisioner:latest volumeMounts: - name: nfs-client-root mountPath: /persistentvolumes env: - name: PROVISIONER_NAME value: icepear.cn/ifs #--- nfs-provisioner的名称，以后设置的storageclass要和这个保持一致 - name: NFS_SERVER value: 192.168.110.15 #---NFS服务器地址，和 valumes 保持一致 - name: NFS_PATH value: /data/nfs-share #---NFS服务器目录，和 valumes 保持一致 volumes: - name: nfs-client-root nfs: server: 192.168.110.15 #---NFS服务器地址 path: /data/nfs-share #---NFS服务器目录 创建 NFS Provisioner1$ kubectl apply -f nfs-provisioner-deploy.yaml -n default 3.创建SotageClassnfs-storage.yaml 123456789apiVersion: storage.k8s.io/v1kind: StorageClassmetadata: name: nfs-storage annotations: storageclass.kubernetes.io/is-default-class: \"true\" #---设置为默认的storageclassprovisioner: icepear.cn/ifs #---动态卷分配者名称，必须和上面创建的\"provisioner\"变量中设置的Name一致parameters: archiveOnDelete: \"true\" #---设置为\"false\"时删除PVC不会保留数据,\"true\"则保留数据 4.测试storegeclass 创建测试 PVC test-pvc.yaml1234567891011kind: PersistentVolumeClaimapiVersion: v1metadata: name: test-pvcspec: storageClassName: nfs-storage #---需要与上面创建的storageclass的名称一致 accessModes: - ReadWriteOnce resources: requests: storage: 1Mi 创建 PVC 1$ kubectl apply -f test-pvc.yaml -n default 查看 PVC 状态是否与 PV 绑定 利用 Kubectl 命令获取 pvc 资源，查看 STATUS 状态是否为 “Bound”。 1234$ kubectl get pvc test-pvc -n defaultNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASStest-pvc Bound pvc-be0808c2-9957-11e9 1Mi RWO nfs-storage 创建测试 Pod 并绑定 PVC 创建一个测试用的 Pod，指定存储为上面创建的 PVC，然后创建一个文件在挂载的 PVC 目录中，然后进入 NFS 服务器下查看该文件是否存入其中。 test-pod.yaml123456789101112131415161718192021kind: PodapiVersion: v1metadata: name: test-podspec: containers: - name: test-pod image: busybox:latest command: - \"/bin/sh\" args: - \"-c\" - \"touch /mnt/SUCCESS &amp;&amp; exit 0 || exit 1\" #创建一个名称为\"SUCCESS\"的文件 volumeMounts: - name: nfs-pvc mountPath: \"/mnt\" restartPolicy: \"Never\" volumes: - name: nfs-pvc persistentVolumeClaim: claimName: test-pvc 创建 Pod1$ kubectl apply -f test-pod.yaml -n default 查看nfs服务器上是否创建的了文件 12$ cd /data/nfs-share$ ls","categories":[{"name":"k8s","slug":"k8s","permalink":"https://www.icepear.cn/categories/k8s/"}],"tags":[{"name":"storageclass","slug":"storageclass","permalink":"https://www.icepear.cn/tags/storageclass/"}]},{"title":"十分钟入门RocketMQ","slug":"mq/rocketmq","date":"2020-04-20T11:30:02.000Z","updated":"2020-05-12T08:43:44.993Z","comments":true,"path":"2020/04/20/mq/rocketmq/","link":"","permalink":"https://www.icepear.cn/2020/04/20/mq/rocketmq/","excerpt":"本文章摘抄自 阿里中间件团队博客本文首先引出消息中间件通常需要解决哪些问题，在解决这些问题当中会遇到什么困难，Apache RocketMQ作为阿里开源的一款高性能、高吞吐量的分布式消息中间件否可以解决，规范中如何定义这些问题。然后本文将介绍RocketMQ的架构设计，以期让读者快速了解RocketMQ。","text":"本文章摘抄自 阿里中间件团队博客本文首先引出消息中间件通常需要解决哪些问题，在解决这些问题当中会遇到什么困难，Apache RocketMQ作为阿里开源的一款高性能、高吞吐量的分布式消息中间件否可以解决，规范中如何定义这些问题。然后本文将介绍RocketMQ的架构设计，以期让读者快速了解RocketMQ。 消息中间件需要解决哪些问题？Publish/Subscribe发布订阅是消息中间件的最基本功能，也是相对于传统RPC通信而言。在此不再详述。 Message Priority规范中描述的优先级是指在一个消息队列中，每条消息都有不同的优先级，一般用整数来描述，优先级高的消息先投递，如果消息完全在一个内存队列中，那么在投递前可以按照优先级排序，令优先级高的先投递。由于RocketMQ所有消息都是持久化的，所以如果按照优先级来排序，开销会非常大，因此RocketMQ没有特意支持消息优先级，但是可以通过变通的方式实现类似功能，即单独配置一个优先级高的队列，和一个普通优先级的队列， 将不同优先级发送到不同队列即可。 对于优先级问题，可以归纳为2类： 只要达到优先级目的即可，不是严格意义上的优先级，通常将优先级划分为高、中、低，或者再多几个级别。每个优先级可以用不同的topic表示，发消息时，指定不同的topic来表示优先级，这种方式可以解决绝大部分的优先级问题，但是对业务的优先级精确性做了妥协。严格的优先级，优先级用整数表示，例如0 ~ 65535，这种优先级问题一般使用不同topic解决就非常不合适。如果要让MQ解决此问题，会对MQ的性能造成非常大的影响。这里要确保一点，业务上是否确实需要这种严格的优先级，如果将优先级压缩成几个，对业务的影响有多大？ Message Order消息有序指的是一类消息消费时，能按照发送的顺序来消费。例如：一个订单产生了3条消息，分别是订单创建，订单付款，订单完成。消费时，要按照这个顺序消费才能有意义。但是同时订单之间是可以并行消费的。RocketMQ可以严格的保证消息有序。 Message FilterBroker端消息过滤在Broker中，按照Consumer的要求做过滤，优点是减少了对于Consumer无用消息的网络传输。缺点是增加了Broker的负担，实现相对复杂。 淘宝Notify支持多种过滤方式，包含直接按照消息类型过滤，灵活的语法表达式过滤，几乎可以满足最苛刻的过滤需求。淘宝RocketMQ支持按照简单的Message Tag过滤，也支持按照Message Header、body进行过滤。CORBA Notification规范中也支持灵活的语法表达式过滤。Consumer端消息过滤这种过滤方式可由应用完全自定义实现，但是缺点是很多无用的消息要传输到Consumer端。 Message Persistence消息中间件通常采用的几种持久化方式： 持久化到数据库，例如Mysql。持久化到KV存储，例如levelDB、伯克利DB等KV存储系统。文件记录形式持久化，例如Kafka，RocketMQ对内存数据做一个持久化镜像，例如beanstalkd，VisiNotify(1)、(2)、(3)三种持久化方式都具有将内存队列Buffer进行扩展的能力，(4)只是一个内存的镜像，作用是当Broker挂掉重启后仍然能将之前内存的数据恢复出来。JMS与CORBA Notification规范没有明确说明如何持久化，但是持久化部分的性能直接决定了整个消息中间件的性能。 RocketMQ充分利用Linux文件系统内存cache来提高性能。 Message Reliablity影响消息可靠性的几种情况： Broker正常关闭Broker异常CrashOS Crash机器掉电，但是能立即恢复供电情况。机器无法开机（可能是cpu、主板、内存等关键设备损坏）磁盘设备损坏。(1)、(2)、(3)、(4)四种情况都属于硬件资源可立即恢复情况，RocketMQ在这四种情况下能保证消息不丢，或者丢失少量数据（依赖刷盘方式是同步还是异步）。 (5)、(6)属于单点故障，且无法恢复，一旦发生，在此单点上的消息全部丢失。RocketMQ在这两种情况下，通过异步复制，可保证99%的消息不丢，但是仍然会有极少量的消息可能丢失。通过同步双写技术可以完全避免单点，同步双写势必会影响性能，适合对消息可靠性要求极高的场合，例如与Money相关的应用。 RocketMQ从3.0版本开始支持同步双写。 Low Latency Messaging在消息不堆积情况下，消息到达Broker后，能立刻到达Consumer。RocketMQ使用长轮询Pull方式，可保证消息非常实时，消息实时性不低于Push。 At least Once是指每个消息必须投递一次。RocketMQ Consumer先pull消息到本地，消费完成后，才向服务器返回ack，如果没有消费一定不会ack消息，所以RocketMQ可以很好的支持此特性。 Exactly Only Once发送消息阶段，不允许发送重复的消息。消费消息阶段，不允许消费重复的消息。只有以上两个条件都满足情况下，才能认为消息是“Exactly Only Once”，而要实现以上两点，在分布式系统环境下，不可避免要产生巨大的开销。所以RocketMQ为了追求高性能，并不保证此特性，要求在业务上进行去重，也就是说消费消息要做到幂等性。RocketMQ虽然不能严格保证不重复，但是正常情况下很少会出现重复发送、消费情况，只有网络异常，Consumer启停等异常情况下会出现消息重复。 Broker的Buffer满了怎么办？Broker的Buffer通常指的是Broker中一个队列的内存Buffer大小，这类Buffer通常大小有限，如果Buffer满了以后怎么办？下面是CORBA Notification规范中处理方式： RejectNewEvents 拒绝新来的消息，向Producer返回RejectNewEvents错误码。按照特定策略丢弃已有消息AnyOrder - Any event may be discarded on overflow. This is the default setting for this property.FifoOrder - The first event received will be the first discarded.LifoOrder - The last event received will be the first discarded.PriorityOrder - Events should be discarded in priority order, such that lower priority events will be discarded before higher priority events.DeadlineOrder - Events should be discarded in the order of shortest expiry deadline first.RocketMQ没有内存Buffer概念，RocketMQ的队列都是持久化磁盘，数据定期清除。 对于此问题的解决思路，RocketMQ同其他MQ有非常显著的区别，RocketMQ的内存Buffer抽象成一个无限长度的队列，不管有多少数据进来都能装得下，这个无限是有前提的，Broker会定期删除过期的数据，例如Broker只保存3天的消息，那么这个Buffer虽然长度无限，但是3天前的数据会被从队尾删除。 此问题的本质原因是网络调用存在不确定性，即既不成功也不失败的第三种状态，所以才产生了消息重复性问题。 回溯消费回溯消费是指Consumer已经消费成功的消息，由于业务上需求需要重新消费，要支持此功能，Broker在向Consumer投递成功消息后，消息仍然需要保留。并且重新消费一般是按照时间维度，例如由于Consumer系统故障，恢复后需要重新消费1小时前的数据，那么Broker要提供一种机制，可以按照时间维度来回退消费进度。RocketMQ支持按照时间回溯消费，时间维度精确到毫秒，可以向前回溯，也可以向后回溯。 消息堆积消息中间件的主要功能是异步解耦，还有个重要功能是挡住前端的数据洪峰，保证后端系统的稳定性，这就要求消息中间件具有一定的消息堆积能力，消息堆积分以下两种情况： 消息堆积在内存Buffer，一旦超过内存Buffer，可以根据一定的丢弃策略来丢弃消息，如CORBA Notification规范中描述。适合能容忍丢弃消息的业务，这种情况消息的堆积能力主要在于内存Buffer大小，而且消息堆积后，性能下降不会太大，因为内存中数据多少对于对外提供的访问能力影响有限。消息堆积到持久化存储系统中，例如DB，KV存储，文件记录形式。 当消息不能在内存Cache命中时，要不可避免的访问磁盘，会产生大量读IO，读IO的吞吐量直接决定了消息堆积后的访问能力。评估消息堆积能力主要有以下四点： 消息能堆积多少条，多少字节？即消息的堆积容量。消息堆积后，发消息的吞吐量大小，是否会受堆积影响？消息堆积后，正常消费的Consumer是否会受影响？消息堆积后，访问堆积在磁盘的消息时，吞吐量有多大？ 分布式事务已知的几个分布式事务规范，如XA，JTA等。其中XA规范被各大数据库厂商广泛支持，如Oracle，Mysql等。其中XA的TM实现佼佼者如Oracle Tuxedo，在金融、电信等领域被广泛应用。 分布式事务涉及到两阶段提交问题，在数据存储方面的方面必然需要KV存储的支持，因为第二阶段的提交回滚需要修改消息状态，一定涉及到根据Key去查找Message的动作。RocketMQ在第二阶段绕过了根据Key去查找Message的问题，采用第一阶段发送Prepared消息时，拿到了消息的Offset，第二阶段通过Offset去访问消息，并修改状态，Offset就是数据的地址。 RocketMQ这种实现事务方式，没有通过KV存储做，而是通过Offset方式，存在一个显著缺陷，即通过Offset更改数据，会令系统的脏页过多，需要特别关注。 定时消息定时消息是指消息发到Broker后，不能立刻被Consumer消费，要到特定的时间点或者等待特定的时间后才能被消费。如果要支持任意的时间精度，在Broker层面，必须要做消息排序，如果再涉及到持久化，那么消息排序要不可避免的产生巨大性能开销。RocketMQ支持定时消息，但是不支持任意时间精度，支持特定的level，例如定时5s，10s，1m等。 消息重试Consumer消费消息失败后，要提供一种重试机制，令消息再消费一次。Consumer消费消息失败通常可以认为有以下几种情况： 由于消息本身的原因，例如反序列化失败，消息数据本身无法处理（例如话费充值，当前消息的手机号被注销，无法充值）等。这种错误通常需要跳过这条消息，再消费其他消息，而这条失败的消息即使立刻重试消费，99%也不成功，所以最好提供一种定时重试机制，即过10s秒后再重试。由于依赖的下游应用服务不可用，例如db连接不可用，外系统网络不可达等。遇到这种错误，即使跳过当前失败的消息，消费其他消息同样也会报错。这种情况建议应用sleep 30s，再消费下一条消息，这样可以减轻Broker重试消息的压力。 RocketMQ OverviewRocketMQ是否解决了上述消息中间件面临的问题，接下来让我们一探究竟。 RocketMQ 是什么？ 上图是一个典型的消息中间件收发消息的模型，RocketMQ也是这样的设计，简单说来，RocketMQ具有以下特点： 是一个队列模型的消息中间件，具有高性能、高可靠、高实时、分布式特点。Producer、Consumer、队列都可以分布式。Producer向一些队列轮流发送消息，队列集合称为Topic，Consumer如果做广播消费，则一个consumer实例消费这个Topic对应的所有队列，如果做集群消费，则多个Consumer实例平均消费这个topic对应的队列集合。能够保证严格的消息顺序提供丰富的消息拉取模式高效的订阅者水平扩展能力实时的消息订阅机制亿级消息堆积能力较少的依赖 RocketMQ 物理部署结构如上图所示， RocketMQ的部署结构有以下特点： Name Server是一个几乎无状态节点，可集群部署，节点之间无任何信息同步。Broker部署相对复杂，Broker分为Master与Slave，一个Master可以对应多个Slave，但是一个Slave只能对应一个Master，Master与Slave的对应关系通过指定相同的BrokerName，不同的BrokerId来定义，BrokerId为0表示Master，非0表示Slave。Master也可以部署多个。每个Broker与Name Server集群中的所有节点建立长连接，定时注册Topic信息到所有Name Server。Producer与Name Server集群中的其中一个节点（随机选择）建立长连接，定期从Name Server取Topic路由信息，并向提供Topic服务的Master建立长连接，且定时向Master发送心跳。Producer完全无状态，可集群部署。Consumer与Name Server集群中的其中一个节点（随机选择）建立长连接，定期从Name Server取Topic路由信息，并向提供Topic服务的Master、Slave建立长连接，且定时向Master、Slave发送心跳。Consumer既可以从Master订阅消息，也可以从Slave订阅消息，订阅规则由Broker配置决定。 RocketMQ 逻辑部署结构如上图所示，RocketMQ的逻辑部署结构有Producer和Consumer两个特点。 Producer Group 用来表示一个发送消息应用，一个Producer Group下包含多个Producer实例，可以是多台机器，也可以是一台机器的多个进程，或者一个进程的多个Producer对象。一个Producer Group可以发送多个Topic消息，Producer Group作用如下： 标识一类Producer可以通过运维工具查询这个发送消息应用下有多个Producer实例发送分布式事务消息时，如果Producer中途意外宕机，Broker会主动回调Producer Group内的任意一台机器来确认事务状态。Consumer Group 用来表示一个消费消息应用，一个Consumer Group下包含多个Consumer实例，可以是多台机器，也可以是多个进程，或者是一个进程的多个Consumer对象。一个Consumer Group下的多个Consumer以均摊方式消费消息，如果设置为广播方式，那么这个Consumer Group下的每个实例都消费全量数据。 RocketMQ 数据存储结构如上图所示，RocketMQ采取了一种数据与索引分离的存储方法。有效降低文件资源、IO资源，内存资源的损耗。即便是阿里这种海量数据，高并发场景也能够有效降低端到端延迟，并具备较强的横向扩展能力。","categories":[{"name":"mq","slug":"mq","permalink":"https://www.icepear.cn/categories/mq/"}],"tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.icepear.cn/tags/RocketMQ/"}]},{"title":"docker中运行RabbitMQ","slug":"mq/rabbitmq-docker","date":"2020-04-19T11:30:02.000Z","updated":"2020-05-12T08:43:44.992Z","comments":true,"path":"2020/04/19/mq/rabbitmq-docker/","link":"","permalink":"https://www.icepear.cn/2020/04/19/mq/rabbitmq-docker/","excerpt":"RabbitMQ是实现高级消息队列协议（AMQP）的开源消息代理软件（有时称为面向消息的中间件）。RabbitMQ服务器使用Erlang编程语言编写，并基于Open Telecom Platform框架构建，用于集群和故障转移。主要用于各个业务场景的拆分，降低系统耦合性。本文主要介绍在docker中如何运行rabbitmq中间件","text":"RabbitMQ是实现高级消息队列协议（AMQP）的开源消息代理软件（有时称为面向消息的中间件）。RabbitMQ服务器使用Erlang编程语言编写，并基于Open Telecom Platform框架构建，用于集群和故障转移。主要用于各个业务场景的拆分，降低系统耦合性。本文主要介绍在docker中如何运行rabbitmq中间件 一、下载及简单运行rabbitmq官方已经编写了docker镜像，镜像地址。 1.下载123docker pull rabbitmq # rabbitmq最小安装#或者采用（建议）docker pull rabbitmq:management #带有web控制台的镜像 2.运行1docker run -d --hostname my-rabbit --name some-rabbit -p 15672:15672 -p 5672:5672 rabbitmq:management 访问http://localhost:15672 即可访问rabbitmq的管理界面。默认的用户名/密码为 guest/guest 二、带参数运行通过cookie连接rabbitmqcookie 对于rabbitmq集群来说相当重要，集群间应该配置相同的cookie使节点互通。参考官网Cookie只是一串字母数字字符，最大长度为255个字符。它通常存储在本地文件中。 在docker 中 可以使用参数RABBITMQ_ERLANG_COOKIE在运行命令中开启cookie， 1docker run -d --hostname some-rabbit --name some-rabbit --network some-network -e RABBITMQ_ERLANG_COOKIE='secret cookie here' rabbitmq:3 也可以使用挂在cookie文件的方式，cookie文件容器内部的地址在 /var/lib/rabbitmq/.erlang.cookie通过docker 创建secrets文件 1docker service create --name rabbitmq-cookie --secret source=my-erlang-cookie,target=/var/lib/rabbitmq/.erlang.cookie,uid=1001,gid=1001,mode=0600 rabbitmq 需要指定uid = XXX，gid = XXX，mode = 0600，以便容器中的Erlang能够正确读取cookie文件。 其他参数1.SSL 配置1234567# 对于使用管理插件的SSL配置RABBITMQ_MANAGEMENT_SSL_CACERTFILERABBITMQ_MANAGEMENT_SSL_CERTFILERABBITMQ_MANAGEMENT_SSL_DEPTHRABBITMQ_MANAGEMENT_SSL_FAIL_IF_NO_PEER_CERTRABBITMQ_MANAGEMENT_SSL_KEYFILERABBITMQ_MANAGEMENT_SSL_VERIFY 2.设置默认用户和密码如果要更改guest / guest的默认用户名和密码，可以使用RABBITMQ_DEFAULT_USER和RABBITMQ_DEFAULT_PASS环境变量来进行更改. 1docker run -d --hostname my-rabbit --name some-rabbit -e RABBITMQ_DEFAULT_USER=user -e RABBITMQ_DEFAULT_PASS=password rabbitmq:3-management 3.设置默认vhost可以使用RABBITMQ_DEFAULT_VHOST来改变vhost 1docker run -d --hostname my-rabbit --name some-rabbit -e RABBITMQ_DEFAULT_VHOST=my_vhost rabbitmq:3-management 4.开启插件 修改dockerfile的方法 12FROM rabbitmq:3.7-managementRUN rabbitmq-plugins enable --offline rabbitmq_mqtt rabbitmq_federation_management rabbitmq_stomp 您还可以在/etc/rabbitmq/enabled_plugins上挂载一个文件，该文件的内容是以英文句号结尾的插件列表名称数组。 例如 1[rabbitmq_federation_management,rabbitmq_management,rabbitmq_mqtt,rabbitmq_stomp]. 5.其他配置其他配置我们可以通过配置文件配置，容器内配置文件地址在/etc/rabbitmq/rabbitmq.conf，文件内容可参考官网在运行的时候，讲写好的配置文件改在到容器内的地址 三、插件上面我们讲到了插件的开启方式，但是对于插件我们怎么安装呢，在rabbitmq中，插件都放在了/plugins文件夹下，所以我们在运行rabbitmq容器时，可以把/plugins文件夹挂在到宿主机上,以及开启插件的文件 1docker run -d --hostname my-rabbit --name some-rabbit -v /home/rabbitmq/plugins:/plugins -v /home/rabbitmq/enabled_plugins:/etc/rabbitmq/enabled_plugins rabbitmq:3-management 例如下载延迟队列 wget https://dl.bintray.com/rabbitmq/community-plugins/3.7.x/rabbitmq_delayed_message_exchange/rabbitmq_delayed_message_exchange-20171201-3.7.x.zip 解压得到文件 rabbitmq_delayed_message_exchange-20171201-3.7.x.ez 然后将下载的插件放入宿主机plugins文件夹下，在enabled_plugins文件中添加插件名称。 rabbitmq_delayed_message_exchange","categories":[{"name":"mq","slug":"mq","permalink":"https://www.icepear.cn/categories/mq/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://www.icepear.cn/tags/RabbitMQ/"},{"name":"docker","slug":"docker","permalink":"https://www.icepear.cn/tags/docker/"}]},{"title":"helm 语法","slug":"k8s/helmgrammar","date":"2019-09-25T12:30:02.000Z","updated":"2020-05-12T08:43:44.978Z","comments":true,"path":"2019/09/25/k8s/helmgrammar/","link":"","permalink":"https://www.icepear.cn/2019/09/25/k8s/helmgrammar/","excerpt":"想要快速的运行管理容器，helm就免不了，但是又不能总是用别人的charts，对于自己的项目肯定需要编写helm模板，所以就有必要学习helm的语法","text":"想要快速的运行管理容器，helm就免不了，但是又不能总是用别人的charts，对于自己的项目肯定需要编写helm模板，所以就有必要学习helm的语法 模版语法表达式123模版表达式： &#123;&#123; 模版表达式 &#125;&#125;模版表达式： &#123;&#123;- 模版表达式 -&#125;&#125; ， 表示去掉表达式输出结果前面和后面的空格，去掉前面空格可以这么写&#123;&#123;- 模版表达式 &#125;&#125;, 去掉后面空格 &#123;&#123; 模版表达式 -&#125;&#125; 变量默认情况点( . ), 代表全局作用域，用于引用全局对象。 例子：这里引用了全局作用域下的Values对象中的key属性。1&#123;&#123; .Values.key &#125;&#125; helm全局作用域中有两个重要的全局对象：Values和Release Values代表的就是values.yaml定义的参数，通过.Values可以引用任意参数。 例子：1&#123;&#123; .Values.replicaCount &#125;&#125; 引用嵌套对象例子，跟引用json嵌套对象类似1&#123;&#123; .Values.image.repository &#125;&#125; Release代表一次应用发布，下面是Release对象包含的属性字段： Release.Name - release的名字，一般通过Chart.yaml定义，或者通过helm命令在安装应用的时候指定。Release.Time - release安装时间Release.Namespace - k8s名字空间Release.Revision - release版本号，是一个递增值，每次更新都会加一Release.IsUpgrade - true代表，当前release是一次更新.Release.IsInstall - true代表，当前release是一次安装例子:1&#123;&#123; .Release.Name &#125;&#125; 除了系统自带的变量，我们自己也可以自定义模版变量。 变量名以$开始命名， 赋值运算符是 := (冒号+等号)1&#123;&#123;- $relname := .Release.Name -&#125;&#125; 引用自定义变量: 不需要 . 引用1&#123;&#123; $relname &#125;&#125; 函数&amp;管道运算符调用函数的语法： 1&#123;&#123; functionName arg1 arg2... &#125;&#125; 例子:调用quote函数，将结果用“”引号包括起来。1&#123;&#123; quote .Values.favorite.food &#125;&#125; 管道（pipelines）运算符 “|” 类似linux shell命令，通过管道 | 将多个命令串起来，处理模版输出的内容。 例子： 将.Values.favorite.food传递给quote函数处理，然后在输出结果。 1&#123;&#123; .Values.favorite.food | quote &#125;&#125; 先将.Values.favorite.food的值传递给upper函数将字符转换成大写，然后专递给quote加上引号包括起来。 1&#123;&#123; .Values.favorite.food | upper | quote &#125;&#125; 如果.Values.favorite.food为空，则使用default定义的默认值 1&#123;&#123; .Values.favorite.food | default &quot;默认值&quot; &#125;&#125; 将.Values.favorite.food输出5次 1&#123;&#123; .Values.favorite.food | repeat 5 &#125;&#125; 对输出结果缩进2个空格 1&#123;&#123; .Values.favorite.food | nindent 2 &#125;&#125; 常用的关系运算符&gt;、 &gt;=、 &lt;、!=、与或非在helm模版中都以函数的形式实现。 关系运算函数定义： eq 相当于 = ne 相当于 != lt 相当于 &lt;= gt 相当于 &gt;= and 相当于 &amp;&amp; or 相当于 || not 相当于 ! 例子:相当于 if (.Values.fooString &amp;&amp; (.Values.fooString == “foo”))123&#123;&#123; if and .Values.fooString (eq .Values.fooString &quot;foo&quot;) &#125;&#125; &#123;&#123; ... &#125;&#125;&#123;&#123; end &#125;&#125; 流程控制语句IF/ELSE语法:12345678910111213&#123;&#123; if 条件表达式 &#125;&#125;#Do something&#123;&#123; else if 条件表达式 &#125;&#125;#Do something else&#123;&#123; else &#125;&#125;#Default case&#123;&#123; end &#125;&#125; 例子:1234567891011apiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-configmapdata: myvalue: &quot;Hello World&quot; drink: &#123;&#123; .Values.favorite.drink | default &quot;tea&quot; | quote &#125;&#125; food: &#123;&#123; .Values.favorite.food | upper | quote &#125;&#125; &#123;&#123;if eq .Values.favorite.drink &quot;coffee&quot;&#125;&#125; mug: true &#123;&#123;end&#125;&#125; withwith主要就是用来修改 . 作用域的，默认 . 代表全局作用域，with语句可以修改.的含义. 语法:123&#123;&#123; with 引用的对象 &#125;&#125;这里可以使用 . (点)， 直接引用with指定的对象&#123;&#123; end &#125;&#125; 例子: .Values.favorite是一个object类型1234&#123;&#123;- with .Values.favorite &#125;&#125;drink: &#123;&#123; .drink | default &quot;tea&quot; | quote &#125;&#125; #相当于.Values.favorite.drinkfood: &#123;&#123; .food | upper | quote &#125;&#125;&#123;&#123;- end &#125;&#125; ps: 不能在with作用域内使用 . 引用全局对象, 如果非要在with里面引用全局对象，可以先在with外面将全局对象复制给一个变量，然后在with内部使用这个变量引用全局对象。 例子:1&#123;&#123;- $release:= .Release.Name -&#125;&#125; #先将值保存起来 123&#123;&#123;- with .Values.favorite &#125;&#125;drink: &#123;&#123; .drink | default &quot;tea&quot; | quote &#125;&#125; #相当于.Values.favorite.drinkfood: &#123;&#123; .food | upper | quote &#125;&#125; 12release: &#123;&#123; $release &#125;&#125; #间接引用全局对象的值&#123;&#123;- end &#125;&#125; rangerange主要用于循环遍历数组类型。 语法: 遍历map类型，用于遍历键值对象 变量$key代表对象的属性名，$val代表属性值 123&#123;&#123;- range $key, $val := 键值对象 &#125;&#125;&#123;&#123; $key &#125;&#125;: &#123;&#123; $val | quote &#125;&#125;&#123;&#123;- end&#125;&#125; 语法：12345&#123;&#123;- range 数组 &#125;&#125;&#123;&#123; . | title | quote &#125;&#125; # . (点)，引用数组元素值。&#123;&#123;- end &#125;&#125; 例子: 1234567891011121314151617181920212223#values.yaml定义 #map类型favorite: drink: coffee food: pizza #数组类型pizzaToppings: - mushrooms - cheese - peppers - onions map类型遍历例子:&#123;&#123;- range $key, $val := .Values.favorite &#125;&#125;&#123;&#123; $key &#125;&#125;: &#123;&#123; $val | quote &#125;&#125;&#123;&#123;- end&#125;&#125; 数组类型遍历例子:&#123;&#123;- range .Values.pizzaToppings&#125;&#125;&#123;&#123; . | quote &#125;&#125;&#123;&#123;- end&#125;&#125; 子模版定义我们可以在_(下划线)开头的文件中定义子模版，方便后续复用。 helm create默认为我们创建了_helpers.tpl 公共库定义文件，可以直接在里面定义子模版，也可以新建一个，只要以下划线开头命名即可。 子模版语法: 12345定义模版&#123;&#123; define &quot;模版名字&quot; &#125;&#125; 模版内容 &#123;&#123; end &#125;&#125;引用模版:&#123;&#123; include &quot;模版名字&quot; 作用域&#125;&#125; 例子: 1234567891011121314#模版定义&#123;&#123;- define &quot;mychart.app&quot; -&#125;&#125;app_name: &#123;&#123; .Chart.Name &#125;&#125;app_version: &quot;&#123;&#123; .Chart.Version &#125;&#125;+&#123;&#123; .Release.Time.Seconds &#125;&#125;&quot;&#123;&#123;- end -&#125;&#125; apiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-configmap labels: &#123;&#123; include &quot;mychart.app&quot; . | nindent 4 &#125;&#125; #引用mychart.app模版内容，并对输出结果缩进4个空格data: myvalue: &quot;Hello World&quot;","categories":[{"name":"k8s","slug":"k8s","permalink":"https://www.icepear.cn/categories/k8s/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://www.icepear.cn/tags/k8s/"},{"name":"helm","slug":"helm","permalink":"https://www.icepear.cn/tags/helm/"}]},{"title":"helm 总结","slug":"k8s/helm","date":"2019-09-20T12:30:02.000Z","updated":"2020-05-12T08:43:44.976Z","comments":true,"path":"2019/09/20/k8s/helm/","link":"","permalink":"https://www.icepear.cn/2019/09/20/k8s/helm/","excerpt":"helm分为helm客户端和tiller服务器。k8s的部署如果用kubectl一个个创建显得太繁琐了；为了让k8s像docker compose一样快速启动一组pod，就有了helm。helm客户端负责chart和release的创建和管理以及和tiller的交互，而tiller服务器则运行在k8s集群中，他负责处理helm客户端的请求，然后转化为 KubeApiServer 的请求跟k8s交互","text":"helm分为helm客户端和tiller服务器。k8s的部署如果用kubectl一个个创建显得太繁琐了；为了让k8s像docker compose一样快速启动一组pod，就有了helm。helm客户端负责chart和release的创建和管理以及和tiller的交互，而tiller服务器则运行在k8s集群中，他负责处理helm客户端的请求，然后转化为 KubeApiServer 的请求跟k8s交互 helmhelm分为helm客户端和tiller服务器。k8s的部署如果用kubectl一个个创建显得太繁琐了；为了让k8s像docker compose一样快速启动一组pod，就有了helm。 helm客户端负责chart和release的创建和管理以及和tiller的交互，而tiller服务器则运行在k8s集群中，他负责处理helm客户端的请求，然后转化为 KubeApiServer 的请求跟k8s交互 chart 是创建一个应用的信息集合，包含各种k8s的对象的配置模板、参数定义、依赖关系、文档说明等 release 是chart 的运行实例，代表了一个正在运行的应用。当chart被安装到k8s集群，就生成了一个release，chart能多次安装到同一个集群，每次安装都是一个release helm 部署客户端下载客户端 下载了之后解压 sudo tar -zxvf helm-v2.16.1-linux-amd64.tar.gz 解压之后放到linux执行目录下，修改权限 sudo cp linux-amd64/helm /usr/local/bin/ sudo chmod a+x /usr/local/bin/helm 输入 helm 显示提示信息则安装成功 安装tiller服务端安装tiller服务器，还需要在机器上配置好kubectl工具和kubeconfig文件，确保kubectl工具可以在这台机器上访问apiserver切正常使用 因为k8s apiserver开启了rbac的访问控制，所以需要创建tiller使用的service account：tiller并分配合适的角色给他，可以查看helm的文档 link 创建clusterRoleBinding123456789101112131415161718apiVersion: v1kind: ServiceAccountmetadata: name: tiller namespace: kube-system---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: tillerroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects: - kind: ServiceAccount name: tiller namespace: kube-system 创建1kubectl create -f rbac-config.yaml 初始化tiller1helm init --service-acount tiller --skip-refresh 这个过程拉取镜像可能有问题，会被墙掉，可以自行去dockerhub中找 gcr.io.kubernetes-helm.tiller:v2.16.1 版本可以通过kubectl describe 看下是什么，要下载对应的 然后通过改tag让容器运行起来1docker tag fishead/gcr.io.kubernetes-helm.tiller:v2.16.1 gcr.io/kubernetes-helm/tiller:v2.16.1 至此helm就安装好了 helm 使用helm 仓库地址 创建chart包当前目录创建一个 myapp chart包1$ helm create myapp 创建完之后，目录结构如下 12345678910myapp - chart 包目录名├── charts - 依赖的子包目录，里面可以包含多个依赖的chart包├── Chart.yaml - chart定义，可以定义chart的名字，版本号信息。├── templates - k8s配置模版目录， 我们编写的k8s配置都在这个目录， 除了NOTES.txt和下划线开头命名的文件，其他文件可以随意命名。│ ├── deployment.yaml│ ├── _helpers.tpl -下划线开头的文件，helm视为公共库定义文件，主要用于定义通用的子模版、函数等，helm不会将这些公共库文件的渲染结果提交给k8s处理。│ ├── ingress.yaml│ ├── NOTES.txt -chart包的帮助信息文件，执行helm install命令安装成功后会输出这个文件的内容。│ └── service.yaml└── values.yaml -chart包的参数配置文件，模版可以引用这里参数。 部署应用通过命令 helm install app文件夹路径1$ helm install /myapp 更新应用通过命令 helm upgrade app名称 app文件夹路径1$ helm upgrade myapp /myapp 删除应用1$ helm delete myapp 但是helm还是会保留已经删除的chart的历史版本，当你重新创建相同名称的chart时，会报错123Error: a release named nacos already exists.Run: helm ls --all nacos; to check the status of the releaseOr run: helm del --purge nacos; to delete it 如果想彻底删除镜像可以使用1$ helm delete --purge myapp","categories":[{"name":"k8s","slug":"k8s","permalink":"https://www.icepear.cn/categories/k8s/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://www.icepear.cn/tags/k8s/"},{"name":"helm","slug":"helm","permalink":"https://www.icepear.cn/tags/helm/"}]},{"title":"k8s 集群调度","slug":"k8s/prodicate","date":"2019-09-15T12:30:02.000Z","updated":"2020-05-12T08:43:44.982Z","comments":true,"path":"2019/09/15/k8s/prodicate/","link":"","permalink":"https://www.icepear.cn/2019/09/15/k8s/prodicate/","excerpt":"因为集群节点性能的不同，所以应用分布也需要针对节点特性进行部署，比如，一些节点cpu性能特别强，可以针对大型计算的应用部署，而一些节点存储是ssd的存储，存储速度很快，可以部署一些索引排序的应用，这就是集群调度的作用","text":"因为集群节点性能的不同，所以应用分布也需要针对节点特性进行部署，比如，一些节点cpu性能特别强，可以针对大型计算的应用部署，而一些节点存储是ssd的存储，存储速度很快，可以部署一些索引排序的应用，这就是集群调度的作用 集群调度因为集群节点性能的不同，所以应用分布也需要针对节点特性进行部署，比如，一些节点cpu性能特别强，可以针对大型计算的应用部署，而一些节点存储是ssd的存储，存储速度很快，可以部署一些索引排序的应用，这就是集群调度的作用。 简介Scheduler 是k8s的调度器，要保证四个特性 公平 资源高效利用 效率 灵活 Scheduler是单独的程序运行的，启动之后会一直监听API Server，获取PodSpec.NodeName 为空的对每个pod都会创建一个binding，表明该pod应该放到那个节点上 调度过程调度分为几个部分： 首先过滤不满足条件的节点，这个过程称为 predicate 然后通过节点按照优先级排序，这个是 priority ；最后从中选择优先级最高的节点。如果中间任何一步有错误，直接返回错误 predicate 有一系列的算法可以使用 PodFitsResources 节点上剩余的资源是否大于pod请求的资源 PodFitsHost 如果pod制定了NodeName，检查节点名称是否匹配 PodFitsHostPorts 节点上已经使用的port是否和pod申请的port冲突 PodSelectorMatches 过滤掉和pod指定的label不匹配的节点 NoDiskConflict 已经mount的volume 和pod指定的volume不冲突，除非他们都是只读 如果在predicate过程中没有合适的节点，pod会一直在pending状态，不断重试调度，如果满足就会继续priorities过程：按照优先级大小对节点排序 优先级由一系列的键值对组成，见识优先级项的名称，值是它的权重，这些优先级选项包括： LeastRequestedPriority 通过计算CPU和Memory的使用率来决定权重，使用率越低权重越高。换句话说就是，优先放到资源使用率低的节点上 BalancedResourceAllocation 节点上CPU和Memory使用率越接近，权重越高。这个一般跟上一个一起使用，不应该单独使用 ImageLocalityPriority 倾向于已经有要使用镜像的节点，镜像总大小值越大，权重越高 亲和性分为节点亲和性和pod的亲和性，而亲和性策略也分为软策略和硬策略，软策略为倾向性，硬策略则为必须满足才行。 节点亲和性123nodeAffinity: preferredDuringSchedulingIgnoredDuringExecution 软策略 requiredDuringSchedulingIgnoredDuringExecution 硬策略 下面看一个requiredDuringSchedulingIgnoredDuringExecution例子：12345678910111213141516171819apiVersion: v1kind: Podmetadata: name: affinity labels: app: node-affinity-podspec: containers: - name: with-node-affinity image: myapp:v1 affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: #匹配规则 - key: kubernetes.io/hostname #规则为主机名 operator: NotIn #条件为NotIn values: #值为下面名称 - k8s-node02 注意nodeSelectorTerms下面有多个选项的话，满足任何一个条件即可，但是如果matchExpressions 有多个选项的话，则必须同时满足这些条件才能正常调度 preferredDuringSchedulingIgnoredDuringExecution例子：1234567891011121314151617181920apiVersion: v1kind: Podmetadata: name: affinity labels: app: node-affinity-podspec: containers: - name: with-node-affinity image: myapp:v1 affinity: nodeAffinity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 1 # 权重，权重越大优先级越大 preference: matchExpressions: #匹配规则 - key: source #规则为一个source的标签 operator: In #条件为In values: #值为下面名称 - saddas 键值运算关系 In label的值在某个列表中 NotIn label的值不在某个列表中 Gt label的值大于某个值 Lt label的值小于某个值 Exists 某个label存在 DoesNotExist 某个label不存在 pod亲和性123podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution 软策略 preferredDuringSchedulingIgnoredDuringExecution 硬策略 例子：1234567891011121314151617181920212223242526272829apiVersion: v1kind: Podmetadata: name: with-pod-affinityspec: affinity: podAffinity: # pod与指定的pod在同一拓扑域 requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: security operator: In values: - S1 topologyKey: failure-domain.beta.kubernetes.io/zone podAntiAffinity: # pod与指定的pod不在同一拓扑域 preferredDuringSchedulingIgnoredDuringExecution: - weight: 100 podAffinityTerm: labelSelector: matchExpressions: - key: security operator: In values: - S2 topologyKey: kubernetes.io/hostname containers: - name: with-pod-affinity image: gcr.io/google_containers/pause:2.0 原则上，topologyKey可以是任意标签，为了性能考虑只允许一些有限的topologyKey，默认情况下，有以下几个： kubernetes.io/hostname failure-domain.beta.kubernetes.io/zone failure-domain.beta.kubernetes.io/region 污点 (Taint)和容忍(Toleration)taint和toleration相互配合使用，可以避免pod被分配到不合适的节点上，每个节点上都可以应用一个或多个taint，这表示那些不能容忍这些taint的pod，不会被该节点运行，如果toleration应用于pod，则表示这些pod可以被调度到具有匹配taint的节点上 污点使用kubectl taint 命令可以给某个Node节点设置污点，node被设置上污点之后就合pod之间存在了一种互斥的关系，可以让node拒绝pod的调度执行，甚至将node已经存在的pod驱逐 污点的形式如下1key=value:effect 而effect有三个选项 NoSchedule 不会调度到具有该污点的node上 PreferNoSchedule 尽量避免调度到具有该污点的node上 NoExecute 不会调度到具有该污点的node上，并且会将node上已经存在的pod驱逐 污点的设置、查看和移除12345678#设置污点$ kubectl taint nodes node1 key1=value1:NoSchedule#节点说明中，查找Taints字段$ kubectl describe pod pod-name# 去除污点$ kubectl taint nodes node1 key1:NoSchedule- 容忍既然污点是针对node，那么容忍则是针对pod。pod如果能容忍污点，那么pod就可以运行 通过 pod.spec.tolerations 配置 例如12345678910toleration: - key:\"key1\" oprator: \"Equal\" value: \"value1\" effect: \"NoSchedule\" tolerationSeconds: 8000 - key:\"key1\" oprator: \"Equal\" value: \"value1\" effect: \"NoExecute\" 其中key，value,effect 要与node上设置的taint保持一致 operator 的值为Exists将会忽略value的值 tolerationSeconds 用于描述当pod需要呗驱逐时可以在pod上继续保留运行的时间 当不指定key时，表示容忍所有的污点key，当不指定effect时，表示容忍所有的污点作用","categories":[{"name":"k8s","slug":"k8s","permalink":"https://www.icepear.cn/categories/k8s/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://www.icepear.cn/tags/k8s/"},{"name":"nodeAffinity","slug":"nodeAffinity","permalink":"https://www.icepear.cn/tags/nodeAffinity/"},{"name":"Taint","slug":"Taint","permalink":"https://www.icepear.cn/tags/Taint/"},{"name":"Toleration","slug":"Toleration","permalink":"https://www.icepear.cn/tags/Toleration/"}]},{"title":"k8s 存储","slug":"k8s/store","date":"2019-09-12T11:30:02.000Z","updated":"2020-05-12T08:43:44.989Z","comments":true,"path":"2019/09/12/k8s/store/","link":"","permalink":"https://www.icepear.cn/2019/09/12/k8s/store/","excerpt":"k8s 存储是一个对于pod的一个外置存储对象，通过pod—&gt;pvc—&gt;pv—&gt;物理存储的一个过程","text":"k8s 存储是一个对于pod的一个外置存储对象，通过pod—&gt;pvc—&gt;pv—&gt;物理存储的一个过程 存储ConfigMap应用程序会从配置文件、命令行参数或者环境变量中读取配置信息。ConfigMap 提供了一个可以向容器注入配置信息的机制。 可以保存单个属性，也可以通过文件创建12345678910111213[node1@localhost ~]$ cat application.yamlserver: port: 8080 undertow: accesslog: dir: enabled: false pattern: common prefix: access_log rotate: true suffix: log [node1@localhost ~]$ kubectl create configmap app-config --from-file=application.yaml –from-file 这个参数可以多次使用，可以使用两次分别指定两个不同的文件 12[node1@localhost ~]$ kubectl create configmap app-config --from-literal=application.server=aaa --from-literal=application.port=80[node1@localhost ~]$ kubectl get configmaps app-config -o yaml –from-literal 可以通过key-value参数配置，使用多次 pod中使用 使用configmap代替环境变量,可以通过env标签变量一一对应，也可以通过envFrom直接引用configmap1234567891011121314151617181920212223242526272829303132333435363738394041apiVersion: v1kind: ConfigMapmetadata: name: app-config namespace: defaultdata: application.server: aaa application.port: 80---apiVersion: v1kind: ConfigMapmetadata: name: env-config namespace: defaultdata: log_level: INFO---apiVersion: v1kind: Podmetadata: name: app1spec: containers: - name: test-container image: ice.com/app1:v1 command: [\"bin/sh\",\"-c\",\"env\"] env: - name: APPLICATION_SERVER valueFrom: configMapKeyRef: name: app-config key: application.server - name: APPLICATION_PORT valueFrom: configMapKeyRef: name: app-config key: application.port envFrom: - configMapRef: name: env-config restartPolicy: Never 可以通过以下命令查看1[node1@localhost ~]$ kubectl describe cm app-config 用configmap设置命令行参数,可以使用 1$(环境变量) 例如 $(APPLICATION_SERVER) 通过数据卷插件 1234567891011121314151617apiVersion: v1kind: Podmetadata: name: app1spec: containers: - name: test-container image: ice.com/app1:v1 command: [\"bin/sh\",\"-c\",\"cat /etc/config/application.server\"] volumeMounts: - name: config-volume mountPath: /etc/config volumes: - name: config-volume configMap: name: app-config restartPolicy: Never configmap 热更新假设现在有一个deployment引用了configmap，可以通过命令1[node1@localhost ~]$ kubectl edit configmap app-config 来对configmap进行修改。需要注意的是deployment中的pod并不会触发更新，重新加载configmap要达到滚动更新可以使用1[node1@localhost ~]$ kubectl patch deployment app1 --patch '&#123;\"spec\":&#123;\"template\":&#123;\"metadata\":&#123;\"annotations\":&#123;\"version/config\":\"20191101\"&#125;&#125;&#125;&#125;&#125;' 这个例子主要是通过 spec.template.metadata.annotations 中添加version/config,每次通过修改version/config 来触发deployment的滚动更新 注意使用configmap挂载的volume中的数据需要大概10秒的时间才能同步更新 SecretSecret解决了密码、token、秘钥等敏感数据的配置问题，使用方式跟configmap类似 Secret有三种类型： Service Account: 由k8s自动创建，并挂在/run/secrets/kuberbetes.io/serviceaccount目录中 Opaque: base64编码格式的Secret，用来存储密码、秘钥等，使用之前要先对明文进行base64加密 如：echo -n “icepear” | base64 kubernetes.io/dockerconfigjson: 用来存储私有docker registry的认证信息,可以通过如下命令创建1kubectl create secret docker-registry ice-harbor --docker-server=reg.icepear.cn --docker-username=admin --docker-password=Harbor123456 --docker-email=a@icepear.cn 然后yaml文件通过imagePullSecrets: - name: ice-harbor 添加认证 VolumeVolume的生命周期跟pod一致 emptyDir 临时空间，创建时为空的目录 容器崩溃时不会删除 样例1234567891011121314apiVersion: v1kind: Podmetadata: name: app1spec: containers: - name: test-container image: ice.com/app1:v1 volumeMounts: - name: cache-volume mountPath: /etc/config volumes: - name: cache-volume emptyDir:&#123;&#125; hostPathhostPath 可以理解为跟docker 的volume挂载方式一样 运行需要访问docker内部的容器，使用 /var/lib/docker 的hostPath 在容器中运行cAdvisor，使用 /dev/cgroups 的hostPath 可以指定type标签 值 行为 空字符串 表示不检查 DirectoryDrCreate 如果在给定的路径上没有任何东西存在，那么将创建一个755权限的空目录 Directory 给定路径下必须存在目录 FileOrCreate 如果在给定的路径上没有任何东西存在，那么将创建一个644权限的空文件 File 给定的路径下必须存在文件 Socket 给定的路径下必须存在UNIX套接字 CharDevice 给定路径下必须存在字符设备 BlockDevice 给定的路径下必须存在块设备 由于每个节点上的文件都不同，具有相同配置的pod在不同节点上的行为可能会有所不同 在底层主机上创建的文件或目录只能由root写入，您需要在特权容器中以root身份运行进程，或修改主机文件或目录的权限供k8s访问写入 样例12345678910111213141516apiVersion: v1kind: Podmetadata: name: app1spec: containers: - name: test-container image: ice.com/app1:v1 volumeMounts: - name: path-volume mountPath: /etc/config volumes: - name: path-volume hostPath: path: /config type: Directory PV-PVCPV也是以插件的形式实现，支持第三方的云商提供的各类插件，也支持本地的存储插件如nfs、hostpath等 PVC则是一种资源规定，定义好之后会按需求自动寻找合适的PV进行存储，也就是说存在这样一种关系：123graph TDPod--&gt;PVCPVC--&gt;PV PV 访问模式 ReadWriteOnce（RWO）单节点读/写模式挂载 ReadOnlyMany（ROX）多节点只读模式挂载 ReadWriteMany（RWX）多节点读/写模式挂载 回收策略 Retain（保留）手动回收 Recycle（回收）基本擦除 Delete（删除）关联的存储资产将被删除 只有NFS和HostPath支持回收策略，AWS EBS、GCE PD、Azure Disk支持删除策略 状态 Available(可用) 一块空闲资源还没有被任何声明绑定 Bound(已绑定) 卷已被绑定 Released(已释放) 声明被删除，但是资源还没有被集群重新声明 Failed(失败) 自动回收失效 nfs服务器创建 服务端安装nfs，启动服务 12345678910#安装服务yum install -y nfs-common nfs-utils rpcbind #启动服务systemctl start rpcbindsystemctl start nfs#开机自启systemctl enable rpcbindsystemctl enable nfs 服务端配置 1234567891011#创建文件mkdir /datachmod 755 /datachown -R nfsnobody:nfsnobody /data#配置/etc/exportsvi /etc/exports#写入配置/data *(rw,sync,all_squash,no_root_squash)#执行后 使配置生效exportfs -r nfs配置文件的格式： NFS共享的目录 NFS客户端地址（参1，参2，……） NFS客户端地址2（参1，参2，……） NFS共享的目录 NFS客户端地址（参1，参2，……） 客服端安装启动服务 12#安装服务yum install -y nfs-utils rpcbind 客户端简单使用 1234#查看nfs服务器共享目录 showmount -e nfs服务器IPshowmount -e 192.168.110.11#挂载至本机目录 mount -t nfs 服务器IP:/目录 本机目录mount -t nfs 192.168.110.11::/data /test PV、PVC 样例123456789101112131415161718apiVersion: v1kind: PersistentVolumemetadata: name: redis-pvspec: capacity: storage: 10Gi volumeMode: Filesystem accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Recycle storageClassName: slow #存储类名称，划分存储类指标 mountOptions: - hard - nfsvers=4.1 nfs: path: /temp server: 192.168.110.15 pv 扩容在kubernetes 1.11版本中开始支持pvc创建后的扩容 storageclass可以根据pvc自动创建pv，所以在创建storageclass时，需要添加参数 例如1234567891011121314apiVersion: storage.k8s.io/v1kind: StorageClassmetadata: name: glusterfs-scparameters: clusterid: 075e35a0ce70274b3ba7f158e77edb2c resturl: http://172.16.9.201:8087 volumetype: replicate:3provisioner: kubernetes.io/glusterfsreclaimPolicy: DeletevolumeBindingMode: ImmediateallowVolumeExpansion: true # 重要","categories":[{"name":"k8s","slug":"k8s","permalink":"https://www.icepear.cn/categories/k8s/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://www.icepear.cn/tags/k8s/"},{"name":"configmap","slug":"configmap","permalink":"https://www.icepear.cn/tags/configmap/"},{"name":"nfs","slug":"nfs","permalink":"https://www.icepear.cn/tags/nfs/"},{"name":"volumes","slug":"volumes","permalink":"https://www.icepear.cn/tags/volumes/"}]},{"title":"k8s service访问控制","slug":"k8s/service","date":"2019-08-09T14:30:08.000Z","updated":"2020-05-12T08:43:44.984Z","comments":true,"path":"2019/08/09/k8s/service/","link":"","permalink":"https://www.icepear.cn/2019/08/09/k8s/service/","excerpt":"kubernetes Service 定义了一个抽象层：用来管理Pod的逻辑分组，外部访问service即可以访问Pod的策略，pod和service通过Label Selector连接","text":"kubernetes Service 定义了一个抽象层：用来管理Pod的逻辑分组，外部访问service即可以访问Pod的策略，pod和service通过Label Selector连接 servicekubernetes Service 定义了一个抽象层：用来管理Pod的逻辑分组，外部访问service即可以访问Pod的策略，pod和service通过Label Selector连接 Service提供了负载均衡的能力，但只能提供4层的负载能力，不支持7层，可以借助ingress实现 service 类型 ClusterIp： 默认类型，自动分配一个可供集群内部访问的ip NodePort：在ClusterIp的基础上为service在每台机器上绑定一个端口，供外部访问。 LoadBalance：在Nodeport的基础上，借助cloud provider创建一个外部负载均衡器，并将请求转发到节点端口上，这个是第三方提供的收费方案，像阿里云、AWS等 ExternalName：把集群外部的服务引入到集群内部来，在集群内部即可使用外部的服务。假如外部服务地址发生变化，也只需要更新externalName的service，而不要更新集群内部的pod。 service实现原理 service代理模式分类userspace —-&gt; iptables —-&gt; ipvs III ipvs 代理模式 与iptables；类似，ipvs基于netfilter的hook功能，但使用哈希表作为底层数据接口并在内核中工作，这意味着ipvs可以更快的重定向流量，此外ipvs为负载均衡算法提供了更多选项 rr 轮询调度 lc 最小连接数 dh 目标哈希 sh 源哈希 sed 最短期望延迟 nq 不排队调度 需要注意的是节点上必须安装了 IPVS 内核模块，如果节点未安装，kube-proxy默认会退级采用iptables的方式 service 样例 首先创建一个deployment 1234567891011121314151617181920212223apiVersion: apps/v1kind: Deploymentmetadata: name: myNginx labels: app: myNginxspec: replicas: 3 template: metadata: name: myNginx labels: app: myNginx version: 1.7.9 spec: containers: - name: myNginx image: nginx:1.7.9 imagePullPolicy: IfNotPresent restartPolicy: Always selector: matchLabels: app: myNginx 创建NodePort service映射到deployment的pod上,根据selector对应 1234567891011apiVersion: v1kind: Servicemetadata: name: ngServicespec: selector: app: myNginx version: 1.7.9 ports: - port: 80 type: NodePort 创建ExternalName service 1234567apiVersion: v1kind: Servicemetadata: name: myServicespec: type: ExternalName externalName: hub.icepear.cn 这个svc创建之后就会有一个myService.defalut.svc.cluster.local的名称出现，内部只需要访问myService.defalut.svc.cluster.local，到时候就会转发到对应的ExternalName的域名上。 service跟pod的关系是多对多 ipvs可以通过 ipvsadm -Ln 查看路由规则，iptables则通过 iptables -t nat -nvL service ingressIngress-Nginx 官网 HTTP代理样例:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950apiVersion: apps/v1kind: Deploymentmetadata: name: myApp labels: app: myAppspec: replicas: 3 template: metadata: name: myApp labels: app: myApp spec: containers: - name: myApp image: icepear/myApp:v1 imagePullPolicy: IfNotPresent ports: - containerPort: 80 restartPolicy: Always selector: matchLabels: app: myApp---apiVersion: v1kind: Servicemetadata: name: ngServicespec: selector: app: myApp ports: - port: 80 targetPort: 80 protocol: TCP type: NodePort---apiVersion: extensions/v1beta1kind: Ingressmetadata: name: my-Ingressspec: rules: - host: a.ice.com http: paths: / - backend: serviceName: ngService servicePort: 80 HTTPS 代理样例 创建证书，以及cert存储方式 123openssl req -x509 -sha256 -nodes -day 365 -newkey rsa:2048 -keyout tls.key -out tls.crt -subj \"/CN=nginxsvc/O=nginxsvc\"kubectl create secret tls tls-secret --key tls.key --cert tls.crt 样例文件 12345678910111213141516apiVersion: extensions/v1beta1kind: Ingressmetadata: name: my-Ingressspec: tls: - hosts: - a.ice.com secretName: tls-secret rules: - host: a.ice.com http: paths: / - backend: serviceName: ngService servicePort: 80","categories":[{"name":"k8s","slug":"k8s","permalink":"https://www.icepear.cn/categories/k8s/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://www.icepear.cn/tags/k8s/"}]},{"title":"k8s 控制器","slug":"k8s/deployment","date":"2019-08-05T11:30:02.000Z","updated":"2020-05-12T08:43:44.972Z","comments":true,"path":"2019/08/05/k8s/deployment/","link":"","permalink":"https://www.icepear.cn/2019/08/05/k8s/deployment/","excerpt":"k8s中内置的控制器相当于一个状态机，用来控制Pod的具体状态和行为","text":"k8s中内置的控制器相当于一个状态机，用来控制Pod的具体状态和行为 控制器定义k8s中内置的控制器相当于一个状态机，用来控制Pod的具体状态和行为 控制器类型 ReplicationController 和 ReplicaSet Deployment DaemonSet StateFulSet Job/CronJob Horizontal Pod Autoscaling RC和RSRC目前不太采用，都采用RS方式。 RC用来控制pod维持一个正常稳定的数量 RS支持集合式的selector，可以根据标签匹配 样例：1234567891011121314151617181920apiVersion: apps/v1kind: ReplicaSetmetadata: name: myRSspec: selector: matchLabels: auth: myAuth replicas: 3 template: metadata: labels: auth: myAuth spec: containers: - name: myAuth image: icepear/dendalion-auth:2.0.0 imagePullPolicy: IfNotPresent ports: - containerPort: 8080 Deployment提供声明式的定义方法，用来替代RC 定义deployment来创建pod和replicaSet 提供滚动升级和回滚应用 扩容和缩容 暂停和继续 deployment deployment跟replicaSet以及pod的关系 声明式的创建建议要用kubectl apply····,不要使用kubectl create···–record参数可以记录命令，可以方便查看每次reversion的变化 1. 部署简单的应用样例：12345678910111213141516171819202122apiVersion: apps/v1kind: Deploymentmetadata: name: myNginx labels: app: myNginxspec: replicas: 3 template: metadata: name: myNginx labels: app: myNginx spec: containers: - name: myNginx image: nginx:1.7.9 imagePullPolicy: IfNotPresent restartPolicy: Always selector: matchLabels: app: myNginx 2. 扩容样例：1kubectl scale deployment myNginx --replicas=10 3.集群如果支持HPA，还可以1kubecl autoscale deployment myNginx --min=10 --max=15 --cpu-percent=80 4.更新镜像1kubectl set image deployment/myNginx nginx:1.8.0 25%-25%的策略，首先会在新的replicas中新建25%，旧的replicas中删除25%。按照这种规律更新 rollover 策略，当还在创建的时候就更新新的版本，deployment会直接干掉之前创建的rs，直接生成新的 5.版本回滚1234567kubectl rollout undo deployment/myNginx --to-version=2 #回滚操作，设置回退的版本号kubectl rollout status deployment myNginx #查看回滚状态kubectl rollout history deployment/myNginx #查看历史版本信息kubectl rollout pause deployment/myNginx #暂停回滚更新 DaemonSetDaemonSet确保全部node上运行一个pod的副本,新增或删除node时,node上对应的pod也会被新增或删除,删除DaemonSet将删除它创建的pod 运行集群存储daemon,例如在每个node上运行glusterd、ceph 在每个node上运行日志收集daemon、例如logstash、fluentd 在每个node上运行监控daemon、例如Promethenus node exporter 创建使用kubectl create JobJob负责批处理任务，可以理解为就是用来运行脚本的控制器 spec.template格式同pod RestartPolicy仅支持Never或Onfailure 单个Pod时，默认Pod成功运行后Job即结束 spec.completions 标志job结束需要成功运行的Pod个数，默认为1 spec.parallelism 标志并行运行的Pod的个数，默认为1 spec.activeDeadlineSeconds 标志失败Pod的重试最大时间，超过不再重试 例如:创建一个使用perl语言，计算圆周率打印2000位1234567891011121314apiVersion: batch/v1kind: Jobmetadata: name: pispec: template: metadata: name: pi spec: containers: - name: pi image: perl command: [\"perl\", \"-Mbignum=bpi\", \"-wle\", \"print bpi(2000)\"] restartPolicy: Never CronJob在Job的基础上，提供了定时执行，周期执行的方案 spec.schedule 运行周期，格式采用Cron spec.jobTemplate Job模板，格式采用Job spec.startingDeadlineSeconds 启动Job的期限，秒 spec.concurrencyPolicy 并发策略,因为有可能在第一个job没完成的时候，第二个job又被创建了，就会形成并发 Allow 允许 Firbid 禁止 Replace 取消当前的，用新的替换 sper.suspend 挂起 spec.successfulJobHistoryLimit和failedJobsHistoryLimit 设置job成功或失败的保留的pod数，默认成功是3个，失败是1个 例子：123456789101112131415161718apiVersion: batch/v1kind: CronJobmetadata: name: myCronjobspec: schedule: \"*/1 * * * *\" jobTemplate: spec: template: spec: containers: - name: myCronjob image: busybox args: - /bin/sh - -c - date; echo Hello k8s restartPolicy: OnFailure CronJob 运行的结果应该是幂等的，就是每次运行的结果应该一样 StateFulSetStateFulSet解决了有状态的服务运行的问题 稳定的持久化存储，即pod重新调度之后依然能访问到相同的持久化数据，基于PVC实现 稳定的网络标志，即pod重新调度之后，podName和HostName不变，基于Headless service实现 有序部署，有序扩展，pod启动是有序的，依据顺序依次进行，只有前一个pod启动成功之后，下面才能继续进行 有序收缩，有序删除，从后往前删除 HPA用于pod的自动扩展，在高峰时扩容，低谷时删除一些资源，提高系统稳定性","categories":[{"name":"k8s","slug":"k8s","permalink":"https://www.icepear.cn/categories/k8s/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://www.icepear.cn/tags/k8s/"},{"name":"deployment","slug":"deployment","permalink":"https://www.icepear.cn/tags/deployment/"},{"name":"StateFulSet","slug":"StateFulSet","permalink":"https://www.icepear.cn/tags/StateFulSet/"}]},{"title":"k8s 基础定义","slug":"k8s/k8sbase","date":"2019-08-01T13:30:00.000Z","updated":"2020-05-12T08:43:44.980Z","comments":true,"path":"2019/08/01/k8s/k8sbase/","link":"","permalink":"https://www.icepear.cn/2019/08/01/k8s/k8sbase/","excerpt":"kubernetes是一个开源的，用于管理云平台中多个主机上的容器化的应用，Kubernetes的目标是让部署容器化的应用简单并且高效（powerful）,Kubernetes提供了应用部署，规划，更新，维护的一种机制。Kubernetes一个核心的特点就是能够自主的管理容器来保证云平台中的容器按照用户的期望状态运行着（比如用户想让apache一直运行，用户不需要关心怎么去做，Kubernetes会自动去监控，然后去重启，新建，总之，让apache一直提供服务），管理员可以加载一个微型服务，让规划器来找到合适的位置，同时，Kubernetes也系统提升工具以及人性化方面，让用户能够方便的部署自己的应用（就像canary deployments）。","text":"kubernetes是一个开源的，用于管理云平台中多个主机上的容器化的应用，Kubernetes的目标是让部署容器化的应用简单并且高效（powerful）,Kubernetes提供了应用部署，规划，更新，维护的一种机制。Kubernetes一个核心的特点就是能够自主的管理容器来保证云平台中的容器按照用户的期望状态运行着（比如用户想让apache一直运行，用户不需要关心怎么去做，Kubernetes会自动去监控，然后去重启，新建，总之，让apache一直提供服务），管理员可以加载一个微型服务，让规划器来找到合适的位置，同时，Kubernetes也系统提升工具以及人性化方面，让用户能够方便的部署自己的应用（就像canary deployments）。 集群资源分类名称空间级别 工作负载型资源：Pod、ReplicaSet、Deployment、StatefulSet、DaemonSet、Job、CronJob 服务发现及负载均衡型资源：Service、Ingress 配置与存储型资源：Volume、CSI(容器存储接口，可以扩展各种第三方存储卷) 特殊类型的存储卷：ConfigMap(当配置中心来使用的资源类型)、Secret(保存敏感数据)、DownwardAPI(把外部环境中的信息输出给容器) 集群级别资源 Namespace Node Role ClusterRole RoleBinding ClusterRolebinding 原数据型资源 HPA PodTemplate(pod模板) LimitRange(资源限制) 资源清单YAML定义，常用字段12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788version: v1 #代表k8s api接口的版本，通常是执行各种命令调用接口的资源路径，可以用kubectl api-versions 查询apiVerion: 1.0 #版本号kind: deployment #资源类型 pod/deployment/servicemetadata: #object 元数据对象 name: mydeployment #string 元数据对象名称 如Pod的名字等 namespace: test #string 元数据的命名空间，指的是资源所处的命名空间,默认default下spec: #object 详细的定义资源对象 replicas: 5 #pods的副本数量 strategy: #object #将现有pod替换为新pod的部署策略 rollingUpdate: #Object 滚动更新配置参数，仅当类型为RollingUpdate maxSurge: 3 #滚动更新过程产生的最大pod数量，可以是个数，也可以是百分比 maxUnavailable: 2 #滚动更新过程减少的最大pod数量，可以是个数，也可以是百分比 type: RollingUpdate #部署类型，Recreate，RollingUpdate revisionHistoryLimit: 5 #设置保留的历史版本个数，默认是10 rollbackTo: revision: 0 #设置回滚的版本，设置为0则回滚到上一个版本 selector: #pod标签选择器，匹配pod标签，默认使用pods的标签 matchLabels: key1: value1 key2: value2 matchExpressions: operator: In #设定标签键与一组值的关系，In, NotIn, Exists and DoesNotExist key: key1 values: va template: #pod模板 metadata: spec: containers: # 容器配置 - name: # 名称 image: # 镜像 imagePullPolicy: IfNotPresent #镜像拉取策略 Always、Never、IfNotPresent command: #容器的启动命令列表，如不指定，使用打包时使用的启动命令 args: #容器的启动命令参数列表 workingDir: #容器的工作目录 ports: - name: #定义端口名 containerPort: #容器暴露的端口 hostPort: #容器所在主机需要监听的端口号，默认与Container相同 protocol: #TCP UDP 协议 volumeMounts: - name: #设置卷名称 mountPath: #设置需要挂在容器内的路径 readOnly: #设置是否只读 env: - name: # 环境变量名称 value: # 环境变量的值 readnessProde: #就绪检测 exec: command: livenessProbe: #对Pod内个容器健康检查的设置，当探测无响应几次后将自动重启该容器，检查方法有exec、httpGet和tcpSocket，对一个容器只需设置其中一种方法即可 exec: # 对 pod 容器内检查方式设置为exec方式 command: # 执行命令或者脚本 httpGet: # http检测，200-400之间为成功 path: #请求路径 port: #端口 host: #ip scheme: # HttpHeaders: #请求头 - name: #键 value: #值 tcpSocket: #tcp方式检测,检测端口是否通的 port: #端口 initialDelaySeconds: 0 #容器启动完成后首次探测的时间，单位为秒 timeoutSeconds: 10 #对容器健康检查探测等待响应的超时时间，单位秒，默认1秒 periodSeconds: 3600 #对容器监控检查的定期探测时间设置，单位秒，默认10秒一次 successThreshold: 1 # 连续成功几次认定为成功，默认一次 failureThreshold: 3 # 连续失败几次认定为失败，默认三次 restartPolicy: Always #Pod的重启策略，Always表示一旦不管以何种方式终止运行，kubelet都将重启，OnFailure表示只有Pod以非0退出码退出才重启，Nerver表示不再重启该Pod nodeSelector: &lt;map[string]string&gt; #设置NodeSelector表示将该Pod调度到包含这个label的node上，以key：value的格式指定 hostNetwork:false #是否使用主机网络模式，默认为false，如果设置为true，表示使用宿主机网络 volumes: #数据卷配置 - name: #设置卷名称,与volumeMounts名称对应 hostPath: #设置挂载宿主机路径 path: #路径 type: #类型：DirectoryOrCreate、Directory、FileOrCreate、File、Socket、CharDevice、BlockDevice - name: nfs nfs: #设置NFS服务器 server: #设置NFS服务器地址 path: #设置NFS服务器路径 readOnly: false #设置是否只读 - name: configmap configMap: name: #configmap名称 defaultMode: 664 #权限设置0~0777，默认0664 optional: false #指定是否必须定义configmap或其keys items: - key: asc path: /home/sad pod生命周期","categories":[{"name":"k8s","slug":"k8s","permalink":"https://www.icepear.cn/categories/k8s/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://www.icepear.cn/tags/k8s/"}]},{"title":"mysql 事务解析","slug":"mysql/transaction","date":"2019-06-20T12:30:00.000Z","updated":"2020-05-12T08:43:44.999Z","comments":true,"path":"2019/06/20/mysql/transaction/","link":"","permalink":"https://www.icepear.cn/2019/06/20/mysql/transaction/","excerpt":"最近mysql碰到一个问题，用Navicat插入数据之后，界面上可以看到数据。应用死活查不到数据，期初怀疑是不是锁表了，后面查看锁的情况发现并没有锁表的情况。后面考虑到可能是事务的问题，由于我改过配置文件，我仔细排查一番果然发现，我把autocommit设置为了0，也就是必须要commit才能提交事务。所以干脆把mysql整个事务情况都记录一下。","text":"最近mysql碰到一个问题，用Navicat插入数据之后，界面上可以看到数据。应用死活查不到数据，期初怀疑是不是锁表了，后面查看锁的情况发现并没有锁表的情况。后面考虑到可能是事务的问题，由于我改过配置文件，我仔细排查一番果然发现，我把autocommit设置为了0，也就是必须要commit才能提交事务。所以干脆把mysql整个事务情况都记录一下。 mysql 事务事务是数据库操作的最小工作单元，是作为单个逻辑工作单元执行的一系列操作；这些操作作为一个整体一起向系统提交，要么都执行、要么都不执行；事务是一组不可再分割的操作集合 事务的ACID特性 Atomicity 原子性 就像事务的定义一样，要么一起执行，要么都不执行，是最小的操作单元；中间任何一个操作出错，之前的操作都会被取消。 Consistency 一致性 一致性是指事务操作通过AID的特性，保证了事务在执行后，依然满足约束；例如张三账户有90元，要转给李四100元，数据库约束余额不能小于0，所以这个事务必然执行不成功，应为没满足约束。 Isolation 隔离性 隔离性主要有两个特性 在一个事务执行过程中，数据的中间的(可能不一致)状态不应该被暴露给所有的其他事务。 两个并发的事务应该不能操作同一项数据。数据库管理系统通常使用锁来实现这个特征。 Durability 持久性 一个被完成的事务的最后结果应该是持久的。 隐式事务和显式事务mysql配置中有autocommit这一项，默认为1，开启自动提交，也就是隐式事务 针对SELECT、UPDATE、DELETE、INSERT等DQL及DML语句的执行，mysql会自动提交该事务，如果关闭就需要手动提交或者回滚来完成操作。 显示事务是指 设置autocommit = 0，在事务操作中，必须要有明显的开启或结束的标签 123[START TRANSACTION] # 可选的语句[DELETE | UPDATE | INSERT | SELECT ] # DML、DQL操作[COMMIT | ROLLBACK]; #提交或者回滚 在显式事务中还存在回滚点的用法 12345START TRANSACTION;[DELETE | UPDATE | INSERT | SELECT]; #回滚时要执行提交的部分SAVEPOINT a; # 设置回滚点，且变量名为a[DELETE | UPDATE | INSERT | SELECT]; #回滚时不执行提交的部分ROLLBACK TO a; # 回滚时与ROLLBACK TO搭配使用 回滚点之前的操作会被commit，而回滚点之后的操作会被rollback 事务隔离级别事务的隔离级别分为四种，隔离级别从左至右递增1234graph LRREAD-UNCOMMITTED--&gt;READ-COMMITTEDREAD-COMMITTED--&gt;REPEATABLE-READ默认REPEATABLE-READ默认--&gt;SERIALIZABLE 不同隔离级别所解决的事务并发问题 隔离级别/解决问题 脏读 不可重复读 幻读 READ UNCOMMITTED 1 1 1 READ COMMITTED 0 1 1 REPEATABLE READ 0 0 1 SERIALIZABLE 0 0 0 1. READ UNCOMMITTED 其隔离性最低，会出现脏读、不可重复读、幻读等所有情况。 2. READ COMMITTED级别能够避免脏读 脏读是指对于两个事务T1与T2，T1读取了已经被T2更新但是还没有提交的字段之后，若此时T2回滚，T1读取的内容就是临时并且无效的 3. REPEATABLE-READ避免不可重复读 不可重复读是指对于两个事务T1和T2，T1读取了一个字段，然后T2更新了该字段并提交之后，T1再次提取同一个字段，值便不相等了。 4. SERIALIZABLE避免幻读 幻读是指对于两个事务T1和T2，T1读取了一个字段，然后T2插入了新字段并提交之后，T1再次提取，结果不一致了。 注：不可重复读跟幻读最主要的区别是，不可重复读针对的是某一条记录产生了更新的情况，导致同一记录两次读取结果不相等。而幻读是指有新数据插入，导致两次查询整个结果不一致的情况 隔离级别的实现都是基于mysql存储引擎内部的锁实现，目前只有InnoDB支持事务，后期再讲一下InnoDB锁相关的知识","categories":[{"name":"mysql","slug":"mysql","permalink":"https://www.icepear.cn/categories/mysql/"}],"tags":[{"name":"transaction","slug":"transaction","permalink":"https://www.icepear.cn/tags/transaction/"}]},{"title":"Hystrix 熔断器","slug":"springcloud/hystrix","date":"2019-01-20T12:30:02.000Z","updated":"2020-05-12T09:37:11.135Z","comments":true,"path":"2019/01/20/springcloud/hystrix/","link":"","permalink":"https://www.icepear.cn/2019/01/20/springcloud/hystrix/","excerpt":"在微服务场景中，通常会有很多层的服务调用。如果一个底层服务出现问题，故障会被向上传播给用户。我们需要一种机制，当底层服务不可用时，可以阻断故障的传播。这就是断路器的作用。他是系统服务稳定性的最后一重保障。在springcloud中断路器组件就是Hystrix。Hystrix也是Netflix套件的一部分。他的功能是，当对某个服务的调用在一定的时间内（默认10s，由metrics.rollingStats.timeInMilliseconds配置），有超过一定次数（默认20次，由circuitBreaker.requestVolumeThreshold参数配置）并且失败率超过一定值（默认50%，由circuitBreaker.errorThresholdPercentage配置），该服务的断路器会打开。返回一个由开发者设定的fallback","text":"在微服务场景中，通常会有很多层的服务调用。如果一个底层服务出现问题，故障会被向上传播给用户。我们需要一种机制，当底层服务不可用时，可以阻断故障的传播。这就是断路器的作用。他是系统服务稳定性的最后一重保障。在springcloud中断路器组件就是Hystrix。Hystrix也是Netflix套件的一部分。他的功能是，当对某个服务的调用在一定的时间内（默认10s，由metrics.rollingStats.timeInMilliseconds配置），有超过一定次数（默认20次，由circuitBreaker.requestVolumeThreshold参数配置）并且失败率超过一定值（默认50%，由circuitBreaker.errorThresholdPercentage配置），该服务的断路器会打开。返回一个由开发者设定的fallback 如何使用如何使用就不多废话，直接官网加上springboot，几分钟就会了，主要介绍下面的一些参数的作用才是最有效的 参数详解hystrix.command.default 其实对应的是 hystrix.command.commandkey,commandkey 用于定义command hystrix.threadpool.default 其实对应的是 hystrix.command.threadpoolkey Command PropertiesExecution相关的属性的配置 hystrix.command.default.execution.isolation.strategy 隔离策略，默认是Thread, 可选Thread｜Semaphore hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds 命令执行超时时间，默认1000ms hystrix.command.default.execution.timeout.enabled 执行是否启用超时，默认启用true hystrix.command.default.execution.isolation.thread.interruptOnTimeout 发生超时是是否中断，默认true hystrix.command.default.execution.isolation.semaphore.maxConcurrentRequests 最大并发请求数，默认10，该参数当使用ExecutionIsolationStrategy.SEMAPHORE策略时才有效。如果达到最大并发请求数，请求会被拒绝。理论上选择semaphoresize的原则和选择thread size一致，但选用semaphore时每次执行的单元要比较小且执行速度快（ms级别），否则的话应该用thread。semaphore应该占整个容器（tomcat）的线程池的一小部分。 Fallback相关的属性这些参数可以应用于Hystrix的THREAD和SEMAPHORE策略 hystrix.command.default.fallback.isolation.semaphore.maxConcurrentRequests 如果并发数达到该设置值，请求会被拒绝和抛出异常并且fallback不会被调用。默认10 hystrix.command.default.fallback.enabled 当执行失败或者请求被拒绝，是否会尝试调用hystrixCommand.getFallback() 。默认true Circuit Breaker相关的属性 hystrix.command.default.circuitBreaker.enabled 用来跟踪circuit的健康性，如果未达标则让request短路。默认true hystrix.command.default.circuitBreaker.requestVolumeThreshold 一个rolling window内最小的请求数。如果设为20，那么当一个rollingwindow的时间内（比如说1个rolling window是10秒）收到19个请求，即使19个请求都失败，也不会触发circuit break。默认20 hystrix.command.default.circuitBreaker.sleepWindowInMilliseconds 触发短路的时间值，当该值设为5000时，则当触发circuit break后的5000毫秒内都会拒绝request，也就是5000毫秒后才会关闭circuit。默认5000 hystrix.command.default.circuitBreaker.errorThresholdPercentage错误比率阀值，如果错误率&gt;=该值，circuit会被打开，并短路所有请求触发fallback。默认50 hystrix.command.default.circuitBreaker.forceOpen 强制打开熔断器，如果打开这个开关，那么拒绝所有request，默认false hystrix.command.default.circuitBreaker.forceClosed 强制关闭熔断器 如果这个开关打开，circuit将一直关闭且忽略circuitBreaker.errorThresholdPercentage Metrics相关参数 hystrix.command.default.metrics.rollingStats.timeInMilliseconds 设置统计的时间窗口值的，毫秒值，circuit break 的打开会根据1个rolling window的统计来计算。若rolling window被设为10000毫秒，则rolling window会被分成n个buckets，每个bucket包含success，failure，timeout，rejection的次数的统计信息。默认10000 hystrix.command.default.metrics.rollingStats.numBuckets 设置一个rolling window被划分的数量，若numBuckets＝10，rolling window＝10000，那么一个bucket的时间即1秒。必须符合rolling window % numberBuckets == 0。默认10 hystrix.command.default.metrics.rollingPercentile.enabled 执行时是否enable指标的计算和跟踪，默认true hystrix.command.default.metrics.rollingPercentile.timeInMilliseconds 设置rolling percentile window的时间，默认60000 hystrix.command.default.metrics.rollingPercentile.numBuckets 设置rolling percentile window的numberBuckets。逻辑同上。默认6 hystrix.command.default.metrics.rollingPercentile.bucketSize 如果bucket size＝100，window＝10s，若这10s里有500次执行，只有最后100次执行会被统计到bucket里去。增加该值会增加内存开销以及排序的开销。默认100 hystrix.command.default.metrics.healthSnapshot.intervalInMilliseconds 记录health 快照（用来统计成功和错误率）的间隔，默认500ms Request Context 相关参数 hystrix.command.default.requestCache.enabled 默认true，需要重载getCacheKey()，返回null时不缓存 hystrix.command.default.requestLog.enabled 记录日志到HystrixRequestLog，默认true Collapser Properties 相关参数 hystrix.collapser.default.maxRequestsInBatch 单次批处理的最大请求数，达到该数量触发批处理，默认Integer.MAX_VALUE hystrix.collapser.default.timerDelayInMilliseconds 触发批处理的延迟，也可以为创建批处理的时间＋该值，默认10 hystrix.collapser.default.requestCache.enabled 是否对HystrixCollapser.execute() and HystrixCollapser.queue()的cache，默认true ThreadPool 相关参数线程数默认值10适用于大部分情况（有时可以设置得更小），如果需要设置得更大，那有个基本得公式可以follow： 123456789101112requests per second at peak when healthy × 99th percentile latency in seconds + some breathing room每秒最大支撑的请求数 (99%平均响应时间 + 缓存值)比如：每秒能处理1000个请求，99%的请求响应时间是60ms，那么公式是：（0.060+0.012）基本的原则是保持线程池尽可能小，他主要是为了释放压力，防止资源被阻塞。当一切都是正常的时候，线程池一般仅会有1到2个线程激活来提供服务 hystrix.threadpool.default.coreSize 并发执行的最大线程数，默认10 hystrix.threadpool.default.maxQueueSize BlockingQueue的最大队列数，当设为－1，会使用SynchronousQueue，值为正时使用LinkedBlcokingQueue。该设置只会在初始化时有效，之后不能修改threadpool的queue size，除非reinitialising thread executor。默认－1。 hystrix.threadpool.default.queueSizeRejectionThreshold 即使maxQueueSize没有达到，达到queueSizeRejectionThreshold该值后，请求也会被拒绝。因为maxQueueSize不能被动态修改，这个参数将允许我们动态设置该值。if maxQueueSize == -1，该字段将不起作用 hystrix.threadpool.default.keepAliveTimeMinutes 如果corePoolSize和maxPoolSize设成一样（默认实现）该设置无效。如果通过(plugin)[https://github.com/Netflix/Hystrix/wiki/Plugins]使用自定义实现，该设置才有用，默认1.","categories":[{"name":"springcloud","slug":"springcloud","permalink":"https://www.icepear.cn/categories/springcloud/"}],"tags":[{"name":"Hystrix","slug":"Hystrix","permalink":"https://www.icepear.cn/tags/Hystrix/"}]},{"title":"TCP连接及传输","slug":"network/tcp_connect","date":"2018-08-09T11:30:02.000Z","updated":"2020-03-20T07:58:06.220Z","comments":true,"path":"2018/08/09/network/tcp_connect/","link":"","permalink":"https://www.icepear.cn/2018/08/09/network/tcp_connect/","excerpt":"OSI七层协议模型主要是：应用层、表示层、会话层、传输层、网络层、数据链路层、物理层。每层都有对应的协议，在传输层主要是TCP、UDP协议，然后通过网络层的IP协议进行网络传输","text":"OSI七层协议模型主要是：应用层、表示层、会话层、传输层、网络层、数据链路层、物理层。每层都有对应的协议，在传输层主要是TCP、UDP协议，然后通过网络层的IP协议进行网络传输 网络结构 TCP协议报文 tcp报文格式如上图所示，主要解释一下首部，因为数据部分主要是应用层协议直接包装的，如下图 字段 含义 URG 紧急指针是否有效。为1，表示某一位需要被优先处理 ACK 确认号是否有效，一般置为1。 PSH 提示接收端应用程序立即从TCP缓冲区把数据读走。 RST 对方要求重新建立连接，复位。 SYN 请求建立连接，并在其序列号的字段进行序列号的初始值设定。建立连接，设置为1 FIN 希望断开连接。 序列号seq：占4个字节，用来标记数据段的顺序，TCP把连接中发送的所有数据字节都编上一个序号，第一个字节的编号由本地随机产生；给字节编上序号后，就给每一个报文段指派一个序号； 序列号seq就是这个报文段中的第一个字节的数据编号。 确认号ack：占4个字节，期待收到对方下一个报文段的第一个数据字节的序号；因此当前报文段最后一个字节的编号+1即为确认号。 确认ACK：占1位，仅当ACK=1时，确认号字段才有效。ACK=0时，确认号无效 同步SYN：连接建立时用于同步序号。当SYN=1，ACK=0时表示：这是一个连接请求报文段。若同意连接，则在响应报文段中使得SYN=1，ACK=1。因此，SYN=1表示这是一个连接请求，或连接接受报文。SYN这个标志位只有在TCP建产连接时才会被置1，握手完成后SYN标志位被置0。 终止FIN：用来释放一个连接。FIN=1表示：此报文段的发送方的数据已经发送完毕，并要求释放运输连接注意小写的ack为确认序号，大写的ACK为确认符 正因为有seq和ack的加持，所以tcp传输是可靠的。TCP为了保证不发生丢包，就给每个包一个序号，同时序号也保证了传送到接收端实体的包的按序接收。然后接收端实体对已成功收到的包发回一个相应的确认（ACK）；如果发送端实体在合理的往返时延（RTT）内未收到确认，那么对应的数据包就被假设为已丢失将会被进行重传。TCP用一个校验和函数来检验数据是否有错误；在发送和接收时都要计算校验和。 握手过程 第一次握手：建立连接时，客户端发送SYN请求连接包（seq=x,x为客户端随机数）到服务器，并进入SYN_SENT状态，等待服务器确认。 第二次握手：服务器收到SYN包，必须确认客户的SYN（ack=x+1），同时自己也发送一个SYN=1、ACK=1的包（seq=y，y为服务端随机数），即SYN+ACK包，此时服务器进入SYN_RECV状态；（这里有个特别注意的地方：很多人会问为什么不直接返回ACK包，不就可以少一次握手了吗。因为TCP之可以是可靠的，来源于双向通讯，并且双方来知会对方开始的序列号seq。第一种情况：已失效的连接请求报文段”的产生在这样一种情况下：client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。于是就向client发出确认报文段，同意建立连接。假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送ack包。（校注：此时因为client没有发起建立连接请求，所以client处于CLOSED状态，接受到任何包都会丢弃第二种情况：如果服务器发送对这个延误的旧连接报文的确认的同时，客户端调用connect函数发起了连接，就会使客户端进入SYN_SEND状态，当服务器那个对延误旧连接报文的确认传到客户端时，因为客户端已经处于SYN_SEND状态，所以就会使客户端进入ESTABLISHED状态，此时服务器端反而丢弃了这个重复的通过connect函数发送的SYN包，见第三个图。而连接建立之后，发送包由于SEQ是以被丢弃的SYN包的序号为准，而服务器接收序号是以那个延误旧连接SYN报文序号为准，导致服务器丢弃后续发送的数据包）但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。） 第三次握手：客户端收到服务器的SYN+ACK包，向服务器发送确认包ACK(ack=y+1），此包发送完毕，客户端和服务器进入ESTABLISHED（TCP连接成功）状态，完成三次握手。 挥手过程 第一次挥手：客户端进程发出连接释放报文，并且停止发送数据。释放数据报文首部，FIN=1，其序列号为seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1），此时，客户端进入FIN-WAIT-1（终止等待1）状态。 TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。 第二次挥手：服务器收到连接释放报文，发出确认报文，ACK=1，ack=u+1，并且带上自己的序列号seq=v，此时，服务端就进入了CLOSE-WAIT（关闭等待）状态。TCP服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于半关闭状态，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。而此时客户端就进入FIN-WAIT-2（终止等待2）状态，等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最后的数据）。 第三次挥手：服务器将最后的数据发送完毕后，服务器再次发送确认关闭请求FIN=1，ACK=1，ack=u+1，假定此时的序列号为seq=w，客户端收到服务器的确认请求后，此时，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认。 第四次挥手：客户端收到服务器的连接释放报文后，必须发出确认，ACK=1，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了TIME-WAIT（时间等待）状态。注意此时TCP连接还没有释放，必须经过2∗∗MSL（最长报文段寿命）的时间后，当客户端撤销相应的TCB后，才进入CLOSED状态。服务器只要收到了客户端发出的确认，立即进入CLOSED状态。同样，撤销TCB后，就结束了这次的TCP连接。可以看到，服务器结束TCP连接的时间要比客户端早一些。","categories":[{"name":"network","slug":"network","permalink":"https://www.icepear.cn/categories/network/"}],"tags":[{"name":"network","slug":"network","permalink":"https://www.icepear.cn/tags/network/"},{"name":"TCP","slug":"TCP","permalink":"https://www.icepear.cn/tags/TCP/"}]},{"title":"mysql 学习笔记（一）","slug":"mysql/mysql-func","date":"2018-07-13T11:30:02.000Z","updated":"2018-07-19T09:47:23.132Z","comments":true,"path":"2018/07/13/mysql/mysql-func/","link":"","permalink":"https://www.icepear.cn/2018/07/13/mysql/mysql-func/","excerpt":"mysql 常用函数，使用sql必然避免不了使用函数，函数往往能让你的工作事半功倍，常用的函数包括：字符串的处理，数值的运算，日期函数，流程控制。","text":"mysql 常用函数，使用sql必然避免不了使用函数，函数往往能让你的工作事半功倍，常用的函数包括：字符串的处理，数值的运算，日期函数，流程控制。 字符串函数 函数 功能 CONCAT(s1,s2,…,sn) 连接 s1，s2 …sn 为一个字符串 INSERT(str,x,y,instr) 将字符串str从第x位开始,y个字符串长度的子串替换成instr REPLACE(str,a,b) 用字符串b替换字符串str中所有出现的字符串a SUBSTRING(str,x,y) 截取字符串str从x位置到y位置的子串 LEFT(str,x) 返回字符串str最左边的x个字符 RIGHT(str,x) 返回字符串str最右边的x个字符 LOWER(str) 将字符串str中所有的字符变为小写 UPPER(str) 将字符串str中所有的字符变为大写 LTRIM(str) 去掉字符串左侧的空格 RTRIM(str) 去掉字符串行尾的空格 TRIM(str) 去掉字符串行头和行尾的空格 LPAD(str,n,pad) 用字符串pad对str最左边进行填充，直到长度为n个字符长度 RPAD(str,n,pad) 用字符串pad对str最右边进行填充，直到长度为n个字符长度 REPEAT(str,x) 返回str重复x次的结果 STRCMP(s1,s2) 比较字符串s1和s2 字符串的拼接、替换、裁剪这些函数是最常见的，务必牢记 CONCAT(s1,s2,…,sn) 拼接字符串 下面例子将aa，bb，cc三个字符串拼接，另外任何字符串与NULL连接的结果都将是NULL 1234567mysql&gt; select concat('aa','bb','cc'),concat('aa',null);+-------------------------+----------------------+| concat('aa','bb','cc') | concat('aa',null) |+-------------------------+----------------------+| aabbcc | NULL |+-------------------------+----------------------+1 row in set(0.00 sec) INSERT、REPLACE 两个函数都是替换字符串 下面例子将abcd字符串替换成abcc，通过两个方法 1234567mysql&gt; select insert('abcd',3,2,'cc'),replace('abcd','d','c');+-------------------------+-------------------------+| insert('abcd',3,2,'cc') | replace('abcd','d','c') |+-------------------------+-------------------------+| abcc | abcc |+-------------------------+-------------------------+1 row in set (0.00 sec) SUBSTRING、LEFT、RIGHT 三个函数都可以对字符串进行裁剪 substring相对灵活很多，left和right函数比较局限，只能截取左边或右边的子串，看三个例子 1234567mysql&gt; select substring('abcdefg',2,5), left('abcdefg',4),right('abcdefg',4);+--------------------------+-------------------+--------------------+| substring('abcdefg',2,5) | left('abcdefg',4) | right('abcdefg',4) |+--------------------------+-------------------+--------------------+| bcdef | abcd | defg |+--------------------------+-------------------+--------------------+1 row in set (0.00 sec) 字符串的字符处理，对比 LOWER、UPPER、LTRIM、RTRIM、TRIM 等函数可以对字符串进行处理 LOWER、UPPER 用于大小写转换，LTRIM、RTRIM、TRIM用于对字符串空格处理。看例子 1234567mysql&gt; select upper('abcd'),lower('ABCD'),ltrim(' $abcd'),rtrim('abcd$ '),trim(' $abcd$ ');+---------------+---------------+-----------------+-----------------+------------------+| upper('abcd') | lower('ABCD') | ltrim(' $abcd') | rtrim('abcd$ ') | trim(' $abcd$ ') |+---------------+---------------+-----------------+-----------------+------------------+| ABCD | abcd | $abcd | abcd$ | $abcd$ |+---------------+---------------+-----------------+-----------------+------------------+1 row in set (0.00 sec) LPAD、RPAD 填充字符串函数 左右填充字符串，直到长度为n，看例子 1234567mysql&gt; select lpad('defg',8,'abcd'),rpad('abcd',8,'defg');+-----------------------+-----------------------+| lpad('defg',8,'abcd') | rpad('abcd',8,'defg') |+-----------------------+-----------------------+| abcddefg | abcddefg |+-----------------------+-----------------------+1 row in set (0.00 sec) REPEAT、STRCMP两个相对特殊一点的函数 见例子，strcmp比较的是字符串的ASCII码大小，相等返回0，小返回-1，大返回1 1234567mysql&gt; select repeat('abc',3),strcmp('a','a'),strcmp('aa','ab'),strcmp('b','a');+-----------------+-----------------+-------------------+-----------------+| repeat('abc',3) | strcmp('a','a') | strcmp('aa','ab') | strcmp('b','a') |+-----------------+-----------------+-------------------+-----------------+| abcabcabc | 0 | -1 | 1 |+-----------------+-----------------+-------------------+-----------------+1 row in set (0.00 sec) 数值函数 函数 功能 ABX(x) 返回x的绝对值 CEIL(x) 返回大于x的最小整数值 FLOOR(x) 返回小于x的最小整数值 MOD(x,y) 返回x/y的模 RAND() 返回0~1内的随机数 ROUND(x,y) 返回参数x的四舍五入的有y位小数的值 TRUNCATE(x,y) 返回数字x截断为y位小数的结果 ABX(x) 绝对值 1234567mysql&gt; select abs(-2),abs(2),abs(-5);+---------+--------+---------+| abs(-2) | abs(2) | abs(-5) |+---------+--------+---------+| 2 | 2 | 5 |+---------+--------+---------+1 row in set (0.00 sec) CEIL(x)、FLOOR(x) 最小整数值 1234567mysql&gt; select ceil(2.5),floor(2.5);+-----------+------------+| ceil(2.5) | floor(2.5) |+-----------+------------+| 3 | 2 |+-----------+------------+1 row in set (0.01 sec) MOD(x,y) 取模 1234567mysql&gt; select mod(9,2),mod(17,5);+----------+-----------+| mod(9,2) | mod(17,5) |+----------+-----------+| 1 | 2 |+----------+-----------+1 row in set (0.00 sec) RAND() 0~1随机数 可以通过组合方式，产生0~9的随机数，或者更大的随机数 1234567mysql&gt; select rand(),floor(rand()*10);+--------------------+------------------+| rand() | floor(rand()*10) |+--------------------+------------------+| 0.9055393793671759 | 7 |+--------------------+------------------+1 row in set (0.00 sec) ROUND(x,y)、TRUNCATE(x,y) 四舍五入和截取 1234567mysql&gt; select round(4.32354,3),round(4.32354,2),truncate(4.32354,3);+------------------+------------------+---------------------+| round(4.32354,3) | round(4.32354,2) | truncate(4.32354,3) |+------------------+------------------+---------------------+| 4.324 | 4.32 | 4.323 |+------------------+------------------+---------------------+1 row in set (0.00 sec) 日期函数 函数 功能 CURDATE() 当前日期 CURTIME() 当前时间 NOW() 当前日期和时间 UNIX_TIMESTAMP(date) 日期date的UNIX时间戳 FROM_UNIXTIME(unixtime) UNIX时间戳的日期值 WEEK(date) 日期date为一年中的第几周 YEAR(date) 日期date的年份 HOUR(time) time的小时值 MINUTE(time) time的分钟值 MOONTHNAME(date) date的月份名 DATE_FORMAT(date,fmt) 按字符串fmt格式化日期date的值 DATE_ADD(date,INTERVAL exper type) 一个日期或时间值加上一个时间间隔的时间值 DATEDIEF(expr,expr2) 其实时间expr和结束时间expr2之间的天数 DATE_ADD(date,INTERVAL exper type)重点说明一下，其中 INTERVAL 是间隔类型关键字，expr 是表达式， type是类型，类型表如下 type 解释 MICROSECOND 间隔单位：毫秒 SECOND 间隔单位：秒 MINUTE 间隔单位：分钟 HOUR 间隔单位：小时 DAY 间隔单位：天 WEEK 间隔单位：星期 MONTH 间隔单位：月 QUARTER 间隔单位：季度 YEAR 间隔单位：年 SECOND_MICROSECOND 复合型，间隔单位：秒、毫秒，expr可以用两个值来分别指定秒和毫秒 MINUTE_MICROSECOND 复合型，间隔单位：分、毫秒 MINUTE_SECOND 复合型，间隔单位：分、秒 HOUR_MICROSECOND 复合型，间隔单位：小时、毫秒 HOUR_SECOND 复合型，间隔单位：小时、秒 HOUR_MINUTE 复合型，间隔单位：小时分 DAY_MICROSECOND 复合型，间隔单位：天、毫秒 DAY_SECOND 复合型，间隔单位：天、秒 DAY_MINUTE 复合型，间隔单位：天、分 DAY_HOUR 复合型，间隔单位：天、小时 YEAR_MONTH 复合型，间隔单位：年、月 例如 12345678910111213mysql&gt; select date_add('2013-01-18', interval '1 2' YEAR_MONTH);+-----------------------------------------------------+| date_add('2013-01-18', interval '1 2' YEAR_MONTH) |+-----------------------------------------------------+| 2014-03-18 |+-----------------------------------------------------+mysql&gt; select date_add('2013-01-18', interval '1-2' YEAR_MONTH);+----------------------------------------------------+| date_add('2013-01-18', interval '1-2' YEAR_MONTH) |+----------------------------------------------------+| 2014-03-18 |+----------------------------------------------------+ 其他函数 函数 功能 DATEBASE() 数据库名 VERSION() 版本 USER() 用户名 MD5(str) str的MD5加密值","categories":[{"name":"mysql","slug":"mysql","permalink":"https://www.icepear.cn/categories/mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.icepear.cn/tags/Mysql/"}]},{"title":"redis 配置解析","slug":"other/redis-conf","date":"2018-06-21T11:30:02.000Z","updated":"2018-07-18T10:40:27.225Z","comments":true,"path":"2018/06/21/other/redis-conf/","link":"","permalink":"https://www.icepear.cn/2018/06/21/other/redis-conf/","excerpt":"拿着原始的redis.conf进行一一解析，应该算是最全的解析版本了","text":"拿着原始的redis.conf进行一一解析，应该算是最全的解析版本了 下载链接文件的下载链接 配置文件 配置内容看不完，就先下载下来慢慢看 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779780781782783784785786787788789790791792793794795796797798799800801802803804805806807808809810811812813814815816817818819820821822823824825826827828829830831832833834835836837838839840841842843844845846847848849850851852853854855856857858859860861862863864865866867868869# Redis 配置样例## 为了读取配置文件，Redis必须以文件路径作为第一个参数来启动：## ./redis-server /path/to/redis.conf# 当需要内存大小时，可以使用1k 5GB 4M等通常的形式指定它，如下所示：## 1k =&gt; 1000 bytes# 1kb =&gt; 1024 bytes# 1m =&gt; 1000000 bytes# 1mb =&gt; 1024*1024 bytes# 1g =&gt; 1000000000 bytes# 1gb =&gt; 1024*1024*1024 bytes## 单位不区分大小写，所以1GB 1Gb 1gB都是一样的。################################## INCLUDES配置文件 #################################### 在这里包含一个或多个其他配置文件。 如果您有一个标准模板可用于所有Redis服务器，# 但也需要自定义几个每服务器设置，这非常有用。 包含文件可以包含其他文件，所以明智地使用它。# “include”不会被来自admin或Redis Sentinel的命令“CONFIG REWRITE”重写。 # 由于Redis总是使用最后一条处理过的行作为配置指令的值，因此最好将include包含在此文件的开头，以避免在运行时覆盖配置更改。## include /path/to/local.conf# include /path/to/other.conf################################## MODULES模块加载 ###################################### 启动时加载模块。 如果服务器无法加载模块，则会中止。 可以使用多个loadmodule指令## loadmodule /path/to/my_module.so# loadmodule /path/to/other_module.so################################## NETWORK网络配置 ###################################### 默认情况下，如果没有指定“绑定”配置指令，则Redis监听来自服务器上可用的所有网络接口的连接。 # 可以使用“bind”配置指令监听一个或多个选定的接口，然后使用一个或多个IP地址。## 例子:## bind 192.168.1.100 10.0.0.1# bind 127.0.0.1 ::1## ~~~ WARNING ~~~ # 如果运行Redis的计算机直接暴露在互联网上，绑定到所有接口是危险的，并会将实例暴露给互联网上的每个人。 # 因此，默认情况下，我们取消注释以下绑定指令，这将强制Redis仅侦听IPv4回溯接口地址#（这意味着Redis将只能接受与运行在同一台计算机上的客户端的连接）。## 如果您确定您希望您的实例能够聆听所有接口，只需像下面这样即可。# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~bind 127.0.0.1# 保护模式是一层安全保护措施，以避免在互联网上保持打开的Redis实例被访问和利用。## 当保护模式打开时，如果：## 1) 服务器没有明确地使用&quot;bind&quot;绑定到一组地址# 2) 没有配置密码。## 服务器只接受来自IPv4和IPv6环回地址127.0.0.1和:: 1以及来自Unix域套接字的客户端的连接。## 默认情况下启用保护模式。protected-mode yes# 接受指定端口上的连接，默认值为6379如果指定端口0，则Redis不会侦听TCP套接字。port 6379# TCP listen() backlog.## 在高请求每秒的环境中，您需要高的backlog以避免缓慢的客户端连接问题。 # 请注意，Linux内核会将其自动截断为/ proc / sys / net / core / somaxconn的值，# 因此请确保同时提高somaxconn和tcp_max_syn_backlog的值以获得所需的效果。tcp-backlog 511# Unix socket.## 指定将用于侦听传入连接的Unix socket的路径。 没有默认设置，因此Redis在未指定时不会在unix socket上侦听。## unixsocket /tmp/redis.sock# unixsocketperm 700# 客户端空闲N秒后关闭连接（0禁用）timeout 0# TCP keepalive. 心跳检测## 如果非零，则在没有通信的情况下使用SO_KEEPALIVE向客户端发送TCP ACK。 # 这是有用的，原因有两个：## 1) 检测死掉的资源共享者# 2) 从中间网络设备的角度来看，连接是活着的。## 在Linux上，指定的值（以秒为单位）是用于发送ACK的时间段。# 请注意，要关闭连接，需要两倍的时间。# 在其他内核上，时间取决于内核配置。## 这个选项的合理值是300秒，这是新的# Redis默认从Redis 3.2.1开始。tcp-keepalive 300################################# 一般配置 ###################################### 默认情况下，Redis不会作为守护进程运行。 如果您需要，请使用&quot;yes&quot;。# 请注意，当守护进程时，Redis将在/var/run/redis.pid中写入一个pid文件。daemonize no# 如果您从upstart或systemd运行Redis，则Redis可以与您的监督树进行交互。选项:# supervised no - 没有监督互动# supervised upstart - 通过将Redis置于SIGSTOP模式来发信号# supervised systemd - 通过将READY = 1写入$ NOTIFY_SOCKET来系统化信号# supervised auto - 检测 upstart or systemd 方法基于UPSTART_JOB or NOTIFY_SOCKET 环境变量# 注意：这些监督方法只会发出“过程已准备就绪”的信号。 他们不能将连续的活跃回馈给你的supervisor。supervised no# 如果指定了pid文件，则Redis将其写入启动时指定的位置，并在退出时将其删除。# 当服务器运行非守护进程时，如果配置中没有指定pid文件，则不会创建pid文件。 # 当服务器被守护进程时，即使未指定，也会使用pid文件，默认为“/var/run/redis.pid”。# 如果Redis不能创建它，创建一个pid文件是最好的选择pidfile /var/run/redis_6379.pid# 服务器日志级别:# debug (对开发/测试有用)# verbose (比debug级别精简)# notice (适度详细，用在生产中)# warning (只记录非常重要/关键的消息)loglevel notice# 指定日志文件名称 空字符串可用于强制Redis log标准输出。请注意，如果您使用标准输出进行日志记录但守护进程，则日志将被发送到/dev/nulllogfile &quot;&quot;# 要启用logging到系统 logger，只需将&apos;syslog-enabled&apos;设置为yes，并可以选择更新其他syslog参数以满足您的需求。# syslog-enabled no# 指定系统日志标识。# syslog-ident redis# 指定系统日志功能。 必须是USER或local0至local7。# syslog-facility local0# 设置数据库的数量，默认值是16。# 默认数据库是DB 0，您可以使用SELECT &lt;dbid&gt;在每个连接的基础上切换不同的数据库，databases 16# 默认情况下，Redis只有在log是标准输出并且标准输出是TTY时才显示ASCII logo。 基本上这意味着通常只有在交互式会话中才会显示logo。always-show-logo yes################################ SNAPSHOTTING快照配置 ################################## 保存DB到磁盘:# # save &lt;seconds&gt; &lt;changes&gt;## 如果发生针对数据库的给定秒数和给定数量的写操作，将保存数据库。## 例如:# after 900 sec (15 min) if at least 1 key changed# after 300 sec (5 min) if at least 10 keys changed# after 60 sec if at least 10000 keys changed## 注意: 您可以通过注释掉所有“保存”行来完全禁用保存。也可以用 save &quot;&quot;save 900 1save 300 10save 60 10000# 默认情况下，如果启用了RDB快照（至少有一个保存点）并且最新的后台保存失败，Redis将停止接受写入。# 可以让用户意识到数据不能正确的保存在磁盘上，否则没人会去关注这一错误的发生## 如果后台保存过程将再次开始工作，则Redis将自动再次允许写入。## 但是，如果您已设置了对Redis服务器和持久性的适当监控，则可能需要禁用此功能，以便即使磁盘，权限等问题仍然存在，Redis仍将照常继续工作。stop-writes-on-bgsave-error yes# 在转储.rdb数据库时使用LZF压缩字符串对象？对于默认设置为&apos;是&apos;，因为它几乎总是可以的。# 如果您想要在保存子节点中保存一些CPU，请将其设置为“否”，但如果您具有可压缩值或密钥，则数据集可能会更大。rdbcompression yes# 从版本5的RDB开始，CRC64校验和被放置在文件的末尾。# 这使得该格式更能抵抗腐败，但在保存和加载RDB文件时，性能会受到影响（大约为10％），因此您可以禁用它以获得最佳性能。rdbchecksum yes# 转储数据库的文件名dbfilename dump.rdb# 存储的文件目录dir ./################################# 主从复制 ################################## 主从复制。 使用slaveof将Redis实例作为另一个Redis服务器的副本## 1) Redis复制是异步的，但是如果它看起来没有连接至少给定数量的slave，您可以配置master来停止接受写入。# 2) 如果复制链接在相对较短的时间内丢失，则Redis从节点能够与主节点执行部分重新同步。 您可能需要根据您的需要配置合理的值来配置复制积压大小# 3) 复制是自动的，不需要用户干预。在网络分区后slave自动尝试重新连接到master并与它们重新同步## slaveof &lt;masterip&gt; &lt;masterport&gt;# 如果主站受密码保护（使用下面的“requirepass”配置指令），可以在开始复制同步过程之前告诉从站进行认证，否则主站将拒绝从站请求。## masterauth &lt;master-password&gt;# 当slave失去与master的连接时，或者复制仍在进行时，slave可以采取两种不同的方式：## 1) 如果slave-serve-stale-data设置为&apos;yes&apos;（缺省值），则从设备仍然会回应客户端请求，可能会使用过时数据，或者如果这是第一次同步，数据集可能只是空的。## 2) 如果slave-serve-stale-data设置为&apos;no&apos;，则从设备将回复一个错误“SYNC with master in progress”，除了INFO和SLAVEOF之外的所有类型的命令。#slave-serve-stale-data yes# 您可以配置一个从设备实例来接受写入与否。 针对从属实例写入数据可能对于存储一些短暂数据非常有用#（因为写入从属服务器上的数据在与主服务器重新同步后很容易被删除），但是如果客户端因错误配置而写入数据，也可能会导致问题。## 从Redis 2.6后 默认情况是只读的。slave-read-only yes# 复制SYNC策略: disk or socket.## -------------------------------------------------------# WARNING: DISKLESS 是目前的测试参数# -------------------------------------------------------## 新的slaves和重新连接的因为接收差异无法继续复制进程,需要做所谓的 &quot;full synchronization&quot;.RDB文件从maste 传输到slaves。# 传输可以以两种不同的方式发生：## 1) Disk-backed: Redis master创建一个将RDB文件写入磁盘的新进程。 之后，文件由父进程传递到从服务器。# 2) Diskless: Redis master创建一个新的进程，直接将RDB文件写入从套接字，而不用接触磁盘。## 使用 disk-backed 复制, 当生成RDB文件时，只要生成RDB文件的当前子节点完成其工作，就可以将更多的从属节点排队并与RDB文件一起提供服务。# 使用diskless复制，一旦传输开始，到达的新从站将排队，并且当当前端口终止时将开始新的传输。# 使用diskless复制，在开始传输之前，主设备等待可配置的时间量（以秒为单位），可以等待多个从设备到达后并行的传输。## 对于慢速磁盘和快速（大带宽）网络 diskless 复制效果更好repl-diskless-sync no# 启用 diskless 时, 服务器等待一段时间后才会通过套接字向从站传送RDB文件，这个等待时间是可配置的。 # 这一点很重要，因为一旦传送开始，就不可能再为一个新到达的从站服务。从站则要排队等待下一次RDB传送。因此服务器等待一段时间以期更多的从站到达。# 延迟时间以秒为单位，默认为5秒。要关掉这一功能，只需将它设置为0秒，传送会立即启动repl-diskless-sync-delay 5# 从站以一个预先设置好的时间间隔向服务器发送PING。这个时间间隔可以通过repl_ping_slave_period选项改变。默认值是10秒。# repl-ping-slave-period 10# 该选项为以下内容设置备份的超时时间：## 1) slaves角度，同步批量传输的I/O.# 2) slave角度，master超时(数据, ping).# 3) master角度，slave超时 (REPLCONF ACK pings).## 确认这个值比定义的repl-ping-slave-period要大，否则每次主站和从站之间通信低速时都会被检测为超时。## repl-timeout 60# 同步之后是否禁用slave上的TCP_NODELAY？## 假如设置成yes，则redis会合并小的TCP包从而节省带宽，但会增加同步延迟（40ms），造成master与slave数据不一致# 假如设置成no，则redis master会立即发送同步数据，没有延迟## 默认情况下，我们针对低延迟进行了优化，但在非常高并发量条件下，或者当主设备和从设备距离很远时，将此设置为“yes”可能是一个好主意。repl-disable-tcp-nodelay no# 设置备份的工作储备大小。工作储备是一个缓冲区，当从站断开一段时间的情况时，# 它替从站接收存储数据，因此当从站重连时，通常不需要完全备份，只需要一个部分同步就可以，即把从站断开时错过的一部分数据接收。 # 工作储备越大，从站可以断开并稍后执行部分同步的断开时间就越长。 # 只要有一个从站连接，就会立刻分配一个工作储备。# repl-backlog-size 1mb# 主站有一段时间没有与从站连接，对应的工作储备就会自动释放。接下来这个选项用于配置释放前等待的秒数，秒数从断开的那一刻开始计算。 ## 请注意，从站永远不会释放积压超时，因为它们可能在稍后被提升为主站，并且应该能够正确地与从站“部分重新同步”：因此它们应该始终积累积压。## 值为0表示不释放。## repl-backlog-ttl 3600# 从站优先级是可以从redis的INFO命令输出中查到的一个整数。当主站不能正常工作时，redis sentinel使用它来选择一个从站并将它提升为主站。 # 低优先级的从站被认为更适合于提升，因此如果有三个从站优先级分别是10， 100， 25，sentinel会选择优先级为10的从站，因为它的优先级最低。 # 然而优先级值为0的从站不能执行主站的角色，因此优先级为0的从站永远不会被redis sentinel提升。 # 默认优先级是100slave-priority 100# 主站可以停止接受写请求，当与它连接的从站少于N个，滞后少于M秒。N个从站必须是在线状态。 # 延迟的秒数必须&lt;=所定义的值，延迟秒数是从最后一次收到的来自从站的ping开始计算。ping通常是每秒一次。 # 这一选项并不保证N个备份都会接受写请求，但是会限制在指定秒数内由于从站数量不够导致的写操作丢失的情况。 # 设置某一个为0表示禁用这一功能。 # 默认情况下default min-slaves-to-write设置为0（禁用）而min-slaves-max-lag设置为10。# 如果想要至少3个从站且延迟少于10秒，这样写：## min-slaves-to-write 3# min-slaves-max-lag 10# Redis master能够以不同的方式列出所连接slave的地址和端口。 # 例如，“INFO replication”部分提供此信息，除了其他工具之外，Redis Sentinel还使用该信息来发现slave实例。# 此信息可用的另一个地方在masterser的“ROLE”命令的输出中。# 通常由slave报告的列出的IP和地址,通过以下方式获得：# IP：通过检查slave与master连接使用的套接字的对等体地址自动检测地址。# 端口：端口在复制握手期间由slavet通信，并且通常是slave正在使用列出连接的端口。# 然而，当使用端口转发或网络地址转换（NAT）时，slave实际上可以通过(不同的IP和端口对)来到达。 slave可以使用以下两个选项，以便向master报告一组特定的IP和端口，# 以便INFO和ROLE将报告这些值。# 如果你需要仅覆盖端口或IP地址，则没必要使用这两个选项。# 注意：在Docker默认网络模式下，使用-p参数做端口映射，就需要配置一下从服务器redis.conf中的slave-announce-ip 和 slave-announce-port，对应外网的IP和外网端口。# Sentinel的配置文件sentinel.conf 也需要配置sentinel announce-ip 和 sentinel announce-port ，对应外网的IP和外网端口。# 当然，如果Docker配置成host网络模式，就不需要配置了，但建议最好不要用host模式# slave-announce-ip 5.5.5.5# slave-announce-port 1234################################## SECURITY安全性 #################################### 密码设置#requirepass icepear123456# 作为服务端的redis-server，我们常常需要禁用以上命令来使服务器更加安全。## 例如:## rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52## 在上面的例子中，CONFIG命令被重命名为一个不可猜测的名字。# 也可以通过将其重命名为空字符串来完全禁用它（或任何其他命令），如下例所示：## rename-command CONFIG &quot;&quot;################################### CLIENTS客户端 ##################################### 设置能连上redis的最大客户端连接数量。默认是10000个客户端连接。由于redis不区分连接是客户端连接还是内部打开文件或者和slave连接等，# 所以maxclients最小建议设置到32。如果超过了maxclients，redis会给新的连接发送’max number of clients reached’，并关闭连接。## maxclients 10000############################## MEMORY MANAGEMENT 内存管理 ################################# 将内存使用限制设置为指定的字节数。 达到内存限制时，Redis将尝试根据所选驱逐策略删除密钥（请参阅maxmemory-policy）。## 如果Redis无法根据策略删除密钥，或者如果策略设置为“noviction”吗，Redis将开始以错误的形式回复将使用更多内存的命令，如SET，LPUSH等，并将继续回复GET等只读命令。## 当使用Redis作为LRU或LFU缓存时，或者为实例设置硬内存限制（使用&apos;noviction&apos;策略）时，此选项通常很有用。## 警告：如果您的从站连接到启用了maxmemory的实例，则从已用存储器计数中减去用于馈送从站的输出缓冲区的大小。# 因此网络问题/ resyncs不会触发导致密钥被清除的一个循环，并且从属的输出缓冲区充满了被删除的DEL键以及触发删除更多密钥的等等，直到数据库完全清空。## 简而言之，如果你有slave，建议你为maxmemory设置一个下限，以便系统上有一些空闲的RAM用于从属输出缓冲区（但如果策略是&apos;noviction&apos;则不需要）。# 如果不设置maxmemory或者设置为0，64位系统不限制内存，32位系统最多使用3GB内存。# maxmemory &lt;bytes&gt;# 内存删除策略: 当达到maxmemory时，Redis将如何选择要删除的内容。 您可以选择八种行为：# 从Redis4.0开始，一个新的叫做最少频率使用驱逐模型是可用的。此模型在某些场景下可能会工作的更好（提供一个更好的命中/失误比率），# 因为使用LFU Redis将试图追踪所访问目标的频率，以便极少使用的驱逐而经常使用的则有更高机会保留在内存中。## volatile-lru -&gt; 在设置了过期时间的键空间中，优先移除最近未使用的key。# allkeys-lru -&gt; 优先移除最近未使用的key。# volatile-lfu -&gt; 在设置了过期时间的键空间中，移除使用频次最少的key# allkeys-lfu -&gt; 移除使用频次最少的key# volatile-random -&gt; 在设置了过期时间的键空间中，随机移除# allkeys-random -&gt; 随机删除 # volatile-ttl -&gt; 在设置了过期时间的键空间中，具有更早过期时间的key优先移除。# noeviction -&gt; 当内存使用达到阈值的时候，所有引起申请内存的命令会报错## LRU 最近未使用# LFU 使用频次最少## LRU，LFU和volatile-ttl都是使用近似随机算法实现的。(没有绝对的随机算法，哈哈)## 注意: 默认值是: noeviction，当没有合适的驱逐算法时，Redis将在写入操作时返回错误## 这些命令是: set setnx setex append# incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd# sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby# zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby# getset mset msetnx exec sort## maxmemory-policy noeviction# LRU，LFU和最小TTL算法不是精确算法，而是近似算法（为了节省内存），因此您可以调整它以获得速度或准确性。 对于默认值，# Redis将检查五个键并选择最近使用的键，您可以使用以下配置指令更改样本大小。## 默认值5会产生足够好的结果。 10非常接近真正的LRU，但成本更高。 3更快但不是很准确。## maxmemory-samples 5############################# LAZY FREEING 懒释放##################################### 这是4.0加入的新特性# Redis有两个原函数来删除键。 一个被称为DEL并且是对象的阻塞删除。就是服务器停止处理新命令用同步方式回收与对象关联的所有内存# 如果删除的键与一个小对象关联，执行DEL命令所需的时间非常短，并且与Redis中的大多数其他O（1）或O（log_N）命令相当 However if the key is associated with an# 但是，如果key与包含数百万个元素的聚合值关联，则服务器可能会阻塞很长时间（甚至几秒）以完成操作。## 由于上述原因，Redis还提供非阻塞删除原语，例如UNLINK（非阻塞DEL）和FLUSHALL和FLUSHDB命令的ASYNC选项，以便在后台回收内存。 # 这些命令在不变的时间内执行。 另一个线程将尽可能快地增量释放背景中的对象。## DEL, UNLINK and ASYNC option of FLUSHALL and FLUSHDB 选项由用户控制。 这取决于应用程序的设计，当然你得了解什么时候使用。 # 但是，Redis服务器有时必须删除key或刷新整个数据库，这将对其他操作产生影响# 具体来说，Redis会在以下情况下自动删除对象：## 1) 在删除时，由于maxmemory和maxmemory策略配置的原因，为了为新数据腾出空间，而不超过指定的内存限制。## 2) 由于过期：必须从存储器中删除具有关联时间的密钥（请参阅EXPIRE命令）## 3) 由于存储数据的命令的副作用可能已经存在。 例如，RENAME命令可能会在旧密钥内容被另一个替换时删除旧密钥内容。 # 同样，SUNIONSTORE或SORT with STORE选项可能会删除现有密钥。 SET命令本身会删除指定键的所有旧内容，以便将其替换为指定的字符串。## 4) 在复制期间，当从服务器与主服务器执行完全重新同步时，整个数据库的内容将被删除，以便加载刚刚传输的RDB文件。## 在上述所有情况下，默认情况下都是以阻塞的方式删除对象，就像调用DEL一样。 要开启调整为“yes”# 但是，您可以专门配置每个案例，以便使用以下配置指令以非阻塞方式释放内存，就像调用UNLINK一样：lazyfree-lazy-eviction nolazyfree-lazy-expire nolazyfree-lazy-server-del noslave-lazy-flush no############################## APPEND ONLY MODE 持久化模式################################ 默认情况下，Redis异步转储磁盘上的数据集。 这种模式在许多应用程序中已经足够了，但Redis进程或停电可能会导致几分钟的写入丢失（取决于配置的保存点）。## 仅追加文件是一种替代的持久模式，可提供更好的耐用性。例如，使用默认数据fsync策略（稍后在配置文件中看到）# 可以同时启用AOF和RDB持久性，是没有问题的。 如果在启动时启用AOF，则Redis将加载AOF，即具有更好的持久性保证的文件。## 查看http://redis.io/topics/persistence 获取更多内容.appendonly no# AOF文件的名称appendfilename &quot;appendonly.aof&quot;# fsync()函数调用告诉操作系统在磁盘上实际写入数据，而不是等待输出缓冲区中的更多数据。 # 有些操作系统会真正在磁盘上刷新数据，其他一些操作系统只会尽量做到这一点。## Redis支持三种不同的模式：## no: 不要fsync，只需让操作系统在需要时刷新数据。 更快。# always: 每次写入追加日志后的fsync。 慢，最安全。# everysec: 每秒只有一次fsync。 折中。## 默认值是“everysec”，因为这通常是速度和数据安全性之间的折中方案。# 您应该了解您是否可以将其放宽至“否”，以便操作系统在需要时刷新输出缓冲区以获得更好的性能（但是如果您可以忍受某些数据丢失的想法，请考虑快照的默认持久性模式），# 或者相反你可以使用 always，慢但是安全## 更多详细信息参考:# http://antirez.com/post/redis-persistence-demystified.html## 如果不确定, 使用 &quot;everysec&quot;.# appendfsync no# appendfsync alwaysappendfsync everysec# 当AOF fsync策略设置为always或everysec，并且后台保存进程（后台保存或AOF日志后台重写）正在对磁盘执行大量I/O时，# 在某些Linux配置中，Redis可能会在fsync（）调用上阻塞太久。 请注意，目前没有解决此问题的方法，因为即使在其他线程中执行fsync也会阻止我们的同步写入操作的调用。## 为了减轻这个问题，可以使用下面的选项来防止在BGSAVE或BGREWRITEAOF进程中在主进程中调用fsync()。## 这意味着，当另一个child正在保存时，Redis的持久性与“appendfsync none”相同。 实际上，这意味着在最坏的情况下（使用默认的Linux设置）可能会丢失高达30秒的日志。## 如果您有延迟问题，请将其转为“yes”。 否则，将其视为“no”，从持久性角度来看这是最安全的选择。# # 什么意思呢，同时在执行bgrewriteaof操作和主进程写aof文件的操作，两者都会操作磁盘，而bgrewriteaof往往会涉及大量磁盘操作，# 这样就会造成主进程在写aof文件的时候出现阻塞的情形，现在no-appendfsync-on-rewrite参数出场了。如果该参数设置为no，是最安全的方式，# 不会丢失数据，但是要忍受阻塞的问题。如果设置为yes呢？这就相当于将appendfsync设置为no，这说明并没有执行磁盘操作，只是写入了缓冲区，# 因此这样并不会造成阻塞（因为没有竞争磁盘），但是如果这个时候redis挂掉，就会丢失数据。丢失多少数据呢？在linux的操作系统的默认设置下，最多会丢失30s的数据。# 因此，如果应用系统无法忍受延迟，而可以容忍少量的数据丢失，则设置为yes。如果应用系统无法忍受数据丢失，则设置为no。no-appendfsync-on-rewrite no# 自动重写AOF文件# 当AOF日志大小按指定的百分比增长时，Redis能够自动重写日志文件，隐式调用BGREWRITEAOF。## 这是如何工作的：Redis记得最近一次重写后AOF文件的大小（如果重启后没有发生重写，则使用启动时AOF的大小）。## 上次AOF的大小与当前大小进行比较。 如果当前的大小大于指定的百分比，则触发重写。 此外，您还需要指定要重写的AOF文件的最小值，# 就是即使达到了百分比增加但文件仍然很小，这可以避免重写AOF## 指定百分比为零以禁用自动AOF重写功能。auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb# Redis启动加载aof文件，如果发现末尾命令不完整则自动截掉，成功加载前面正确的数据。# 如果设置为no，遇到此类情况，Redis启动失败，用redis-check-aof 工具手工修复。aof-load-truncated yes# 混合 RDB-AOF 持久化格式 # Redis 4.0 新增了 RDB-AOF 混合持久化格式， 这是一个可选的功能， 在开启了这个功能之后， AOF 重写产生的文件将同时包含 RDB 格式的内容和 AOF 格式的内容， # 其中 RDB 格式的内容用于记录已有的数据， 而 AOF 格式的内存则用于记录最近发生了变化的数据， # 这样 Redis 就可以同时兼有 RDB 持久化和 AOF 持久化的优点 —— 既能够快速地生成重写文件， 也能够在出现问题时， 快速地载入数据。aof-use-rdb-preamble no################################ LUA SCRIPTING Lua 脚本################################ 一个Lua脚本最长的执行时间，单位为毫秒，如果为0或负数表示无限执行时间，默认为5000lua-time-limit 5000################################ REDIS CLUSTER redis集群 ################################# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++# WARNING EXPERIMENTAL: Redis Cluster is considered to be stable code, however# in order to mark it as &quot;mature&quot; we need to wait for a non trivial percentage# of users to deploy it in production.# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++## 开启集群模式# cluster-enabled yes# 集群节点配置文件# cluster-config-file nodes-6379.conf# 集群节点超时时间限制# cluster-node-timeout 15000# 在进行故障转移的时候全部slave都会请求申请为master，但是有些slave可能与master断开连接一段时间了导致数据过于陈旧，不应该被提升为master。# 该参数就是用来判断slave节点与master断线的时间是否过长。判断方法是：# 比较slave断开连接的时间和# (node-timeout * slave-validity-factor)+ repl-ping-slave-period# 如果节点超时时间为三十秒, 并且slave-validity-factor为10，假设默认的repl-ping-slave-period是10秒，即如果超过310秒slave将不会尝试进行故障转移## cluster-slave-validity-factor 10# 一个主节点在拥有多少个好的从节点的时候就要割让一个从节点出来。例如这个参数若被设为 2，那么只有当一个主节点拥有 2 个可工作的从节点时，它的一个从节点会尝试迁移。## cluster-migration-barrier 1 # yes表示当负责一个主节点宕机并且下线没有相应的从库进行故障恢复时，整个集群不可用# no表示当负责一个插槽的主库下线且没有相应的从库进行故障恢复时，集群仍然可用。## cluster-require-full-coverage yes# 此选项设置为yes时，可防止从站在主站故障期间尝试故障切换其主站## 这在不同情况下非常有用，特别是在多数据中心操作的情况下，如果不是在发生全面的DC故障的情况下，我们希望一方不会被提升。## cluster-slave-no-failover no# 文档见 http://redis.io web site.########################## CLUSTER DOCKER/NAT support docker集群网络支持 ######################### 在某些部署中，Redis群集节点地址发现失败，因为地址是NAT或由于端口被转发（典型情况是Docker和其他容器）。## 为了使Redis Cluster在这样的环境中工作，需要每个节点都知道其公共地址的静态配置。提供了以下配置：## * cluster-announce-ip# * cluster-announce-port# * cluster-announce-bus-port## 如果以上选项未使用，则将使用正常的Redis集群自动检测。## 请注意，在重新映射时，总线端口可能不在客户端端口+ 10000的固定偏移量处，因此您可以根据它们如何重新映射来指定任何端口和总线端口。 # 如果未设置总线端口，则通常会使用10000的固定偏移量。## Example:## cluster-announce-ip 10.1.1.5# cluster-announce-port 6379# cluster-announce-bus-port 6380################################## SLOW LOG 慢日志#################################### Redis Slow Log是一个系统，用于记录超过指定执行时间的查询。 执行时间不包括像客户端连接，发送回复等I / O操作，# 而只是实际执行命令所需的时间（这是命令执行的唯一阶段，其中线程被阻止并且可以在此期间不提供其他请求）。## 只有query执行时间大于slowlog-log-slower-than的才会定义成慢查询，才会被slowlog进行记录。# slowlog-log-slower-than设置的单位是微妙，默认是10000微妙，也就是10ms # slowlog-max-len表示慢查询最大的条数，当slowlog超过设定的最大值后，会将最早的slowlog删除，是个FIFO队列slowlog-max-len 128################################ LATENCY MONITOR 监控############################### Redis延迟监视子系统在运行时对不同的操作进行采样，以收集与Redis实例的可能延迟来源有关的数据。## 通过 LATENCY命令 可以打印一些图样和获取一些报告，方便监控## 这个系统仅仅记录那个执行时间大于或等于预定时间（毫秒）的操作,这个预定时间是通过latency-monitor-threshold配置来指定的，## 默认情况下，阈值设置为0，即禁用redis监控。实际上启用该监控功能，对redis所增加的成本很少。不过对于一个运行良好的redis，是没有必要打开该监控功能。latency-monitor-threshold 0############################# EVENT NOTIFICATION 事件通知############################### Redis可以通知Pub / Sub客户端有关key发生的事件。 此功能记录在http://redis.io/topics/notifications## 例如，如果启用密钥空间事件通知，并且客户机对存储在数据库0中的密钥“foo”执行DEL操作，# 则将通过Pub / Sub发布两条消息：## PUBLISH __keyspace@0__:foo del# PUBLISH __keyevent@0__:del foo## 可以选择Redis通知的事件类别，每个类别都由一个字符标识：## K Keyspace events, published with __keyspace@&lt;db&gt;__ prefix.# E Keyevent events, published with __keyevent@&lt;db&gt;__ prefix.# g Generic commands (non-type specific) like DEL, EXPIRE, RENAME, ...# $ String commands# l List commands# s Set commands# h Hash commands# z Sorted set commands# x Expired events (events generated every time a key expires)# e Evicted events (events generated when a key is evicted for maxmemory)# A Alias for g$lshzxe, so that the &quot;AKE&quot; string means all the events.## 你可以像下面一样组合几个字符表示那些事件将被通知## notify-keyspace-events Elg## 如果你想使用__keyevent@&lt;db&gt;__的前缀，并发布过期的键的事件可以用：## notify-keyspace-events Ex## 默认情况下，采用空字符串所有通知都被禁用，因为大多数用户不需要此功能，并且该功能有一定的开销。 # 请注意，如果您未指定K或E中的至少一个，则不会传送任何事件。notify-keyspace-events &quot;&quot;############################### ADVANCED CONFIG 高级设置 ################################ Hashes are encoded using a memory efficient data structure when they have a# small number of entries, and the biggest entry does not exceed a given# threshold. These thresholds can be configured using the following directives.hash-max-ziplist-entries 512hash-max-ziplist-value 64# Lists are also encoded in a special way to save a lot of space.# The number of entries allowed per internal list node can be specified# as a fixed maximum size or a maximum number of elements.# For a fixed maximum size, use -5 through -1, meaning:# -5: max size: 64 Kb &lt;-- not recommended for normal workloads# -4: max size: 32 Kb &lt;-- not recommended# -3: max size: 16 Kb &lt;-- probably not recommended# -2: max size: 8 Kb &lt;-- good# -1: max size: 4 Kb &lt;-- good# Positive numbers mean store up to _exactly_ that number of elements# per list node.# The highest performing option is usually -2 (8 Kb size) or -1 (4 Kb size),# but if your use case is unique, adjust the settings as necessary.list-max-ziplist-size -2# Lists may also be compressed.# Compress depth is the number of quicklist ziplist nodes from *each* side of# the list to *exclude* from compression. The head and tail of the list# are always uncompressed for fast push/pop operations. Settings are:# 0: disable all list compression# 1: depth 1 means &quot;don&apos;t start compressing until after 1 node into the list,# going from either the head or tail&quot;# So: [head]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[tail]# [head], [tail] will always be uncompressed; inner nodes will compress.# 2: [head]-&gt;[next]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[prev]-&gt;[tail]# 2 here means: don&apos;t compress head or head-&gt;next or tail-&gt;prev or tail,# but compress all nodes between them.# 3: [head]-&gt;[next]-&gt;[next]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[prev]-&gt;[prev]-&gt;[tail]# etc.list-compress-depth 0# Sets have a special encoding in just one case: when a set is composed# of just strings that happen to be integers in radix 10 in the range# of 64 bit signed integers.# The following configuration setting sets the limit in the size of the# set in order to use this special memory saving encoding.set-max-intset-entries 512# Similarly to hashes and lists, sorted sets are also specially encoded in# order to save a lot of space. This encoding is only used when the length and# elements of a sorted set are below the following limits:zset-max-ziplist-entries 128zset-max-ziplist-value 64# HyperLogLog sparse representation bytes limit. The limit includes the# 16 bytes header. When an HyperLogLog using the sparse representation crosses# this limit, it is converted into the dense representation.## A value greater than 16000 is totally useless, since at that point the# dense representation is more memory efficient.## The suggested value is ~ 3000 in order to have the benefits of# the space efficient encoding without slowing down too much PFADD,# which is O(N) with the sparse encoding. The value can be raised to# ~ 10000 when CPU is not a concern, but space is, and the data set is# composed of many HyperLogLogs with cardinality in the 0 - 15000 range.hll-sparse-max-bytes 3000# Active rehashing uses 1 millisecond every 100 milliseconds of CPU time in# order to help rehashing the main Redis hash table (the one mapping top-level# keys to values). The hash table implementation Redis uses (see dict.c)# performs a lazy rehashing: the more operation you run into a hash table# that is rehashing, the more rehashing &quot;steps&quot; are performed, so if the# server is idle the rehashing is never complete and some more memory is used# by the hash table.## The default is to use this millisecond 10 times every second in order to# actively rehash the main dictionaries, freeing memory when possible.## If unsure:# use &quot;activerehashing no&quot; if you have hard latency requirements and it is# not a good thing in your environment that Redis can reply from time to time# to queries with 2 milliseconds delay.## use &quot;activerehashing yes&quot; if you don&apos;t have such hard requirements but# want to free memory asap when possible.activerehashing yes# The client output buffer limits can be used to force disconnection of clients# that are not reading data from the server fast enough for some reason (a# common reason is that a Pub/Sub client can&apos;t consume messages as fast as the# publisher can produce them).## The limit can be set differently for the three different classes of clients:## normal -&gt; normal clients including MONITOR clients# slave -&gt; slave clients# pubsub -&gt; clients subscribed to at least one pubsub channel or pattern## The syntax of every client-output-buffer-limit directive is the following:## client-output-buffer-limit &lt;class&gt; &lt;hard limit&gt; &lt;soft limit&gt; &lt;soft seconds&gt;## A client is immediately disconnected once the hard limit is reached, or if# the soft limit is reached and remains reached for the specified number of# seconds (continuously).# So for instance if the hard limit is 32 megabytes and the soft limit is# 16 megabytes / 10 seconds, the client will get disconnected immediately# if the size of the output buffers reach 32 megabytes, but will also get# disconnected if the client reaches 16 megabytes and continuously overcomes# the limit for 10 seconds.## By default normal clients are not limited because they don&apos;t receive data# without asking (in a push way), but just after a request, so only# asynchronous clients may create a scenario where data is requested faster# than it can read.## Instead there is a default limit for pubsub and slave clients, since# subscribers and slaves receive data in a push fashion.## Both the hard or the soft limit can be disabled by setting them to zero.client-output-buffer-limit normal 0 0 0client-output-buffer-limit slave 256mb 64mb 60client-output-buffer-limit pubsub 32mb 8mb 60# Client query buffers accumulate new commands. They are limited to a fixed# amount by default in order to avoid that a protocol desynchronization (for# instance due to a bug in the client) will lead to unbound memory usage in# the query buffer. However you can configure it here if you have very special# needs, such us huge multi/exec requests or alike.## client-query-buffer-limit 1gb# In the Redis protocol, bulk requests, that are, elements representing single# strings, are normally limited ot 512 mb. However you can change this limit# here.## proto-max-bulk-len 512mb# Redis calls an internal function to perform many background tasks, like# closing connections of clients in timeout, purging expired keys that are# never requested, and so forth.## Not all tasks are performed with the same frequency, but Redis checks for# tasks to perform according to the specified &quot;hz&quot; value.## By default &quot;hz&quot; is set to 10. Raising the value will use more CPU when# Redis is idle, but at the same time will make Redis more responsive when# there are many keys expiring at the same time, and timeouts may be# handled with more precision.## The range is between 1 and 500, however a value over 100 is usually not# a good idea. Most users should use the default of 10 and raise this up to# 100 only in environments where very low latency is required.hz 10# When a child rewrites the AOF file, if the following option is enabled# the file will be fsync-ed every 32 MB of data generated. This is useful# in order to commit the file to the disk more incrementally and avoid# big latency spikes.aof-rewrite-incremental-fsync yes# Redis LFU eviction (see maxmemory setting) can be tuned. However it is a good# idea to start with the default settings and only change them after investigating# how to improve the performances and how the keys LFU change over time, which# is possible to inspect via the OBJECT FREQ command.## There are two tunable parameters in the Redis LFU implementation: the# counter logarithm factor and the counter decay time. It is important to# understand what the two parameters mean before changing them.## The LFU counter is just 8 bits per key, it&apos;s maximum value is 255, so Redis# uses a probabilistic increment with logarithmic behavior. Given the value# of the old counter, when a key is accessed, the counter is incremented in# this way:## 1. A random number R between 0 and 1 is extracted.# 2. A probability P is calculated as 1/(old_value*lfu_log_factor+1).# 3. The counter is incremented only if R &lt; P.## The default lfu-log-factor is 10. This is a table of how the frequency# counter changes with a different number of accesses with different# logarithmic factors:## +--------+------------+------------+------------+------------+------------+# | factor | 100 hits | 1000 hits | 100K hits | 1M hits | 10M hits |# +--------+------------+------------+------------+------------+------------+# | 0 | 104 | 255 | 255 | 255 | 255 |# +--------+------------+------------+------------+------------+------------+# | 1 | 18 | 49 | 255 | 255 | 255 |# +--------+------------+------------+------------+------------+------------+# | 10 | 10 | 18 | 142 | 255 | 255 |# +--------+------------+------------+------------+------------+------------+# | 100 | 8 | 11 | 49 | 143 | 255 |# +--------+------------+------------+------------+------------+------------+## NOTE: The above table was obtained by running the following commands:## redis-benchmark -n 1000000 incr foo# redis-cli object freq foo## NOTE 2: The counter initial value is 5 in order to give new objects a chance# to accumulate hits.## The counter decay time is the time, in minutes, that must elapse in order# for the key counter to be divided by two (or decremented if it has a value# less &lt;= 10).## The default value for the lfu-decay-time is 1. A Special value of 0 means to# decay the counter every time it happens to be scanned.## lfu-log-factor 10# lfu-decay-time 1########################### ACTIVE DEFRAGMENTATION 自动碎片整理######################### WARNING 此功能是实验性的。但是在生产过程中也进行了压力测试，并且由多位工程师手动测试一段时间。## 什么是自动碎片整理?# -------------------------------## 碎片整理允许Redis服务器压缩存储器中小分配和释放数据之间的空间，从而允许回收内存。## 碎片是每个分配器都会发生的自然过程（但幸运的是，Jemalloc并不如此），以及某些工作负载。 # 通常情况下，需要重新启动服务器以降低碎片，或至少清除所有数据并重新创建。 # 然而，由于Oran Agra为Redis 4.0实现的这个特性，这个过程可以在运行时以“热”的方式发生，而服务器并不会停止。## 基本上，当碎片超过特定级别时（请参阅下面的配置选项）# Redis将开始通过利用某些特定的Jemalloc功能（为了理解分配是否导致分段并将其分配到更好的位置）而在连续内存区域中创建值的新副本，# 并且同时将释放 旧的数据副本。 此过程对所有键重复递增将导致碎片回落到正常值。## 重要了解的几点：## 1. 此功能在默认情况下处于禁用状态，只有在编译Redis时才能使用我们随Redis源代码一起提供的Jemalloc副本。 这是Linux版本的默认设置。## 2. 如果您没有碎片问题，则永远不需要启用此功能。## 3. 一旦遇到碎片，您可以在需要时使用命令“CONFIG SET activedefrag yes”启用此功能。## 配置参数能够微调碎片整理过程的行为。 如果您不确定它们的含义，最好保持默认值不变。# 开启碎片整理# activedefrag yes# 最小量的碎片浪费来启动主动碎片整理# active-defrag-ignore-bytes 100mb# 碎片启动主动碎片整理的最小百分比# active-defrag-threshold-lower 10# 我们使用最大努力的最大碎片百分比# active-defrag-threshold-upper 100# 在CPU百分比中进行碎片整理的最小努力# active-defrag-cycle-min 25# 在CPU百分比中进行碎片整理的最大努力# active-defrag-cycle-max 75","categories":[{"name":"other","slug":"other","permalink":"https://www.icepear.cn/categories/other/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://www.icepear.cn/tags/Redis/"}]},{"title":"mysql 配置解析","slug":"mysql/mysql-conf","date":"2018-06-20T11:30:02.000Z","updated":"2020-05-12T08:43:44.997Z","comments":true,"path":"2018/06/20/mysql/mysql-conf/","link":"","permalink":"https://www.icepear.cn/2018/06/20/mysql/mysql-conf/","excerpt":"最近对mysql的配置进行了了解，通过一些文档，所以把配置的一些参数都罗列了一下","text":"最近对mysql的配置进行了了解，通过一些文档，所以把配置的一些参数都罗列了一下 下载链接文件的下载链接 配置文件 docker 运行12345678910docker run --name mysql \\ -p 3306:3306 \\ -v $PWD/mysql/conf:/etc/mysql/conf.d \\ -v $PWD/mysql/mnt:/home/mnt \\ -v $PWD/mysql/db:/var/lib/mysql \\ -v $PWD/mysql/logs:/home/log \\ -v $PWD/mysql/audit:/home/audit \\ -e MYSQL_ROOT_PASSWORD=123456 \\ -e TZ=Asia/Shanghai \\ --restart=always -d mysql 配置内容123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280# 自用Docker MySql5.7配置文件my.cnf设置 # 可参考https://dev.mysql.com/doc/refman/5.7/en/server-system-variables.html[mysqld]pid-file = /var/run/mysqld/mysqld.pidsocket = /var/run/mysqld/mysqld.sockdatadir = /var/lib/mysql# 支持符号链接，就是可以通过软连接的方式，管理其他目录的数据库，最好不要开启，当一个磁盘或分区空间不够时，# 可以开启该参数将数据存储到其他的磁盘或分区。使用命令 ln -s /dr1/databases/test /path/to/datadir# 参考 https://dev.mysql.com/doc/refman/8.0/en/symbolic-links-to-databases.htmlsymbolic-links=0# 此变量用于限制数据导入和导出操作的效果，例如由LOAD DATA和SELECT ... INTO OUTFILE语句和LOAD_FILE（）函数执行的操作。# 这些操作只允许拥有FILE权限的用户使用。NULL值为禁用导入导出secure-file-priv= NULLskip-host-cache# 只能用IP地址检查客户端的登录，不用主机名skip-name-resolve#####################基础设置################## Mysql服务的唯一编号 每个mysql服务Id需唯一server-id = 1# 服务端口号 默认3306port = 3306# 用户名 默认root# user = mysql# 默认值为本地地址# bind_address = 127.0.0.1# 主要用于MyISAM存储引擎,如果多台服务器连接一个数据库则建议注释下面内容# skip-external-locking# 设置autocommit=0，则用户将一直处于某个事务中，直到执行一条commit提交或rollback语句才会结束当前事务重新开始一个新的事务。# set autocommit=0的好处是在频繁开启事务的场景下，减少一次begin的交互。autocommit = 1# utf8mb4编码是utf8编码的超集，兼容utf8，并且能存储4字节的表情字符。 # 采用utf8mb4编码的好处是：存储与获取数据的时候，不用再考虑表情字符的编码与解码问题。character_set_server=utf8mb4# 数据库字符集对应一些排序等规则，注意要和character-set-server对应collation-server = utf8mb4_general_ci# 设置client连接mysql时的字符集,防止乱码init_connect=&apos;SET NAMES utf8mb4&apos;# 事务隔离级别，默认为可重复读，mysql默认可重复读级别transaction_isolation = REPEATABLE-READ# 是否区分大小写，0区分，1不区分，2，表名存储以规定格式存，但比较还是用小写lower_case_table_names = 1# 最大连接数max_connections = 800# 在MySQL暂时停止响应新请求之前的短时间内多少个请求可以被存在堆栈中# 官方建议back_log = 50 + (max_connections / 5),封顶数为900back_log = 210# 最大错误连接数，对于同一主机，如果有超出该参数值个数的中断错误连接，则该主机将被禁止连接。# 如需对该主机进行解禁，执行：FLUSH HOST。max_connect_errors = 1000# TIMESTAMP如果没有显示声明NOT NULL，允许NULL值explicit_defaults_for_timestamp = true# SQL数据包发送的大小，如果有BLOB对象建议修改成1Gmax_allowed_packet = 128M# MySQL连接闲置超过一定时间后(单位：秒)将会被强行关闭# MySQL默认的wait_timeout 值为8个小时, interactive_timeout参数需要同时配置才能生效interactive_timeout = 1800wait_timeout = 1800# 临时目录 比如load data infile会用到tmpdir = /tmp# 内部内存临时表的最大值 ，默认64M，设置成128M。# 比如大数据量的group by ,order by时可能用到临时表，# 超过了这个值将写入磁盘，系统IO压力增大tmp_table_size = 134217728max_heap_table_size = 134217728# MySQL读入缓冲区的大小，该参数对应的分配内存是每连接独占（以字节为单位）。# 如果您执行多次连续扫描，则可能需要增加此值，该值默认为131072.此变量的值应为4KB的倍数。# 如果设置的值不是4KB的倍数，则其值将舍入到4KB的最接近倍数。现在都是InnerDB存储引擎，设置作用不大read_buffer_size = 8388608# MySQL的随机读缓冲区大小，将该变量设置为较大的值可以大大提高ORDER BY的性能。# 但是，这是为每个客户端分配的缓冲区，因此您不应将全局变量设置为较大的值。# 相反，只需从需要运行大型查询的客户端中更改会话变量。默认值256kb 所以设值2Mread_rnd_buffer_size = 2097152# MySQL在完成某些join（连接）需求的时候，为了减少参与join的“被驱动表”的读取次数以提高性能，需要使用到join buffer来协助完成join操作# 当join buffer 太小，MySQL不会将该buffer存入磁盘文件而是先将join buffer中的结果与需求join的表进行操作，# 然后清空join buffer中的数据，继续将剩余的结果集写入次buffer中，默认值262144，对应的也是每个独占连接join_buffer_size = 8388608# MySQL的顺序读缓冲区大小 order by或group by时用到，建议先用4M试一下，对应的也是每个独占连接sort_buffer_size = 4194304#一般数据库中没什么大的事务，设成1~2M，默认32kbbinlog_cache_size = 524288####################日志设置########################## 数据库错误日志文件(针对docker)log_error = /home/log/error.log# 慢查询sql日志设置slow_query_log = 1slow_query_log_file = /home/log/slow.log# 检查未使用到索引的sqllog_queries_not_using_indexes = 1# 针对log_queries_not_using_indexes开启后，记录慢sql的频次、每分钟记录的条数log_throttle_queries_not_using_indexes = 5# 作为从库时生效,从库复制中如何有慢sql也将被记录log_slow_slave_statements = 1# 慢查询执行的秒数，必须达到此值可被记录long_query_time = 8# 检索的行数必须达到此值才可被记为慢查询min_examined_row_limit = 1000# mysql binlog日志文件保存的过期时间，过期后自动删除expire_logs_days = 7####################主从复制设置########################## 参考https://dev.mysql.com/doc/refman/5.7/en/replication-options.html# 将master.info和relay.info保存在表中master_info_repository = TABLErelay_log_info_repository = TABLE# 开启mysql binlog二进制日志功能log_bin = /var/lib/mysql/mysql-bin# 当每进行n次事务提交之后，MySQL将进行一次fsync之类的磁盘同步指令来将binlog_cache中的数据强制写入磁盘。设置为零是让系统自行决定# 为1时安全性高，只丢失一次事物数据，消耗同样也大sync_binlog = 5# 从服务器的更新是否写入二进制日志，从库必须开启了二进制日志功能log_slave_updates = 1# 开启全局事务ID，GTID能够保证让一个从服务器到其他的从服务器那里实现数据复制而且能够实现数据整合的gtid_mode = on# 开启gtid，必须主从全开enforce_gtid_consistency = 1# 开启简单gtid，开启此项会提升mysql执行恢复的性能binlog_gtid_simple_recovery = 1# 从服务器的更新是否写入二进制日志log_slave_updates = 1# 三种模式 STATEMENT（有可能主从数据不一致，日质量小）版本小于5.7.6的默认值；ROW（产生大量二进制日志）版本大于5.7.7的默认值、MIXEDbinlog_format = row# 对于binlog_format = ROW模式时，减少记录日志的内容，只记录受影响的列# full（记录所有列）默认# minimal（仅记录更改的列和标识行所需的列）# noblob（记录所有列，除了不需要的blob和文本列）binlog_row_image = minimal# relay-log日志记录的是从服务器I/O线程将主服务器的二进制日志读取过来记录到从服务器本地文件，然后SQL线程会读取relay-log日志的内容并应用到从服务器relay_log = /home/log/relay.log# 作为从库时生效,中继日志relay-log可以自我修复relay_log_recovery = 1# 作为从库时生效,主从复制时忽略的错误slave_skip_errors = ddl_exist_errors#######################Innodb设置######################### 参考 https://dev.mysql.com/doc/refman/5.7/en/innodb-parameters.html# 这个参数在一开始初始化时就要加入my.cnf里，如果已经创建了表，再修改，启动MySQL会报错。最好为8K#innodb_page_size = 16384innodb_page_size = 8192# 数据缓冲区buffer pool大小，建议使用物理内存的 75%innodb_buffer_pool_size = 8G# 缓冲池实例数量，当buffer_pool的值较大的时候为1，较小的设置为8innodb_buffer_pool_instances = 8# 运行时load缓冲池，快速预热缓冲池，将buffer pool的内容（文件页的索引）dump到文件中，然后快速load到buffer pool中。# 避免了数据库的预热过程，提高了应用访问的性能 默认值(&gt;= 5.7.7) 开启;默认值(&lt;= 5.7.6)关闭。innodb_buffer_pool_load_at_startup = 1# 运行时dump缓冲池 默认值(&gt;= 5.7.7) 开启;默认值(&lt;= 5.7.6)关闭。innodb_buffer_pool_dump_at_shutdown = 1# 在innodb中处理用户查询后，其结果在内存空间的缓冲池已经发生变化，但是还未记录到磁盘。这种页面称为脏页，将脏页记录到磁盘的过程称为刷脏innodb_lru_scan_depth = 2000# 参数设置innodb后台任务每秒执行的I / O操作数量的上限，默认值200，好的硬盘可适当调高innodb_io_capacity = 4000# 突破innodb_io_capacity后的上限值innodb_io_capacity_max = 8000# 事务等待获取资源等待的最长时间，超过这个时间还未分配到资源则会返回应用失败，默认50sinnodb_lock_wait_timeout = 30# 设置redoLog文件所在目录, redoLog记录事务具体操作内容，默认为data的home目录：# 系统不会创建该目录，请确保目录已经存在#innodb_log_group_home_dir = /home/log/redolog# 设置undoLog文件所在目录, undoLog用于事务回滚操作#innodb_undo_directory = /home/log/undolog# 这个参数控制着innodb数据文件及redo log的打开、刷写模式# fsync InnoDB 使用fsync（）系统调用来刷新数据和日志文件。fsync是默认设置。# O_DIRECT 不经过系统缓存直接存入磁盘，减少操作系统级别VFS的缓存和Innodb本身的buffer缓存之间的冲突，适用于某些GNU/Linux versions, FreeBSD, and Solaris.# 根据官方提示还有其他选项好像都不可用，Docker官方镜像不支持O_DIRECT#innodb_flush_method = O_DIRECT# 表空间innodb文件格式。支持的文件格式是Antelope和Barracuda# Antelope是原始的innodb文件格式，它支持冗余和紧凑的行格式。# Barracuda是较新的文件格式，它支持压缩和动态行格式。默认值(&gt;= 5.7.7) Barracuda 默认值(&lt;= 5.7.6) Antelope# 但是这两个选项都被弃用了，在后面版本会删除# innodb_file_format = Barracuda# innodb_file_format_max = Barracuda# 当启用innodb_strict_mode时，innodb在某些情况下返回错误而不是警告。默认值(&gt;= 5.7.7) 开启；默认值(&lt;= 5.7.6) 关闭#innodb_strict_mode = 1# 当启用innodb_file_per_table（默认值 开启）时，innodb将每个新创建的表的数据和索引存储在单独的.ibd文件中，而不是系统表空间中。# 当这些表被删除或截断时，这些表的存储将被回收。缺点会导致单个表文件过大innodb_file_per_table = 1# undo日志回滚段 默认为128innodb_undo_logs = 128# 传统机械硬盘建议使用，而对于固态硬盘可以关闭#innodb_flush_neighbors = 1# 日志文件大小1G，默认48M innodb_log_file_size = 1073741842innodb_log_buffer_size = 16777216# 专用于innodb清除操作的后台线程的数量。最小值为1表示清除操作总是由后台线程执行，而不是主线程的一部分。# 在一个或多个后台线程中运行清除操作有助于减少innodb内部的争用，提高可伸缩性。将值增加到大于1会创建许多单独的清除线程，这可以提高在多个表上执行dml操作的系统的效率。# (&gt;= 5.7.8)默认值是4，(&lt;= 5.7.7)默认值是1，最大值是32。innodb_purge_threads = 4# 改为ON时，允许单列索引最大达到3072。否则最大为767，也已经弃用#innodb_large_prefix = 1# innodb中同时保持操作系统线程的数量小于或等于此变量（innodb使用操作系统线程处理用户事务）给出的限制。# 一旦线程数量达到此限制，额外的线程就会进入“先进先出”（fifo）队列中的等待状态以供执行。等待锁的线程数不计入并发执行线程数。# 值范围0-1000,0表示无限并发。如果工作负载的并发用户线程数小于64，建议用默认值0，否则需要视情况进行调整innodb_thread_concurrency = 0# 开启后会将所有的死锁记录到error_log中innodb_print_all_deadlocks = 1# 用于在创建innodb索引期间对数据进行排序的排序缓冲区的大小，仅用于索引创建期间的合并排序，而不用于以后的索引维护操作。innodb_sort_buffer_size = 8338608","categories":[{"name":"mysql","slug":"mysql","permalink":"https://www.icepear.cn/categories/mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.icepear.cn/tags/Mysql/"}]},{"title":"代理模式（proxy）","slug":"designpattern/proxy","date":"2018-03-21T14:30:00.000Z","updated":"2020-03-23T10:13:38.902Z","comments":true,"path":"2018/03/21/designpattern/proxy/","link":"","permalink":"https://www.icepear.cn/2018/03/21/designpattern/proxy/","excerpt":"代理(Proxy)是一种设计模式,提供了间接对目标对象进行访问的方式;即通过代理对象访问目标对象.这样做的好处是:可以在目标对象实现的功能上,增加额外的功能补充,即扩展目标对象的功能.符合开闭原则，即在对既有代码不改动的情况下，增加代码进行功能的扩展。","text":"代理(Proxy)是一种设计模式,提供了间接对目标对象进行访问的方式;即通过代理对象访问目标对象.这样做的好处是:可以在目标对象实现的功能上,增加额外的功能补充,即扩展目标对象的功能.符合开闭原则，即在对既有代码不改动的情况下，增加代码进行功能的扩展。 背景歌手与经纪人之间就是被代理和代理的关系,歌手出演活动的时候，歌手就是一个目标对象,他只要负责活动中的节目,而其他琐碎的事情就交给他的经纪人。这就是典型的代理模式 分析代理模式实现分为三种: 静态代理 动态代理 cglib代理 静态代理 抽象主题类 123456public interface Subject &#123; /** * 接口方法 */ public void request();&#125; 具体主题类 123456789public class ConcreteSubject implements Subject &#123; /** * 具体的业务逻辑实现 */ @Override public void request() &#123; //业务处理逻辑 &#125;&#125; 代理类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class Proxy implements Subject &#123; /** * 要代理的实现类 */ private Subject subject = null; /** * 默认代理自己 */ public Proxy() &#123; this.subject = new Proxy(); &#125; public Proxy(Subject subject) &#123; this.subject = subject; &#125; /** * 构造函数，传递委托者 * * @param objects 委托者 */ public Proxy(Object... objects) &#123; &#125; /** * 实现接口方法 */ @Override public void request() &#123; this.before(); this.subject.request(); this.after(); &#125; /** * 预处理 */ private void before() &#123; //do something &#125; /** * 后处理 */ private void after() &#123; //do something &#125;&#125; 客户端类 1234567public class Client &#123; public static void main(String[] args) &#123; Subject subject = new ConcreteSubject(); Proxy proxy = new Proxy(subject); proxy.request(); &#125;&#125; 动态代理静态代理的意思呢，通过上面的案例就可以发现，他只能代理一个对象，可以理解为一个经纪人只能代理一个歌手的活动，这样就会产生很多的代理人。所以我们想办法通过一个代理类完成全部的代理功能，那么我们就需要用动态代理.动态代理就是在运行时，通过反射机制实现动态代理，并且能够代理各种类型的对象。 在Java中要想实现动态代理机制，需要java.lang.reflect.InvocationHandler接口和 java.lang.reflect.Proxy类的支持。 java.lang.reflect.InvocationHandler接口的定义12345package java.lang.reflect;public interface InvocationHandler &#123; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable;&#125; 参数解释： Object proxy 被代理对象 Method method 要调用的方法 Object[] args 方法调用时所需要的参数 java.lang.reflect.Proxy类的定义123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778public class Proxy implements java.io.Serializable &#123; private static final long serialVersionUID = -2222568056686623797L; /** parameter types of a proxy class constructor */ private static final Class&lt;?&gt;[] constructorParams = &#123; InvocationHandler.class &#125;; /** * a cache of proxy classes */ private static final WeakCache&lt;ClassLoader, Class&lt;?&gt;[], Class&lt;?&gt;&gt; proxyClassCache = new WeakCache&lt;&gt;(new KeyFactory(), new ProxyClassFactory()); /** * the invocation handler for this proxy instance. * @serial */ protected InvocationHandler h; /** * Prohibits instantiation. */ private Proxy() &#123; &#125; ········ //中间其他方法就不介绍了 //主要是这个创建的方法 @CallerSensitive public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException &#123; Objects.requireNonNull(h); final Class&lt;?&gt;[] intfs = interfaces.clone(); final SecurityManager sm = System.getSecurityManager(); if (sm != null) &#123; checkProxyAccess(Reflection.getCallerClass(), loader, intfs); &#125; /* * Look up or generate the designated proxy class. */ Class&lt;?&gt; cl = getProxyClass0(loader, intfs); /* * Invoke its constructor with the designated invocation handler. */ try &#123; if (sm != null) &#123; checkNewProxyPermission(Reflection.getCallerClass(), cl); &#125; final Constructor&lt;?&gt; cons = cl.getConstructor(constructorParams); final InvocationHandler ih = h; if (!Modifier.isPublic(cl.getModifiers())) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; cons.setAccessible(true); return null; &#125; &#125;); &#125; return cons.newInstance(new Object[]&#123;h&#125;); &#125; catch (IllegalAccessException|InstantiationException e) &#123; throw new InternalError(e.toString(), e); &#125; catch (InvocationTargetException e) &#123; Throwable t = e.getCause(); if (t instanceof RuntimeException) &#123; throw (RuntimeException) t; &#125; else &#123; throw new InternalError(t.toString(), t); &#125; &#125; catch (NoSuchMethodException e) &#123; throw new InternalError(e.toString(), e); &#125; &#125;&#125; 参数说明： ClassLoader loader 类的加载器 Class&lt;?&gt;[] interfaces 得到全部的接口 InvocationHandler h 得到InvocationHandler接口的子类的实例 主要就是利用反射构建出代理类 例子下面就是例子 目标接口类 1234//目标类接口interface ISinger&#123; void singing();&#125; 目标歌手类 12345678//目标类class Zxy implements ISinger&#123; @Override public void singing() &#123; System.out.println(\"张学友唱歌\"); &#125;&#125; 代理功能 123456789class SingerUtils&#123; public static void method1() &#123; System.out.println(\"增强方式一\"); &#125; public static void method2() &#123; System.out.println(\"增强方式二\"); &#125;&#125; 代理人预编译处理 12345678910111213class SingerInvocationHandle implements InvocationHandler&#123; private Object target; public void setTarget(Object target) &#123; this.target = target; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; SingerUtils.method1(); method.invoke(target, args); SingerUtils.method2(); return null; &#125;&#125; 创建代理人 12345678class SingerProxyFactory&#123; public static Object getProxy(Object target) &#123; SingerInvocationHandle handle = new SingerInvocationHandle(); handle.setTarget(target); Object proxy = Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), handle); return proxy; &#125;&#125; 测试 1234567891011public class ProxyDemo &#123; public static void main(String[] args) &#123; //张学友要开演唱会，首先张学友得唱歌 ISinger zxy = new Zxy(); //但是呢，唱歌有一些列的事情要准备，要找场地，音响，要卖门票等等事情，这就需要代理人来做，所以就创建一个歌手的代理人来办这些事情 ISinger proxy =(ISinger) SingerProxyFactory.getProxy(zxy); //演唱会开始 proxy.run(); &#125;&#125; cglib代理上面的代码中有个相同点就是都要求目标对象是实现一个接口的对象,然而并不是任何对象都会实现一个接口，也存在没有实现任何的接口的对象,这时就可以使用继承目标类以目标对象子类的方式实现代理,这种方法就叫做:Cglib代理，也叫作子类代理。 cglib 依赖第三方的jar实现 实现方式只列举关键代码 1234567891011121314151617181920212223 //实例化一个增强器，也就是cglib中的一个class generator Enhancer enhancer = new Enhancer(); //设置目标类 enhancer.setSuperclass(XXX.class); //设置拦截对象，这里直接使用匿名内部类写法 enhancer.setCallback(new MethodInterceptor() &#123; @Override public Object intercept(Object object , Method method, Object[] args, MethodProxy proxy) throws Throwable &#123; //todo 要做的前置处理 //使用proxy的invokeSuper方法来调用目标类的方法 proxy.invokeSuper(object, args); // todo 要做的后置处理 return null; &#125; &#125;);//然后调用时,用enhancer 创建出代理目标对象XXX xxx = (XXX) enhancer.create();xxx.run();","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://www.icepear.cn/categories/设计模式/"}],"tags":[{"name":"代理模式","slug":"代理模式","permalink":"https://www.icepear.cn/tags/代理模式/"}]},{"title":"桥接模式（bridger）","slug":"designpattern/bridger","date":"2018-03-19T13:30:00.000Z","updated":"2020-03-23T10:12:56.128Z","comments":true,"path":"2018/03/19/designpattern/bridger/","link":"","permalink":"https://www.icepear.cn/2018/03/19/designpattern/bridger/","excerpt":"桥接模式,组合两个对象的机器,比如我们拿画笔为例子，笔有铅笔、蜡笔、水彩笔等等，而不同的笔又有不同的颜色，如果我们用七种颜色和三只不同种类的笔的话，按照普通的逻辑，我们就需要创建二十一个类来对应不同的笔，但是有的同学就会讲了可以用工厂模式啊，对的，但是我们看待问题的角度不一样，之所以称工厂模式为创建型模式，就是用这种方法来构建出现实对象。而桥接模式是属于结构型，就是两个对象通过用一种协同的模式，让他们达到想要的逻辑。","text":"桥接模式,组合两个对象的机器,比如我们拿画笔为例子，笔有铅笔、蜡笔、水彩笔等等，而不同的笔又有不同的颜色，如果我们用七种颜色和三只不同种类的笔的话，按照普通的逻辑，我们就需要创建二十一个类来对应不同的笔，但是有的同学就会讲了可以用工厂模式啊，对的，但是我们看待问题的角度不一样，之所以称工厂模式为创建型模式，就是用这种方法来构建出现实对象。而桥接模式是属于结构型，就是两个对象通过用一种协同的模式，让他们达到想要的逻辑。 UMLuml图就是banner图，不再复述 案例还是采用简介上面的例子，用桥接模式来实现它。 首先我们创建图形抽象类，这个抽象类是关键，它里面必须包含我们实现类的接口，也就是说颜色的接口 123456789public abstract class Shape &#123; Color color; public void setColor(Color color) &#123; this.color = color; &#125; public abstract void draw();&#125; 然后是三个形状 12345678910111213141516171819202122public class Circle extends Shape&#123; public void draw() &#123; color.bepaint(\"正方形\"); &#125;&#125;public class Rectangle extends Shape&#123; public void draw() &#123; color.bepaint(\"长方形\"); &#125; &#125;public class Square extends Shape&#123; public void draw() &#123; color.bepaint(\"正方形\"); &#125; &#125; 颜色接口 123public interface Color &#123; public void bepaint(String shape);&#125; 然后是具体的颜色 123456789101112131415161718192021public class White implements Color&#123; public void bepaint(String shape) &#123; System.out.println(\"白色的\" + shape); &#125; &#125;public class Gray implements Color&#123; public void bepaint(String shape) &#123; System.out.println(\"灰色的\" + shape); &#125;&#125;public class Black implements Color&#123; public void bepaint(String shape) &#123; System.out.println(\"黑色的\" + shape); &#125;&#125; 最关键就看我们这个调用过程了，我们先创建白色的实现类，然后创建正方形图形，关键是融合的这一点，我们将图形上色，运用java多态的特性，设置白色的实现类，然后绘制图形的方法里再反过来调用颜色的绘制方法就实现了两个独立对象合作完成一件事情，而不是创建出一只白色的笔，再去绘制，这就区分出工厂和桥接的区别了。1234567891011public class Client &#123; public static void main(String[] args) &#123; //白色 Color white = new White(); //正方形 Shape square = new Square(); //白色的正方形 square.setColor(white); square.draw(); &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://www.icepear.cn/categories/设计模式/"}],"tags":[{"name":"桥接模式","slug":"桥接模式","permalink":"https://www.icepear.cn/tags/桥接模式/"}]},{"title":"适配器模式（adapter）","slug":"designpattern/adapter","date":"2018-03-18T12:30:00.000Z","updated":"2020-03-20T07:08:02.300Z","comments":true,"path":"2018/03/18/designpattern/adapter/","link":"","permalink":"https://www.icepear.cn/2018/03/18/designpattern/adapter/","excerpt":"适配器模式,连接两个接口的桥梁 ,适配器模式有两种，类适配器和对象适配器.","text":"适配器模式,连接两个接口的桥梁 ,适配器模式有两种，类适配器和对象适配器. 类适配器类适配器主要是使用继承的方式连接两个接口,众所周知，苹果电脑连投影仪都是需要转接头转换的，那么我们就用这个做例子。 电脑都可以投影，它又个投影的方法123public interface Computer&#123; void projection();&#125; 苹果电脑的实现类12345public class Mac implement Computer&#123; public void projection()&#123; // todo &#125;&#125; 投影仪有个展示的方法123public interface Projector&#123; void show();&#125; 假如你的工程中有这几个类，然后你发现，show()方法中要写的操作，就是Mac中的操作，如果你的投影仪要想直接支持苹果电脑接口，就必须在show方法中实现放映的方法，但是如果又来一个其他类型的电脑，则必须又要实现另外一个接口，那投影仪商就不要活了，所以，投影仪也比较硬气，老子就一个洞爱上不上，你不习惯，你可以戴螺纹的，或者戴胶点的；所以呢，小杜和小冈就这么发家致富了。 那么现在就来介绍小杜，哦不，介绍适配器1234567public class ProjectorAdapter extends Mac implement Projector&#123; //实现投影仪的展示方法 public void show()&#123; //调用苹果电脑的投影方法 projection(); &#125;&#125; 但是呢，此种类适配器不够灵活，java又不支持多继承，所以再来个其他类型的电脑，则又必须开一个适配器，才对得上。 对象适配器那么我们不用继承，可以用什么呢，相必大家都知道，不继承的话，那就直接放里面去new吧。 我们改造一下小杜投影仪适配插头。 123456789101112public class ProjectorAdapter implement Projector&#123; private Mac mac; public PlayerAdapter ()&#123; this.mac = new Mac(); &#125; //实现投影仪的示方法 public void show()&#123; //调用苹果电脑的投影方法 mac.projection(); &#125;&#125; 但是这样好像还不太行，遵循可以给多个电脑插的原则，只允许mac插好像不太合适。 再改造一下，直接传电脑进来不就成了么。123456789101112public class ProjectorAdapter implement Projector&#123; private Computer computer; public PlayerAdapter (Computer computer)&#123; this.computer = computer; &#125; //实现投影仪的示方法 public void show()&#123; //调用电脑的投影方法，至于什么电脑就看外面实例化的是个什么电脑 computer.projection(); &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://www.icepear.cn/categories/设计模式/"}],"tags":[{"name":"适配器模式","slug":"适配器模式","permalink":"https://www.icepear.cn/tags/适配器模式/"}]},{"title":"原型模式（builder）","slug":"designpattern/prototype","date":"2018-03-16T10:30:00.000Z","updated":"2018-05-24T10:15:28.370Z","comments":true,"path":"2018/03/16/designpattern/prototype/","link":"","permalink":"https://www.icepear.cn/2018/03/16/designpattern/prototype/","excerpt":"原型模式是构造性模式中的一种，它的宗旨就是创建重复的对象，通过克隆，充分保障性能。","text":"原型模式是构造性模式中的一种，它的宗旨就是创建重复的对象，通过克隆，充分保障性能。 源代码地址源码连接 UML类图就不画了，就是通过clone出一个新对象 #源码分析小刚热衷于大保健，还是通过小刚大保健的例子说明见注释分析一个大保健服务1234567891011121314151617181920212223242526public class BigHealthCare implements Cloneable&#123; private String serviceName;//服务名称 public BigHealthCare(String serviceName) &#123; this.serviceName = serviceName; &#125; public String getServiceName() &#123; return serviceName; &#125; public void setServiceName(String serviceName) &#123; this.serviceName = serviceName; &#125; @Override public BigHealthCare clone() throws CloneNotSupportedException &#123; return new BigHealthCare(serviceName); &#125; @Override public String toString() &#123; return \"&#123;\" + \"\\\"serviceName\\\":\\\"\" + serviceName + \"\\\"\" + \"&#125;\"; &#125;&#125; 小刚要做大保健1234567891011121314151617181920212223242526272829public class Test &#123; public static void main(String args[])&#123; //小刚要做大保健服务，但是大保健服务有很多种，有洗脚、按摩、papapa。 //小刚呼叫了一号技师，说要做个洗脚服务 BigHealthCare simpleBighealthcare = new BigHealthCare(\"洗脚\"); System.out.printf(\"一号技师给小刚做了个\"+simpleBighealthcare.getServiceName()+\"服务\\n\"); //小刚说一号技师不错，还想来个按摩，于是加了个服务 try &#123; BigHealthCare generalBighealthcare = simpleBighealthcare.clone(); generalBighealthcare.setServiceName(\"按摩\"); System.out.printf(\"一号技师给小刚做了个\"+generalBighealthcare.getServiceName()+\"服务\\n\"); &#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace(); &#125; //技师手法把小刚弄的欲罢不能，于是小刚还想加服务 try &#123; BigHealthCare specialBighealthcare = simpleBighealthcare.clone(); specialBighealthcare.setServiceName(\"papapa\"); System.out.printf(\"一号技师给小刚做了个\"+specialBighealthcare.getServiceName()+\"服务\\n\"); &#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace(); &#125; //那么问题来了小刚为什么要这么做呢，为什么不每次通过new一下叫个技师来呢？原因有二 //1.小刚服务做得正爽，也就是在run-time时期，可以实现动态加服务 //2.小刚觉得1号技师长得好，技术也好（保持对象原有状态），要是new了一个不好的来就不爽了（浪费资源）。 &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://www.icepear.cn/categories/设计模式/"}],"tags":[{"name":"原型模式","slug":"原型模式","permalink":"https://www.icepear.cn/tags/原型模式/"}]},{"title":"建造者模式（builder）","slug":"designpattern/builder","date":"2018-03-14T08:30:00.000Z","updated":"2018-05-24T10:15:18.399Z","comments":true,"path":"2018/03/14/designpattern/builder/","link":"","permalink":"https://www.icepear.cn/2018/03/14/designpattern/builder/","excerpt":"建造者模式属于设计模式中的构造性模式，也就是说该模式基本上是用在构建对象的时候。它的宗旨就是将一个复杂的事物，进行一步一步的构建，需要什么就拼接成什么。","text":"建造者模式属于设计模式中的构造性模式，也就是说该模式基本上是用在构建对象的时候。它的宗旨就是将一个复杂的事物，进行一步一步的构建，需要什么就拼接成什么。 源代码地址源码连接 UML类图如下： Derictor: 指挥人，哔哩吧啦说你这玩意儿要怎么建builder：抽象建造者，怎么建的一系列方法concreteBuilder：具体的劳动力，实现建造的方法product：具体的产品类 #源码分析给大家讲一个生动形象的例子，小刚喜欢大保健，没事就去洗洗脚按按摩。从这句话里面，我们就可以分析出一个模式。大保健：具体的产品小刚：享受服务的指挥人，要什么服务都由他决定老板：大保健服务的建造者 传统模式下，小刚要一个大保健服务是不是说：老板，做个大保健（new dabaojian()）服务就出来了。但是存在一个问题，这样叫出来的是个大保健，但是具体哪一些服务没有指定，老板肯定问你：都想做什么服务；那服务种类很多，不可能每次都是12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576new Dabaojian(\"洗脚\");new Dabaojian(\"洗脚\",\"按摩\");new Dabaojian(\"洗脚\",\"按摩\",\"papapa\");``` 服务千姿百态这样就会存在弊端。老板也想到这个问题了所以老板就会拼接各种服务给客人做成一个大保健具体见代码分析```javapublic class Bighealthcare &#123; private String xijiao; private String anmo; private String papapa; /** * 传统享受大保健服务就洗洗脚 * @param xijiao */ public Bighealthcare(String xijiao)&#123; this.xijiao = xijiao; &#125; /** * 舒服一点就加个按摩 * @param xijiao */ public Bighealthcare(String xijiao,String anmo)&#123; this.xijiao = xijiao; this.anmo = anmo; &#125; /** * 想更舒服就搞下特殊服务 * @param xijiao * @param anmo * @param papapa */ public Bighealthcare(String xijiao,String anmo,String papapa)&#123; this.xijiao = xijiao; this.anmo = anmo; this.papapa = papapa; &#125; /** * 建造者模式的大保健服务 */ public Bighealthcare(Builder builder)&#123; this.xijiao = builder.xijiao; this.anmo = builder.anmo; this.papapa = builder.papapa; &#125; protected static class Builder&#123; protected String xijiao; protected String anmo; protected String papapa; protected Builder xijiao(String xijiao)&#123; this.xijiao = xijiao; return this; &#125; protected Builder anmo(String anmo)&#123; this.anmo = anmo; return this; &#125; protected Builder papapa(String papapa)&#123; this.papapa = papapa; return this; &#125; protected Bighealthcare build()&#123; return new Bighealthcare(this); &#125; &#125; public void service()&#123; System.out.print(this.toString()); &#125; 小刚要做大保健了12345678910111213141516171819public class Test &#123; public static void main(String args[])&#123; //传统模式下的大保健服务 Bighealthcare tradition = new Bighealthcare(\"洗个脚\",\"按个摩\",\"ppp\"); tradition.service(); //建造器模式下的大保健服务，先构造一个大保健服务，具体要哪些项目可以一个个拼装，扩展方便 //运用《effective java》中说的，当构造方法过多时就应该要考虑使用构造器，其实就是建造者模式 //简单大保健 Bighealthcare simpleBighealthcare = new Bighealthcare.Builder().xijiao(\"洗个脚\").build(); simpleBighealthcare.service(); //一般大保健 Bighealthcare generalBighealthcare = new Bighealthcare.Builder().xijiao(\"洗个脚\").anmo(\"按个摩\").build(); generalBighealthcare.service(); //高级大保健 Bighealthcare specialBighealthcare = new Bighealthcare.Builder().xijiao(\"洗个脚\").anmo(\"按个摩\").papapa(\"ppp\").build(); specialBighealthcare.service(); &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://www.icepear.cn/categories/设计模式/"}],"tags":[{"name":"建造者模式","slug":"建造者模式","permalink":"https://www.icepear.cn/tags/建造者模式/"}]},{"title":"sql的优化","slug":"mysql/sql_optimization","date":"2017-11-15T10:00:00.000Z","updated":"2018-09-05T08:06:03.021Z","comments":true,"path":"2017/11/15/mysql/sql_optimization/","link":"","permalink":"https://www.icepear.cn/2017/11/15/mysql/sql_optimization/","excerpt":"在应用开发初期，由于数据量小，开发人员写sql时更加注重功能实现，但当应用上线后，数据量的上升，很多sql的性能问题就逐渐显露出来，成为系统性能的瓶颈，下面介绍一些优化方法","text":"在应用开发初期，由于数据量小，开发人员写sql时更加注重功能实现，但当应用上线后，数据量的上升，很多sql的性能问题就逐渐显露出来，成为系统性能的瓶颈，下面介绍一些优化方法 分析不管面对什么问题第一步肯定是分析，分析到底哪里出问题，然后再想解决方案。sql优化也不例外，所以第一步做的就是分析。 通过 show status 命令了解各种sql的执行频率通过命令 show [global/session] status 命令获取信息。 比较关心的参数如： Com_select 执行select操作的次数 Com_insert 执行insert的次数，批量插入只累加一次 Com_update 执行update的次数 Com_delete 执行delete的次数 针对InnoDB存储引擎，累加算法略有不同 Innodb_rows_read select 查询返回的行数 Innodb_rows_inserted 执行insert操作插入的行数 Innodb_rows_ updated 执行update操作更新的行数 Innodb_rows_delete 执行delete操作删除的行数 还有几个参数也比较重要，事物操作 Com_commit Com_rollback。数据库情况： Connections 试图连接mysql服务器的次数 Uptime 服务器工作时间 Slow_queries 慢查询的次数 定位执行效率极低的sql语句设置mysql慢查询，然后通过日志定位 见 mysql配置 通过EXPLAIN分析低效SQL的执行计划通过上面两个步骤查到效率低的sql后，可以通过explain或者desc命令获取select语句信息信息中的说明 select_type select的类型，SIMPLE 简单表、PRIMARY 主查询、UNION UNION中的第二个或后面的查询、SUBQUERY 子查询中的第一个select table 输出结果的表 type 表示mysql在表中找到所需行的方式，或者叫访问类型，常见类型ALL—-index—-range—-ref—-eq_ref—-const,system—-NULL从左到右，性能由差到好 possible_keys 表示查询时可能使用的索引 key 表示实际使用的索引 key_len 使用索引字段的长度 rows 扫描行的数量 extra 执行情况的说明和描述 通过explain extended之后再输入show warnings可以看到执行之前优化器做了哪些改动 通过 show profile 分析sql可以先通过select @@profiling查看数据库是否开启profiling 然后通过show profile查看sql执行的时间，以及query_id。然后可以通过show profile for query [query_id]查看执行过程中线程每个状态和消耗时间 索引B-Tree 索引 大部分支持HASH 索引 只有Memory引擎支持，适用于 key-value查询R-Tree 索引 MyISAM 特有，用于地理空间数据类型Full-text 全文索引 MyISAM 特有","categories":[{"name":"mysql","slug":"mysql","permalink":"https://www.icepear.cn/categories/mysql/"}],"tags":[{"name":"SQL Mysql","slug":"SQL-Mysql","permalink":"https://www.icepear.cn/tags/SQL-Mysql/"}]},{"title":"一张图带你理解sql的join","slug":"mysql/sql_join","date":"2017-08-15T10:00:00.000Z","updated":"2018-07-13T06:14:05.845Z","comments":true,"path":"2017/08/15/mysql/sql_join/","link":"","permalink":"https://www.icepear.cn/2017/08/15/mysql/sql_join/","excerpt":"在数据库查询中，连表查询是经常需要操作的，其关键字就是利用join，下面一张图带你充分理解各种join的意义","text":"在数据库查询中，连表查询是经常需要操作的，其关键字就是利用join，下面一张图带你充分理解各种join的意义","categories":[{"name":"mysql","slug":"mysql","permalink":"https://www.icepear.cn/categories/mysql/"}],"tags":[{"name":"SQL Mysql","slug":"SQL-Mysql","permalink":"https://www.icepear.cn/tags/SQL-Mysql/"}]},{"title":"gitlab提交管理","slug":"other/git-manage","date":"2017-08-09T11:30:02.000Z","updated":"2020-03-23T01:37:30.313Z","comments":true,"path":"2017/08/09/other/git-manage/","link":"","permalink":"https://www.icepear.cn/2017/08/09/other/git-manage/","excerpt":"在团队开发的项目中少不了gitlab作为代码管理库，遵循git的分支特性，总结了团队代码提交的一个标准，减少代码冲突带来的不可控因素。","text":"在团队开发的项目中少不了gitlab作为代码管理库，遵循git的分支特性，总结了团队代码提交的一个标准，减少代码冲突带来的不可控因素。 gitlab提交管理分支管理每个大任务需要开启一个临时分支，从dev分支branch出来；branch的名称根据tapd中大任务的ID的命名 成员本地 gitlab远程 临时 稳定 发版 | 任务a分支local_branch_id { &lt;—-pull/push—–&gt; 任务b分支&lt;—–MR(pass/refuse)—-&gt; dev —–MR——&gt; master | 任务c分支 创建分支 拉取dev稳定版本的最新代码 1git pull origin dev 创建本地分支并切换(tapd中大任务的ID) 1git checkout -b local_branch_id 创建远程分支并关联(local_branch_id:remote_branch_id一致) 1git push origin local_branch_id:remote_branch_id 合并请求(Merge Request)（gitlab不像github那样有类似于rebase merge操作，只能自己先rebase）任务开发完毕之后，自己可能存在多次commit的情况，但是针对于这一个大任务，其实只需要一次commit。所以在合并之前，需要rebase之间的commit。在合并之前，可能其他成员已经将代码合并到了dev，而自己的代码还是之前的，如果两人修改了同一个文件，直接提交合并请求，gitlab会提示存在冲突。所以针对于上面两种情况： 同步dev最新代码，解决冲突(pull and merge的语句就不写了) 变基rebase操作 首先使用git log 查看提交记录。 然后选择从某一个提交记录开始变基 git rebase -i commitId（git log可看到的md5的一串字符） 输完之后，会让你选择如何合并，pick 是合并基础，也就是合并之后会提现在这一次commit上。 squash 是将本次提交合并到pick的提交上。主要是这两个命令，其他的不加以说明 例如，下面我之前提交了三次；输入rebash之后进入VI界面，如果我需要合并到first上面，我就pick 第一个，后面的改为squash；然后esc，:wq保存 1234567891011121314pick f8ff805 firstsquash 7b0db2f secondsquash 8dc017c third# Rebase 9b9fd65..8dc017c onto 9b9fd65 (3 commands)## Commands:# p, pick = use commit# r, reword = use commit, but edit the commit message# e, edit = use commit, but stop for amending# s, squash = use commit, but meld into previous commit# f, fixup = like \"squash\", but discard this commit's log message# x, exec = run command (the rest of the line) using shell# d, drop = remove commit 保存之后，可以对这次rebase进行说明，同样是vi界面;添加说明之后也是:wq保存 123456789101112131415# This is a combination of 3 commits.大任务完成了，三个小任务包括# This is the 1st commit message:first# This is the commit message #2:second# This is the commit message #3:third# Please enter the commit message for your changes. Lines starting 变基完成，假如之前有把那三次commit，push到远程对应的临时分支，直接push会失败，则使用 git push origin remote_branch_id -f 提交到远程临时分支，并在gitlab上创建Merge Request 删除分支code review 通过merge到了dev分支后，则可以删除掉远程分支 用空分支的方式覆盖远程分支 git push origin :remote_branch_id 删除分支 git push origin –delete remote_branch_id","categories":[{"name":"other","slug":"other","permalink":"https://www.icepear.cn/categories/other/"}],"tags":[{"name":"git","slug":"git","permalink":"https://www.icepear.cn/tags/git/"}]},{"title":"接口安全策略","slug":"other/api-security","date":"2017-08-09T11:30:02.000Z","updated":"2018-04-20T07:07:22.324Z","comments":true,"path":"2017/08/09/other/api-security/","link":"","permalink":"https://www.icepear.cn/2017/08/09/other/api-security/","excerpt":"在做接口的时候，我们经常会对安全这方面进行考虑，包括认证授权，接口安全等方面，下面就介绍一种接口安全的设计，如果有什么其他好的设计，都可以在评论区提出交流","text":"在做接口的时候，我们经常会对安全这方面进行考虑，包括认证授权，接口安全等方面，下面就介绍一种接口安全的设计，如果有什么其他好的设计，都可以在评论区提出交流 背景为什么要对接口进行安全控制呢，主要是出于这几方面的因素 防伪装攻击 防篡改攻击 防重放攻击 防数据信息泄露 解决办法解决办法有很多，一般常见的做法是token校验然后加上HTTPS。针对这四种情况，假如接口没做任何安全策略是很容易被攻击的。对于第一种防伪装攻击，一般的接口都会带有token认证，可以过滤掉；对于第二种以及第三种，假如别人截获了请求，修改了参数，token机制是没办法做到安全的，所以有效的办法就是加密，加密的办法有很多。下面以图介绍我用的一种这种方法的步骤是 将请求参数（一般是json形式）加上约定好的salt进行AES加密，加密出来的是byte，一般用base64进行转码输出，也可做位偏移，得到一个加密字符串；然后加上后端的token，加上时间戳，进行MD5加密得到一个定长的sign字符串 将sign，toekn，时间戳，参数组成http请求去访问接口这样做的好处就是，针对第二三种攻击，别人拦击你的请求进行篡改，后端根据参数+约定好的salt进行AES加密再加上+token+时间戳进行MD5加密，与sign比对发现两个MD5不一致，就知道，肯定有人篡改了参数，就可以拒绝这样的请求。如果你不想参数直接暴露出来也可以进行AES加密传给后端。这样就可以避免第四种情况 总结以上都是自己的愚见，如果有更好的设计方法，欢迎交流学习","categories":[{"name":"security","slug":"security","permalink":"https://www.icepear.cn/categories/security/"}],"tags":[{"name":"api","slug":"api","permalink":"https://www.icepear.cn/tags/api/"},{"name":"security","slug":"security","permalink":"https://www.icepear.cn/tags/security/"}]},{"title":"go圣经阅读","slug":"other/gopl","date":"2017-08-09T10:30:02.000Z","updated":"2017-11-22T08:18:16.280Z","comments":true,"path":"2017/08/09/other/gopl/","link":"","permalink":"https://www.icepear.cn/2017/08/09/other/gopl/","excerpt":"学习一门新语言时，会有一种自然的倾向, 按照自己熟悉的语言的套路写新语言程序。学习Go语言的过程中，请警惕这种想法，尽量别这么做。我们会演示怎么写好Go语言程序，所以阅读了称之为《go圣经》这本书,并且利用思维导图的方式记录了重点。","text":"学习一门新语言时，会有一种自然的倾向, 按照自己熟悉的语言的套路写新语言程序。学习Go语言的过程中，请警惕这种想法，尽量别这么做。我们会演示怎么写好Go语言程序，所以阅读了称之为《go圣经》这本书,并且利用思维导图的方式记录了重点。","categories":[{"name":"go","slug":"go","permalink":"https://www.icepear.cn/categories/go/"}],"tags":[{"name":"go","slug":"go","permalink":"https://www.icepear.cn/tags/go/"}]},{"title":"ArrayList源码记录","slug":"javautil/arraylist","date":"2017-07-15T10:30:00.000Z","updated":"2018-09-05T07:52:18.082Z","comments":true,"path":"2017/07/15/javautil/arraylist/","link":"","permalink":"https://www.icepear.cn/2017/07/15/javautil/arraylist/","excerpt":"ArrayList是动态数组，也是java中最常用的数据结构，它提供了动态的增加和减少元素，实现了Collection和List接口，可以灵活的设置数组的大小。下面根据源码重点介绍","text":"ArrayList是动态数组，也是java中最常用的数据结构，它提供了动态的增加和减少元素，实现了Collection和List接口，可以灵活的设置数组的大小。下面根据源码重点介绍 简介ArrayList是动态数组，它的容量可以动态增长。它的底层实现还是基于数组，既然是数组，就知道这是类似线性表的顺序存储，插入删除元素的时间复杂度为O（n）,求表长以及增加元素，取第 i 元素的时间复杂度为O（1）。如果是默认add方法，则默认添加至列表末尾，也是O（1）;但是如果add(int index, E element)则就是O（n）。 ArrayList 继承了AbstractList，实现了List。它是一个数组队列，提供了相关的添加、删除、修改、遍历等功能。 ArrayList 实现了RandmoAccess 接口，即提供了随机访问功能。RandmoAccess 是 Java 中用来被 List 实现，为 List 提供快速访问功能的。在 ArrayList 中，我们即可以通过元素的序号快速获取元素对象，这就是快速随机访问。 ArrayList 实现了Cloneable 接口，即覆盖了函数 clone()，能被克隆。 ArrayList 实现java.io.Serializable 接口，这意味着ArrayList支持序列化，能通过序列化去传输。但是这里有个细节需要注意，transient Object[] elementData 保存数据的数组用transient修饰了，所以不能直接序列化，这是因为elementData是动态的，直接序列化会导致末尾的空元素也会序列化，所以ArrayList重写了writeObject和readObject方法 ArrayList 中的操作不是线程安全的！所以，建议在单线程中才使用 ArrayList，而在多线程中可以选择 Vector 或者 CopyOnWriteArrayList。 源码解析ArrayList基本结构如下代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable&#123; private static final long serialVersionUID = 8683452581122892189L; private static final int DEFAULT_CAPACITY = 10; //初始化容量 private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;;//用于空实例的共享空数组实例。 /** *用于默认大小的空实例的共享空数组实例。 *我们将此与EMPTY_ELEMENTDATA区分开来，以便在添加第一个元素时知道要扩大多少。 */ private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;; transient Object[] elementData; // 保存数据的数组 private int size;// ArrayList保存数据的数量 //规定初始大小的构造方法 public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException(\"Illegal Capacity: \"+ initialCapacity); &#125; &#125; //默认的构造方法 public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; &#125; /** * 构造一个包含指定集合的元素的列表，按照它们由集合的迭代器返回的顺序。 */ public ArrayList(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); if ((size = elementData.length) != 0) &#123; // c.toArray 可能返回的不是Object类型的数组所以加上下面的语句用于判断， //这里用到了反射里面的getClass()方法 if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // 空数组填充 this.elementData = EMPTY_ELEMENTDATA; &#125; &#125;&#125; 常用方法关键方法其实还在 扩容，所以针对扩容的一系列方法进行说明 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778/** * 默认add方法，添加至数组末尾 */public boolean add(E e) &#123; //判断size+1有没有大于最大容量，大于就进行扩容 ensureCapacityInternal(size + 1); elementData[size++] = e; return true;&#125;/** * 在此列表中的指定位置插入指定的元素。 * 先调用 rangeCheckForAdd 对index进行界限检查；然后调用 ensureCapacityInternal 方法保证capacity足够大； * 再将从index开始之后的所有成员后移一个位置；将element插入index位置；最后size加1。 */public void add(int index, E element) &#123; rangeCheckForAdd(index); //同上 ensureCapacityInternal(size + 1); System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++;&#125;/*** 确保容量有效*/private void ensureCapacityInternal(int minCapacity) &#123; //如果是初始化数组，就用默认容量10 if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); &#125; ensureExplicitCapacity(minCapacity);&#125;private void ensureExplicitCapacity(int minCapacity) &#123; //结构变化次数 modCount++; //大于现有容量就进行扩容 if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125;/** * 最大的数组大小，不能超出vm限制 */private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;/** * 扩容方法 */private void grow(int minCapacity) &#123; // oldCapacity为旧容量，newCapacity为新容量 int oldCapacity = elementData.length; //将oldCapacity 右移一位，新容量更新为旧容量的1.5倍， int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); //然后检查新容量是否大于最小需要容量，若还是小于最小需要容量，那么就把最小需要容量当作数组的新容量 if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; //再检查新容量是否超出了ArrayList所定义的最大容量， //若超出了，则调用hugeCapacity()来比较minCapacity和 MAX_ARRAY_SIZE， //如果minCapacity大于最大容量，则新容量则为ArrayList定义的最大容量，否则，新容量大小则为 minCapacity。 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // 调用底层的System.arraycopy方法，该方法是native方法用C实现 elementData = Arrays.copyOf(elementData, newCapacity);&#125;/*** 比较minCapacity和 MAX_ARRAY_SIZE*/private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE;&#125; 其他一些常用方法包括 size()、isEmpty()、contains(Object o)、indexOf(Object o)、toArray()、get(int index)、set(int index, E element) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134/** *返回此列表中的元素数。 */ public int size() &#123; return size; &#125; /** * 如果此列表不包含元素，则返回 true 。 */ public boolean isEmpty() &#123; //注意=和==的区别 return size == 0; &#125; /** * 如果此列表包含指定的元素，则返回true 。 */ public boolean contains(Object o) &#123; //indexOf()方法：返回此列表中指定元素的首次出现的索引，如果此列表不包含此元素，则为-1 return indexOf(o) &gt;= 0; &#125; /** *返回此列表中指定元素的首次出现的索引，如果此列表不包含此元素，则为-1 */ public int indexOf(Object o) &#123; if (o == null) &#123; for (int i = 0; i &lt; size; i++) if (elementData[i]==null) return i; &#125; else &#123; for (int i = 0; i &lt; size; i++) //equals()方法比较 if (o.equals(elementData[i])) return i; &#125; return -1; &#125; /** * 返回此列表中指定元素的最后一次出现的索引，如果此列表不包含元素，则返回-1。. */ public int lastIndexOf(Object o) &#123; if (o == null) &#123; for (int i = size-1; i &gt;= 0; i--) if (elementData[i]==null) return i; &#125; else &#123; for (int i = size-1; i &gt;= 0; i--) if (o.equals(elementData[i])) return i; &#125; return -1; &#125; /** * 返回此ArrayList实例的浅拷贝。 （元素本身不被复制。） */ public Object clone() &#123; try &#123; ArrayList&lt;?&gt; v = (ArrayList&lt;?&gt;) super.clone(); //Arrays.copyOf功能是实现数组的复制，返回复制后的数组。参数是被复制的数组和复制的长度 v.elementData = Arrays.copyOf(elementData, size); v.modCount = 0; return v; &#125; catch (CloneNotSupportedException e) &#123; // 这不应该发生，因为我们是可以克隆的 throw new InternalError(e); &#125; &#125; /** *以正确的顺序（从第一个到最后一个元素）返回一个包含此列表中所有元素的数组。 *返回的数组将是“安全的”，因为该列表不保留对它的引用。 （换句话说，这个方法必须分配一个新的数组）。 *因此，调用者可以自由地修改返回的数组。 此方法充当基于阵列和基于集合的API之间的桥梁。 */ public Object[] toArray() &#123; return Arrays.copyOf(elementData, size); &#125; /** * 以正确的顺序返回一个包含此列表中所有元素的数组（从第一个到最后一个元素）; *返回的数组的运行时类型是指定数组的运行时类型。 如果列表适合指定的数组，则返回其中。 *否则，将为指定数组的运行时类型和此列表的大小分配一个新数组。 *如果列表适用于指定的数组，其余空间（即数组的列表数量多于此元素），则紧跟在集合结束后的数组中的元素设置为null 。 *（这仅在调用者知道列表不包含任何空元素的情况下才能确定列表的长度。） */ @SuppressWarnings(\"unchecked\") public &lt;T&gt; T[] toArray(T[] a) &#123; if (a.length &lt; size) // 新建一个运行时类型的数组，但是ArrayList数组的内容 return (T[]) Arrays.copyOf(elementData, size, a.getClass()); //调用System提供的arraycopy()方法实现数组之间的复制 System.arraycopy(elementData, 0, a, 0, size); if (a.length &gt; size) a[size] = null; return a; &#125; // 位置访问操作 @SuppressWarnings(\"unchecked\") E elementData(int index) &#123; return (E) elementData[index]; &#125; /** * 返回此列表中指定位置的元素。 */ public E get(int index) &#123; rangeCheck(index); return elementData(index); &#125; /** * 用指定的元素替换此列表中指定位置的元素。 */ public E set(int index, E element) &#123; //对index进行界限检查 rangeCheck(index); E oldValue = elementData(index); elementData[index] = element; //返回原来在这个位置的元素 return oldValue; &#125; // 边界检查 private void rangeCheck(int index) &#123; if (index &gt;= size) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); &#125;","categories":[{"name":"java.util","slug":"java-util","permalink":"https://www.icepear.cn/categories/java-util/"}],"tags":[{"name":"ArrayList List","slug":"ArrayList-List","permalink":"https://www.icepear.cn/tags/ArrayList-List/"}]},{"title":"HashMap源码记录","slug":"javautil/hashmap","date":"2017-06-15T10:30:00.000Z","updated":"2020-03-20T07:53:32.747Z","comments":true,"path":"2017/06/15/javautil/hashmap/","link":"","permalink":"https://www.icepear.cn/2017/06/15/javautil/hashmap/","excerpt":"hashmap在java里是出现频率较高的类，不管是工作还是面试，掌握hashmap的原理是很重要的，本文也将从整体到细节介绍hashmap","text":"hashmap在java里是出现频率较高的类，不管是工作还是面试，掌握hashmap的原理是很重要的，本文也将从整体到细节介绍hashmap 摘要hashmap在java里是出现频率较高的类，不管是工作还是面试，掌握hashmap的原理是很重要。随着JDK版本的更新，HashMap底层的实现进行了优化，例如引入红黑树的数据结构和扩容的优化等。本文结合JDK1.7和JDK1.8的区别，深入探讨HashMap的结构实现和功能原理。 简介java中Map数据结构定义了一个主要的接口：java.util.Map。主要实现这个接口的类是：HashMap、HashTable、LinkedHashMap、TreeMap。关系如下下面针对各个实现类的特点做一些说明： (1) HashMap： 访问速度快hashcode直接定位，但遍历顺序却是不确定的。 最多只允许一条记录的键为null，允许多条记录的值为null。 非线程安全，可以用 Collections的synchronizedMap方法使HashMap具有线程安全的能力，或者使用ConcurrentHashMap。 (2) Hashtable：没什么卵用，基本上与HashMap类似、虽然线程安全，但介于HashMap与ConcurrentHashMap之间，不上不下。 (3) LinkedHashMap：LinkedHashMap是HashMap的一个子类，保存了记录的插入顺序。 (4) TreeMap： 它保存的记录根据键排序，默认是按键值的升序排序，也可以指定排序的比较器，当用Iterator遍历TreeMap时，得到的记录是排过序的。 如果使用排序的映射，建议使用TreeMap。在使用TreeMap时，key必须实现Comparable接口或者在构造TreeMap传入自定义的Comparator，否则会在运行时抛出java.lang.ClassCastException类型的异常。 本文主要讲HashMap的实现原理，结合1.7和1.8主要从存储结构，常用方法，定位，扩容等方面展开 存储结构存储结构如图： HashMap在1.7中只用到了数组和链表，代码也只有一千多行。上图展示的是1.8的存储结构，在1.8中加入了红黑树，在链表大于8的时候转换为红黑树；扩容后导致红黑树节点在小于6时，又会转换成链表。代码量虽然翻倍了，带来的确实性能的提升。HashMap 1.8结构代码如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // 16 默认hashmap的容量static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; //hashmap最大的容量static final float DEFAULT_LOAD_FACTOR = 0.75f; // 负载因子，跟扩容有关，后面会提到static final int TREEIFY_THRESHOLD = 8; //转换成红黑树的阀值static final int UNTREEIFY_THRESHOLD = 6;//红黑树转成链表的阀值static final int MIN_TREEIFY_CAPACITY = 64;//转换成红黑树最小需要hash数组中的数量大于64// Node 节点static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; //hash值 final K key; // 键 V value; // 值 Node&lt;K,V&gt; next; // 链表下一个节点 ··· //一些默认函数省略掉 &#125;transient Node&lt;K,V&gt;[] table; // 数组transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet; //缓存了hashmap中的nodetransient int size; //存储的node数量transient int modCount; //结构修改次数，跟Fail-Fast机制有关int threshold; // 能负载的node数量（Capacity*loadFactor）初识值 16*0.75 =12final float loadFactor; //负载因子//构造函数，程序员传初始化容量和负载因子进来（一般不用）因为0.75这个值是经过大量的统计计算得出来的结论，一般不更改//也就是说容量到达Capacity的0.75时，进行扩容操作。不至于loadFactor过大，导致hash碰撞过多，太小，扩容次数太多影响性能public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);&#125;// 构造函数，初始化容量（最好也是2的N次幂）这个会影响hash定位public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125;//最常用的构造函数，使用默认的0.75作为负载因子public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; &#125;// 构造函数，传一个map进来，复制到本hashmappublic HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false);//这个函数将用到m这个map中的entrySet，目的是将m中的node通过put函数复制到本hashmap中&#125;//树节点static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt; &#123; TreeNode&lt;K,V&gt; parent; // 根节点 TreeNode&lt;K,V&gt; left; // 左节点 TreeNode&lt;K,V&gt; right; // 右节点 TreeNode&lt;K,V&gt; prev; // 删除后需要取消链接 boolean red; //一些红黑树操作的函数 ···&#125; 实现说明主要从hashmap的主要三个步骤进行说明，hash定位，插入，扩容 hash定位hash定位是HashMap比较核心的方法了，上面我们了解到HashMap的结构为数组，既然是数组，就会有下标，那么这个hash值就是数组的下标，也正是HashMap可以根据key快速查找定位到Value的原因下面看下1.7中hash的源码 12345678910111213final int hash(Object k) &#123; int h = hashSeed; if (0 != h &amp;&amp; k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h ^= k.hashCode(); h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);&#125;static int indexFor(int h, int length) &#123; return h &amp; (length-1);&#125; 在1.8中做了改进 1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 1.8中虽然取消了indexFor函数，但是在put和get的时候都通过了 tab[i = (n - 1) &amp; hash] 来定位，原理跟1.7是一样的可以看出，不管是哪个版本，算法大致分为 取key的hashcode，高位运算 取模运算为了让hash值均匀分布，会采用高位运算，让小的值的高位也参与运算;然后拿运算后key的hashcode对数组的长度进行模运算定位数组中的位置，但是细心一点就会发现，取模运算并没有使用%运算，因为模运算是很耗费性能的，所以采用与运算，可以说这个与运算设计的是相当精巧了。这也就是为什么数组的长度一定要是2的N次幂长度的原因，因为当length等于2的n次幂时，h&amp;(length-1)就等于h%length put实现我们知道HashMap的时间复杂度为O(1)，但是当Hash碰撞率过高时hashmap就会遍历链表，导致某些情况时间复杂度提高至O(n)；所以好的hash算法以及扩容机制是相当重要的，下面就讲讲hashmap插入值的原理单纯的代码加文字，表现力可能没那么强，所以采用文字加流程图的方式进行说明：流程图： 源码解释: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 第1步 判断table是否为null，如果为空进行扩容 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 第2步 判断table中hash值对应的位置是否有值，就是table[i],如果没值，就new一个Node节点存入 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); //第3步 else &#123; Node&lt;K,V&gt; e; K k; //第3步 如果table[i]有值，就判断table[i]的key是否和要插入的值的key相同，相同则令节点e等于table[i] if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //第4步 不相同则判断table[i]是否为树节点，为树节点则将新值插入红黑树,如果红黑树里面存在这个值，也令e等于这个树节点，否则e等于null else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); //第5步 key不相同也不是树节点，则按链表的方式处理，判断链表中是否存在这个值，存在则e等于这个节点，否则将这个值插入到链表，e等于null；插入后判断链表大小是否大于8，大于则转换为红黑树 else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; //第6步 判断e是否为空，不为空说明有相同key的节点，需要进行覆盖，并返回old值 if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; //第7步 如果是old值覆盖，则modCount不变，modCount只有在插入节点才会变化；最后判断table大小是否大于负载值threshold，大于则进行扩容 ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125; 相比较于1.7的插入操作，1.8的优化是引入红黑树，不至于在hash碰撞频繁的情况下，导致链表过长查询速度变慢的问题。在插入操作里最后就是扩容函数，想必很想知道hashmap是怎么扩容的，下面详细讲讲扩容原理 扩容resize就是更换容器，小桶放不下了得换个大桶。前面我们了解到，table是个数组，我们也知道数组是有大小的，不能动态的扩张，但是HashMap对象却可以不停的添加元素，这也真是resize帮我们做的，方法就是使用一个新的数组代替已有的容量小的数组。下面我们分析下resize的源码。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; //如果hashmap存在值 if (oldCap &gt; 0) &#123; // 超过最大值就不再扩充 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; //否则负载数量左移一位，翻倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; //负载量大于0，则用负载量替换容量 else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; //都为0则初始化容量和负载量 else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; //计算新的负载量上限 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;\"rawtypes\",\"unchecked\"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; //将原来的数据放入新的数组中 if (oldTab != null) &#123; //遍历老数组 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; //oldTab[j]存在数据 if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; //不是链表，直接定位值并插入 if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; //树节点操作，里面实现不细讲（实际上有点复杂） else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); //数组节点操作（非常精辟的一段操作，简直牛逼） else &#123; // preserve order //定义四个节点，老位置的首尾节点，倍数位置的首尾节点（倍数指的是“例如当前位置为1，老容量为8，扩容一倍就加8，所以倍数位置是9”） Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; //遍历链表节点 Node&lt;K,V&gt; next; do &#123; //链表下一个节点 next = e.next; //如果e的hash值与上老容量等于0，在老位置操作 if ((e.hash &amp; oldCap) == 0) &#123; //如果老位置尾节点为空，则老位置头位置就是e if (loTail == null) loHead = e; // 否则老位置尾节点的 next 指向 e else loTail.next = e; // 老位置尾节点也指向e，构造链表 loTail = e; &#125; //如果hash与值不等于0 就放入到倍数节点去 else &#123; //如果倍数尾节点等于null，倍数节点头位置为e if (hiTail == null) hiHead = e; //否则倍数尾节点的 next 指向 e else hiTail.next = e; // 倍数尾节点 为 e，构造新链表 hiTail = e; &#125; &#125; while ((e = next) != null); //如果老位置有值，则在老位置加上链表 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; //如果倍数节点位置有值，则在倍数倍数加上链表 if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; 这跟java 7是完全不同的,java 7是采用遍历后重新hash的方法，并且链表采用的是头插法 12345678910111213141516171819202122void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; // 遍历 hash 表 for (Entry&lt;K,V&gt; e : table) &#123; // 遍历 节点 中的链表 while(null != e) &#123; Entry&lt;K,V&gt; next = e.next; // 重新hash if (rehash) &#123; e.hash = null == e.key ? 0 : hash(e.key); &#125; //定位 int i = indexFor(e.hash, newCapacity); //头插法，把原有的数据发到next后面去 e.next = newTable[i]; //头节点放新数据 newTable[i] = e; // 移动至链表下一节点 e = next; &#125; &#125; &#125;","categories":[{"name":"java.util","slug":"java-util","permalink":"https://www.icepear.cn/categories/java-util/"}],"tags":[{"name":"HashMap Map","slug":"HashMap-Map","permalink":"https://www.icepear.cn/tags/HashMap-Map/"}]},{"title":"多线程高并发面试题（Multithreading & Concurrency）","slug":"concurrency/interview","date":"2017-06-10T11:30:02.000Z","updated":"2018-03-26T09:08:11.841Z","comments":true,"path":"2017/06/10/concurrency/interview/","link":"","permalink":"https://www.icepear.cn/2017/06/10/concurrency/interview/","excerpt":"线程是java面试问题中的热门话题之一，下面总结了一些Java多线程以及并发访问问题和答案，毕竟多线程和并发性都是并存的。","text":"线程是java面试问题中的热门话题之一，下面总结了一些Java多线程以及并发访问问题和答案，毕竟多线程和并发性都是并存的。 多线程和并发多线程Process和Thread之间的区别 进程是一个独立的运行环境，能够看做是一个程序或者应用，java运行环境运行作为一个简单的包含不同的类和程序的进程集。 而线程可以叫做一个轻量级的进程，线程可以看作是进程中的一个执行任务，线程需要较少的资源来创建并存在于进程中，线程共享进程资源 多线程编程的优点多线程编程可以并发的执行，提高性能，因为某些线程会等待获取某些资源所以cpu不会闲置，多线程共享堆内存，所以创建多线程比创建多进程要好，举个例子就是Servlets的性能要比CGI要好 用户线程和守护线程有什么不同首先都是线程，区别是用户线程dead后，JVM就会退出，不管是否还有守护线程，因为守护线程本来就是守护用户线程的，用户线程都死了，守护线程也没有存在的意义，所以JVM就退出了。还有就是守护线程创建的子线程也是守护线程 在java中怎么创建一个线程 通过实现Runnable接口，重写run方法，线程通过New Thread(new 线程类())的方式创建，通过调用start方法启动 通过extend一个Thread类，重写run方法，通过new 线程类()的方式创建，通过调用start方法启动我们可以直接调用run方法，像普通方法那样，但是这时，线程是没有启动的，只有通过start方法，线程才会启动如果你的类提供更多的功能，建议实现Runnable接口。毕竟java是多实现，单继承，所以优先Runnable 线程的生命周期有哪些创建，就绪，运行，阻塞，死亡这五种方式 当new出线程类时，线程处于创建状态 当调用start方法时，线程处于就绪状态 当run方法执行时，线程处于运行状态 当线程因为某些原因放弃cpu资源时，处于阻塞状态。直到重新进入就绪状态，才有机会再次运行 当线程run方法执行完了，或者运行过程中异常中断了，或者调用了stop方法，就会退出run方法，此时线程就死亡了 怎样理解线程的优先级每个线程都有优先级，通常优先级较高的线程在执行时优先，但这个要取决于操作系统相关的线程调度程序实现。我们可以定义线程的优先级，线程优先级是一个int，从1到10,1的优先级最低，10最高。但不能保证优先级较低的线程之前一定执行优先级较高的线程。 什么是线程调度和时间分片线程调度器是一个操作系统服务，它负责为Runnable状态的线程分配CPU时间。一旦创建一个线程并启动它，它的执行便依赖于线程调度器的实现。时间分片是指将可用的CPU时间分配给可用的Runnable线程的过程。分配CPU时间可以基于线程优先级或者线程等待的时间。线程调度并不受到Java虚拟机控制，所以由应用程序来控制它是更好的选择（也就是说不要让的程序依赖于线程的优先级） 如何确保main（）是Java程序中最后完成的线程我们可以使用Thread join（）方法来确保在完成主函数之前程序创建的所有线程都已经死亡 线程间通信方式主要是通过线程间内存共享，通过类的wait(),notify(),notifyAll()方法进行，这些方法都应该在同步方法或同步块中调用。 怎么确保线程安全 同步是最简单也是最广泛的线程安全工具 使用java.util.concurrent.atomic下的Atomic Wrapper类，例如AtomicInteger 使用java.util.concurrent.locks包中的类 使用线程安全的集合类，也在java.util.concurrent中，例如ConcurrentHashMap 将volatile关键字与变量一起使用，使每个线程都从内存中读取数据，而不是从线程缓存中读取数据。 volatile 关键字当使用volatile 关键字定义变量时，所有的线程将从主内存中读取而不是从线程的本地缓存读取，这就能确保变量在多线程的情况下也是同步的 同步块和同步方法那个更好更倾向于同步块的写法，因为同步块可以指定minitor对象锁定，可控制粒度更小。而同步方法会锁定整个对象，并且如果类中有多个同步块，即使它们不相关，也会阻止它们执行并将它们置于等待状态 创建守护线程的方法通常创建守护线程用于对系统不重要的功能，例如记录线程或监事线程来捕获系统资源细节和状态，最好避免IO操作的守护线程可以用Thread.setDaemon(true) 创建 ThreadLocal是什么ThreadLocal用于创建线程的局部变量，对象的所有线程共享它的变量，所以这个变量不是线程安全的，可以使用线程同步来达到线程的目的，但是如果想避免同步，就可以使用ThreadLocal变量，每个线程都有自己的ThreadLocal变量互不影响，可以使用get/set方法来设置和获取值 什么是死锁，怎么分析和避免死锁死锁是指两个或以上的线程永远处于阻塞状态。分析死锁，可以通过查看应用程序的java Thread dump，可以通过jstack工具查看状态为阻塞的线程，然后查看它正在等待的锁定的资源，每个资源都有一个唯一的ID，我们可以使用它找到哪个线程已经在对象上持有锁有以下准则可以避免死锁 避免嵌套锁定，这是大部分死锁的情况，也就是说尽量不要在锁定资源a的情况下，又去锁定资源b 只锁定需要锁定的东西，你应该只获取必须处理的资源的锁，如果我们只对某一个字段感兴趣，那么我们应该只锁定该特定字段而不是完整对象 避免无限等待，如果线程a必须等待线程b完成，尽量不要用sleep去控制，而是使用threa.join串行执行 什么是线程池，如何创建线程池根据系统自身的环境情况，有效的限制执行线程的数量，使得运行效果达到最佳。线程主要是通过控制执行的线程的数量，超出数量的线程排队等候，等待有任务执行完毕，再从队列最前面取出任务执行。创建线程池的方式有多种 java.util.concurrent.Executors 提供了线程池的静态实现方法,但一般不推荐这种写法 newFixedThreadPool();创建的线程池corePoolSize和maximumPoolSize值是相等的，它使用的LinkedBlockingQueue； newSingleThreadExecutor();将corePoolSize和maximumPoolSize都设置为1，也使用的LinkedBlockingQueue； newCachedThreadPool();将corePoolSize设置为0，将maximumPoolSize设置为Integer.MAX_VALUE，使用的SynchronousQueue，也就是说来了任务就创建线程运行，当线程空闲超过60秒，就销毁线程。 newScheduledThreadPool(); 用于创建一个线程池，线程池中得线程能够周期性地执行给定的任务 ThreadPoolExecutor类提供了更完善的线程池创建构造方法 ScheduledExecutorService 类提供了定期执行任务线程池 并发什么是原子操作，java并发api中的原子类是什么原子操作在一个任务单元中执行，不受其他操作的干扰。原子操作在多线程环境中是必需的，以避免数据不一致。比如int++ 就不是一个原子操作，因为再多线程的情况下，某个线程执行了加1，但其他线程可能读的还是旧的值，就会导致错误的结果。为了解决这个问题，我们必须保证count的增量操作是院子的，我们可以使用同步来达到目的，但java1.5以后在java.util.concurrent.atomic提供了int和long的包装类，可以用来实现这个原子操作，没有使用同步，有兴趣的可以深入了解实现 java并发api中的Lock接口是什么？与synchronize相比，它有什么好处？Lock 借口提供了更多广泛的锁定操作比使用synchronized，Lock结构更加灵活，可以有完全不同的属性，并且可以关联多个条件对象Lock有以下优点 可以让线程更公平 可以使线程在等待一个锁定对象时响应中断 可以去尝试获取锁定，但如果无法获取锁定时，则会立即返回或在超时后返回 可以以不同的顺序获取或释放不同范围内的lock 谈谈ExcutorExcutor 是在jdk 1.5 引入的，通过java.util.concurrent.Executor接口Excutor 主要是根据一组执行策略规范调用，调度，执行和控制异步任务创建多个线程并且没有达到最大阈值的限制会导致应用程序耗尽堆内存，所以创建线程池是一个比较好的解决方案，应为有限的线程可以被集中和重用，而Excutor就是为了更好的创建线程池设计的 什么是BlockingQueue，怎么通过BlockingQueue实现一个生产者消费者模型java.util.concurrent.BlockingQueue 是一个阻塞队列，阻塞必然有两种情况， 当队列满了的时候，进行入列操作会被阻塞 当队列空的时候，出列操作会被阻塞阻塞队列是线程安全的，所有排队方法本质上都是原子性的，使用内部锁或其他形式的并发控制阻塞队列主要也是用于生产者消费者问题，负责生产的线程不断的制造新对象并插入到阻塞队列中，直到达到这个队列的上限值。队列达到上限值之后生产线程将会被阻塞，直到消费的线程对这个队列进行消费。同理，负责消费的线程不断的从队列中消费对象，直到这个队列为空，当队列为空时，消费线程将会被阻塞，除非队列中有新的对象被插入。 谈谈Callable和FutureCallable相当于Runnable的一个扩展，不同于Runnable的是Callable是个泛型参数化接口，并能返回线程的执行结果，而且能在无法正常计算时抛出异常。Callable并不像Runnable那样通过Thread的start方法就能启动实现类的run方法，通常是利用ExecutorService的submit方法去启动call方法自执行任务，而ExecutorService的submit又可以返回一个Future类型的结果，因此Callable通常也与Future一起使用，还有一种方式是使用FutureTask封装Callable再由Thread去启动。所以Callable的好处是异步执行，还能返回结果，结合Future还能判断任务状态，取消任务 谈谈FutureTaskFutureTask是Future接口基类的实现类，可以和Executors一起用于异步处理，大多数情况下很少使用FutureTask类，但如果我们想要覆盖Future类的某些方法，并且保留基本实现，它就变得非常方便。我们可以扩展这个类，根据需求覆盖一些方法 谈谈Concurrent Collection类通常Collection类是快速失败的，这意味着当一个线程在使用iterator便利时，去修改集合，这个iterator.next()操作将抛出ConcurrentModificationException异常。而Concurrent Collection则不会出现这个问题，因为它就是为多线程设计的主要的类包括 ConcurrentHashMap, CopyOnWriteArrayList 和 CopyOnWriteArraySet 讲讲Executors类Executors 提供了很多静态使用方法，包括Executor, ExecutorService, ScheduledExecutorService, ThreadFactory, 以及 Callable，所以可以使用executors类在java中轻松创建线程池，这也是唯一支持可调用实现执行的类。 java8中并发改进了哪些？重要的改进包括： ConcurrentHashMap 的compute(), forEach(), forEachEntry(), forEachKey(), forEachValue(), merge(), reduce() 和 search() 等方法 加入了CompletableFuture ，使异步编程更优美 Executors 新增了 newWorkStealingPool 线程池方法","categories":[{"name":"多线程","slug":"多线程","permalink":"https://www.icepear.cn/categories/多线程/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://www.icepear.cn/tags/多线程/"},{"name":"高并发","slug":"高并发","permalink":"https://www.icepear.cn/tags/高并发/"},{"name":"面试","slug":"面试","permalink":"https://www.icepear.cn/tags/面试/"}]},{"title":"jenkins 持续集成","slug":"jenkins/jenkins","date":"2017-04-10T10:30:02.000Z","updated":"2018-04-20T06:30:34.292Z","comments":true,"path":"2017/04/10/jenkins/jenkins/","link":"","permalink":"https://www.icepear.cn/2017/04/10/jenkins/jenkins/","excerpt":"持续集成是DevOps不可或缺的一部分，可以减少大量的部署操作。之所以选择jenkins，其重要原因可能在于其开源免费，接下来进行详细介绍","text":"持续集成是DevOps不可或缺的一部分，可以减少大量的部署操作。之所以选择jenkins，其重要原因可能在于其开源免费，接下来进行详细介绍 JenkinsWhat is Jenkins? Jenkins is a self-contained, open source automation server which can be used to automate all sorts of tasks related to building, testing, and deploying software. Jenkins can be installed through native system packages, Docker, or even run standalone by any machine with a Java Runtime Environment (JRE) installed. 官方给出了两点定义,大概的意思就是: jenkins 是一个独立的开源自动化服务器，可用于自动化与构建，测试和部署软件相关的各种任务。 Jenkins可以通过本机系统软件包安装，Docker，甚至可以通过安装Java Runtime Environment（JRE）的任何机器独立运行。 构建现在主要的这类软件，我都习惯使用docker进行部署，当然官方也说了可以直接使用jre，根据个人习惯选择。介绍三种方法: docker方式(推荐) 下载镜像 1docker pull jenkins 运行实例 1docker run -p 8080:8080 -p 50000:50000 jenkins 如果想挂载数据到宿主机，就先创建一个目录 1docker run -p 8080:8080 -p 50000:50000 -v /your/home:/var/jenkins_home jenkins 这只是简单的运行，并不能用于实际，后面会细说 jre运行下载,然后运行 1java -jar jenkins.war 官方方式 Ubuntu 1234wget -q -O - https://pkg.jenkins.io/debian/jenkins.io.key | sudo apt-key add -sudo sh -c 'echo deb http://pkg.jenkins.io/debian-stable binary/ &gt; /etc/apt/sources.list.d/jenkins.list'sudo apt-get updatesudo apt-get install jenkins centos 123sudo wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.reposudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.keyyum install jenkins 你也可以在/etc/sysconfig/jenkins中修改参数 12JENKINS_USER=\"root\"JENKINS_PORT=\"8008\" 设置完成之后，运行 1service jenkins start 如果能成功启动,那么恭喜你。像我就没这么轻松了，一脚下去几个坑，md，只能默默地填上。 坑1: 本以为可以成功,查看/etc/log/jenkins/jenkins.log发现端口占用导致错误,我X,docker那边没停占用了8008 顺带记录一下查看端口占用命令，老是忘 查看端口占用： 12 netstat -anp | grep 8008 或者 lsof -i:8008 查看应用占用： 1ps -aux | grep docker 坑2: 端口解决了，结果尼玛还是失败,发现启动脚本里面的java路径没设置 1vi /etc/init.d/jenkins 打开脚本发现 12345678candidates=\"/etc/alternatives/java/usr/lib/jvm/java-1.8.0/bin/java/usr/lib/jvm/jre-1.8.0/bin/java/usr/lib/jvm/java-1.7.0/bin/java/usr/lib/jvm/jre-1.7.0/bin/java/usr/bin/java\" 尼玛，还要配java路径,加上之后是可以启动了。 坑3 你以为启动了就ok了,简直是葫芦娃救爷爷，一个一个来。发现访问不了，于是乎怀疑是防火墙问题 打开端口后，终于正常了 上图 细说docker方式运行以docker方式运行，主要是快速方便。搭建docker形式需要注意几点 需要自己编写dockerfile，安装所需的一些工具 如果利用jenkins构建docker镜像，就要考虑是使用dockerIndocker还是dockerOutdocker 如果项目使用docker，可以考虑镜像私服，搭建方法可以参考下面详细针对这几点说明。 编写dockerfile是必要的，为什么这么说呢，因为避免不了要使用docker，jenkins使用docker有两种方式，一种是在dockerfile中再安装一个docker就是所谓的dockerIndocker，但是很多都不太推荐这种用法，大部分还是选择将宿主机的docker挂载至jenkins容器内运行。那既然能挂载那为什么还要写dockerfile呢，因为你宿主机跟jenkins镜像引入的基础镜像里自带的一些包都有些差异，毕竟镜像不可能像宿主机一样完整。像我用的centos，直接将docker挂进容器里面用，jenkins运行docker命令就会提示包不存在1docker: error while loading shared libraries: libltdl.so.7: cannot open shared object file: No such file or directory 后面找了一下，其实就是少包参考链接所以最终还是编写dockerfile，然后安装缺少的包假如宿主机docker 的权限是root，直接挂进jenkins容器还是会存在权限问题运行docker权限错误12Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock:Get http://%2Fvar%2Frun%2Fdocker.sock/v1.27/containers/json: dial unix /var/run/docker.sock: connect: permission denied 参考链接办法就是看宿主机docker用户的GID是多少，然后镜像中对应添加一致的，就可以愉快的在jenkins容器中使用docker了，我的dockerfile如下：1234567891011121314151617FROM jenkins:latestUSER rootARG DOCKER_GID=991RUN groupadd -g $&#123;DOCKER_GID&#125; dockerRUN apt-get update \\ &amp;&amp; apt-get install -y sudo libltdl-dev expect \\ &amp;&amp; rm -rf /var/lib/apt/lists/*RUN usermod -aG docker jenkinsRUN echo \"jenkins ALL=NOPASSWD: ALL\" &gt;&gt; /etc/sudoersUSER jenkins jenkins自动部署也少不了maven，jdk一系列插件，建议是直接挂在宿主机使用的，运行命令如下：docker run -p 8008:8080 -p 50000:50000 –add-host stpass-15.com:192.168.110.15 –name jenkins \\ -v /home/wulm/jenkins:/var/jenkins_home \\ -v /home/wulm/jdk1.8.0_131:/usr/java/jdk1.8.0_131 \\ -v /var/maven:/var/maven \\ -v /root/.ssh:/jenkins/.ssh \\ -v /usr/bin/docker:/usr/bin/docker:ro \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -d myjenkins:1.0（注：–add-host 是为了让容器dns能识别到内网私服库的域名）","categories":[{"name":"jenkins","slug":"jenkins","permalink":"https://www.icepear.cn/categories/jenkins/"}],"tags":[{"name":"jenkins","slug":"jenkins","permalink":"https://www.icepear.cn/tags/jenkins/"},{"name":"持续集成","slug":"持续集成","permalink":"https://www.icepear.cn/tags/持续集成/"}]},{"title":"docker 私服库(V2)","slug":"other/docker-registry","date":"2017-04-09T10:30:02.000Z","updated":"2017-11-14T03:55:09.071Z","comments":true,"path":"2017/04/09/other/docker-registry/","link":"","permalink":"https://www.icepear.cn/2017/04/09/other/docker-registry/","excerpt":"搭建docker 私服库是持续集成的一部分，当然你可以使用公共库，但我更倾向于私服库，对团队内部来讲还是相当有益的，接下来详细记录如何搭建以及注意环节","text":"搭建docker 私服库是持续集成的一部分，当然你可以使用公共库，但我更倾向于私服库，对团队内部来讲还是相当有益的，接下来详细记录如何搭建以及注意环节 docker registry 搭建介绍registry是一种开源的,无状态，高度可扩展的服务器端应用程序，可存储和分发Docker映像。其实这些都是屁话，哈哈，只要了解私服库字面意思就知道是干嘛的了。V1就直接pass了，官方都抛弃了，直接用的是V2 搭建前提：先安装了docker，而且版本1.6以上 下载下载比较简单，通过docker下载镜像就行了1docker pull registry:2 简单运行下载之后，运行1docker run -d -p 5000:5000 --restart=always --name registry registry:2 这样一个私服库就跑起来了，但事实上这样基本上是没卵用的。官方文档说了A production-ready registry must be protected by TLS and should ideally use an access-control mechanism生产必须被TLS保护，合理的使用访问控制所以说了这么多其实没卵用，官方文档这么带我的，我也就这么写咯，所以还是看下面吧 安全运行 做TLS就要签名证书，所以第一步就是创建证书用openssl创建文件夹用于存放证书,也为了方便后续挂载至registry容器,官方也有1234$ mkdir -p certs$ openssl req \\ -newkey rsa:4096 -nodes -sha256 -keyout certs/domain.key \\ -x509 -days 365 -out certs/domain.crt 注意一定要输入CN（common name）之后的要用到(例如：myregistrydomain.com)创建之后，文件夹下就有两个文件：domain.crt domain.key 将证书添加至系统信任使用身份验证时，Docker的某些版本还要求在操作系统级别信任证书。centos:12$ cat certs/domain.crt » /etc/pki/tls/certs/ca-bundle.crt$ update-ca-trust ubuntu:12$ cp certs/domain.crt /usr/local/share/ca-certificates/myregistrydomain.com.crt$ update-ca-certificates 生成用户和密码光有TLS是不够的，还必须做到访问控制。实现访问限制的最简单方法是通过Native basic auth（这与其他Web服务器的基本身份验证机制非常相似）。 1234$ mkdir auth$ docker run \\ --entrypoint htpasswd \\ registry:2 -Bbn testuser testpassword &gt; auth/htpasswd 启动registry容器万事具备，只欠东风。现在只需要把容器启动起来，该挂载的挂载，改配的环境变量配上 12345678910111213docker run -d \\ -p 5000:5000 \\ --restart=always \\ --name registry \\ -v /home/docker-registry:/var/lib/registry \\ -v /home/wulm/auth:/auth \\ -e \"REGISTRY_AUTH=htpasswd\" \\ -e \"REGISTRY_AUTH_HTPASSWD_REALM=Registry Realm\" \\ -e REGISTRY_AUTH_HTPASSWD_PATH=/auth/htpasswd \\ -v /home/wulm/certs:/certs \\ -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/domain.crt \\ -e REGISTRY_HTTP_TLS_KEY=/certs/domain.key \\ registry:2 至此registry算是搭建成功了，但是真的成没成功还得测试，最简单的是直接访问前提是这个域名写到了你的hosts文件 客户端docker测试 在另外一台主机上测试私服库是否可用，才能真正测试出正确性。 首先将myregistrydomain.com域名（也就是你配置的域名）对应的IP一起写到你的hosts文件中，以便系统能够根据域名找到私服 1vi /etc/hosts 在文件末尾添加一行 然后不管以什么方法，将私服库上的证书搞到测试机上来,并且写到docker认证的目录下（/etc/docker/certs.d/） 12mkdir -p /etc/docker/certs.d/myregistrydomain.com:5000 建一个文件夹cp /certs/domain.crt /etc/docker/certs.d/myregistrydomain.com:5000 然后将证书放到这个目录下（假设证书已经从私服库上拷下来放到/certs/domain.crt中） 建议是重启一下docker 1systemctl restart docker 这会假如你测试机上跑了其他容器，那这些肯定都是挂了的，一个一个起有太麻烦，所以可以用下面的命令批量重启一下 1docker start $(docker ps -a | awk '&#123; print $1&#125;' | tail -n +2) 就可以测试登录了 1docker login myregistrydomain.com:5000 不出意外输入账号密码，会提示登录成功。good luck","categories":[{"name":"docker","slug":"docker","permalink":"https://www.icepear.cn/categories/docker/"}],"tags":[{"name":"持续集成","slug":"持续集成","permalink":"https://www.icepear.cn/tags/持续集成/"},{"name":"docker","slug":"docker","permalink":"https://www.icepear.cn/tags/docker/"}]},{"title":"linux 防火墙配置","slug":"network/firewalld","date":"2017-03-21T10:30:02.000Z","updated":"2020-03-20T07:25:13.012Z","comments":true,"path":"2017/03/21/network/firewalld/","link":"","permalink":"https://www.icepear.cn/2017/03/21/network/firewalld/","excerpt":"目前大多情况都使用CentOs7，但Centos升级到7之后，内置的防火墙已经从iptables变成了firewalld。所以两个都记录一下。","text":"目前大多情况都使用CentOs7，但Centos升级到7之后，内置的防火墙已经从iptables变成了firewalld。所以两个都记录一下。 linux 防火墙配置firewalldCentos7默认安装了firewalld，如果没有安装的话，可以使用 yum install firewalld firewalld-config进行安装。 常用命令123456789101112启动防火墙 systemctl start firewalld 禁用防火墙 systemctl stop firewalld设置开机启动 systemctl enable firewalld停止并禁用开机启动 sytemctl disable firewalld重启防火墙 firewall-cmd --reload查看状态 systemctl status firewalld 或者 firewall-cmd --state 其他命令1234567891011121314151617181920212223查看版本 firewall-cmd --version查看帮助 firewall-cmd --help查看区域信息 firewall-cmd --get-active-zones查看指定接口所属区域信息 firewall-cmd --get-zone-of-interface=eth0拒绝所有包 firewall-cmd --panic-on取消拒绝状态 firewall-cmd --panic-off查看是否拒绝 firewall-cmd --query-panic将接口添加到区域(默认接口都在public) firewall-cmd --zone=public --add-interface=eth0(永久生效再加上 --permanent 然后reload防火墙)设置默认接口区域 firewall-cmd --set-default-zone=public(立即生效，无需重启)更新防火墙规则 firewall-cmd --reload 无需断开连接 或firewall-cmd --complete-reload 需要断开连接，类似重启服务 打开端口12345查看指定区域所有打开的端口 firewall-cmd --zone=public --list-ports在指定区域打开端口 firewall-cmd --zone=public --add-port=80/tcp --permanent 需要重启防火墙 说明：–zone 作用域–add-port=8080/tcp 添加端口，格式为：端口/通讯协议–permanent #永久生效，没有此参数重启后失效 iptables常用命令123456789开启防火墙(即时生效，重启后失效)：service iptables start关闭防火墙(即时生效，重启后失效)：service iptables stop开启防火墙(重启后永久生效)：chkconfig iptables on关闭防火墙(重启后永久生效)：chkconfig iptables off重启防火墙:service iptables restartd 打开、查看端口1/etc/init.d/iptables status 打开某个端口(以8080为例)12345iptables -A INPUT -p tcp --dport 8080 -j ACCEPT 打开/etc/rc.d/init.d/iptables save 保存/etc/init.d/iptables restart 重启 其他方式可以通过修改/etc/sysconfig/iptables文件的方式开启端口，运行1vi /etc/sysconfig/iptables 增加一行1-A RH-Firewall-1-INPUT -m state –state NEW -m tcp -p tcp –dport 8080 -j ACCEPT 参数说明: –A 参数就看成是添加一条规则–p 指定是什么协议，我们常用的tcp 协议，当然也有udp，例如53端口的DNS–dport 就是目标端口，当数据从外部进入服务器为目标端口–sport 数据从服务器出去，则为数据源端口使用–j 就是指定是 ACCEPT -接收 或者 DROP 不接收","categories":[{"name":"network","slug":"network","permalink":"https://www.icepear.cn/categories/network/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://www.icepear.cn/tags/linux/"},{"name":"防火墙","slug":"防火墙","permalink":"https://www.icepear.cn/tags/防火墙/"},{"name":"network","slug":"network","permalink":"https://www.icepear.cn/tags/network/"}]},{"title":"单例模式（Singleton pattern）","slug":"designpattern/singleton","date":"2017-03-15T10:30:00.000Z","updated":"2018-03-27T01:33:49.815Z","comments":true,"path":"2017/03/15/designpattern/singleton/","link":"","permalink":"https://www.icepear.cn/2017/03/15/designpattern/singleton/","excerpt":"单例模式（Singleton Pattern）是 Java 中最简单的设计模式之一。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。单例类负责创建自己的对象，同时确保只有单个对象被创建。这个类提供了一种访问其唯一的对象的方式，可以直接访问，不需要实例化该类的对象。","text":"单例模式（Singleton Pattern）是 Java 中最简单的设计模式之一。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。单例类负责创建自己的对象，同时确保只有单个对象被创建。这个类提供了一种访问其唯一的对象的方式，可以直接访问，不需要实例化该类的对象。 简介单例模式是常用的设计模式之一，在spring中也大量采用到，单例模式一般分为饿汉式和饱汉式这两种实现，但除了这两种其实还可以细分到线程安全领域，所以也就还会有线程安全的实现方式 基本定律 私有的静态实例变量 私有的构造方法 公共的获取实例的方法满足这三个条件，基本就可以写出单例了。下面详细分析几种写法 单例模式的写法饿汉式，最常见实现（可用）这种写法比较简单，而且一般来讲也是线程安全的，因为在类装载的时候就完成了实例化，避免同步问题 1234567public class Singleton&#123; private final static Singleton instance = new Singleton(); private Singleton(); public Singleton getInstance()&#123; return instance; &#125;&#125; 饿汉式，静态代码块（可用）和上面基本类似，只是把实例化的过程抽离到了静态代码块中 12345678910public class Singleton&#123; private static Singleton instance; static&#123; instance = new Singleton(); &#125; private Singleton(); public Singleton getInstance()&#123; return instance; &#125;&#125; 饿汉式，静态内部类，推荐这种方式跟上两种虽然都采用类加载机制来保证实例化时只有一个线程，但是上两种的做法是只要类被加载就会被实例化，假如这个类没有被用到，就会浪费内存。这种方式的好处就是起到了懒加载的效果，静态内部类在singleton类被加载时并不会立即实例化，而是在需要时实例化，调用getInstance才会去装载内部类 123456789101112public class Singleton&#123; private Singleton(); private static class SingletonInstance&#123; private static final Singleton instance = new Singleton(); &#125; public static Singleton getInstance()&#123; return SingletonInstance.instance; &#125;&#125; 饱汉式，线程不安全（不可用）谈完饿汉再谈饱汉，饱汉一般的写法是，getInstance的时候我在实例化，当多个线程同时调用getInstance就会导致线程不安全12345678910111213public class Singleton &#123; private static Singleton instance; private Singleton() &#123;&#125; public static Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125;&#125; 饱汉式，线程安全（可用，但效率低）那怎么可以达到线程安全呢，实现也很简单，不就是getInstance会导致同步问题嘛，那就加一个同步方法，但是也不太推荐这种做法，毕竟每次都要同步效率是很低的12345678910111213public class Singleton &#123; private static Singleton instance; private Singleton() &#123;&#125; public static synchronized Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125;&#125; 饱汉式，线程安全升级（不可用）那同步效率低该怎么改进呢，于是想到就是静态代码块咯，效率会高一点吧123456789101112131415public class Singleton &#123; private static Singleton instance; private Singleton() &#123;&#125; public static Singleton getInstance() &#123; if (instance == null) &#123; synchronized (Singleton.class) &#123; instance = new Singleton(); &#125; &#125; return instance; &#125;&#125; 这样就没问题了吗？仔细想想，假如在判断if (instance == null)时，另外一个线程也放好判断完了，两个线程还是会同时实例化 饱汉式，双重检查，线程安全，推荐这时双重检测是最完美不过的了，首先保证实例的原子性，然后双重判断，这样就不会出现实例化多个的情况了1234567891011121314151617public class Singleton &#123; //volatile 保证变量的原子性，都是从主线程内存中读取 private static volatile Singleton instance; private Singleton() &#123;&#125; public static Singleton getInstance() &#123; if (instance == null) &#123; synchronized (Singleton.class) &#123; if (instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; 枚举，推荐jdk1.5 引入枚举后，使用枚举来实现单例模式。不仅能避免多线程同步问题，而且还能防止反序列化重新创建新的对象。123456public enum Singleton &#123; INSTANCE; public void whateverMethod() &#123; &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://www.icepear.cn/categories/设计模式/"}],"tags":[{"name":"单例模式","slug":"单例模式","permalink":"https://www.icepear.cn/tags/单例模式/"}]},{"title":"工厂模式（Factory Method）","slug":"designpattern/Factory","date":"2017-03-11T08:30:00.000Z","updated":"2017-10-16T08:57:22.038Z","comments":true,"path":"2017/03/11/designpattern/Factory/","link":"","permalink":"https://www.icepear.cn/2017/03/11/designpattern/Factory/","excerpt":"工厂模式是设计模式中比较基础也是比较常见的模式，一般用在创建对象上，所以属于创建型模式。工厂模式也分三种:简单工厂模式、工厂模式、抽象工厂模式。下面会对每个模式从解释、UML、代码进行详细说明","text":"工厂模式是设计模式中比较基础也是比较常见的模式，一般用在创建对象上，所以属于创建型模式。工厂模式也分三种:简单工厂模式、工厂模式、抽象工厂模式。下面会对每个模式从解释、UML、代码进行详细说明 工厂模式简单工厂模式解释简单工厂模式主要的意图就是抽象化实体类，让子类去决定实例化。在小米加步枪时代，你需要一辆马车，你需要自己去创造。而在飞机大炮时代，你需要一辆汽车，你就会找工厂造一台，如果需求再变通一点，甲需要宝马，乙需要奥迪。所以造车的工厂就要能造两种车，而简单工厂模式就符合这种需求。这个优点就是调用者创建对象只需通过工厂创建，扩展性高 UML图 示例代码Car接口基类123public interface Car&#123; void run();&#125; BMW类123456public class BMW implements Car&#123; @Override public void run() &#123; System.out.println(\"BMW is run!\"); &#125; &#125; AUTO类123456public class AUTO implements Car&#123; @Override public void run() &#123; System.out.println(\"AUTO is run!\"); &#125; &#125; 工厂类12345678910public class CarFactory&#123; public static BMW CreateBMW() &#123; return new BMW(); &#125; public static AUTO CreateAUTO() &#123; return new AUTO(); &#125;&#125; 具体调用123456789public class Test&#123; public static void main(String []args)&#123; BMW bmw = CarFactory.CreateBMW(); bmw.run(); AUTO auto = CarFactory.CreateAUTO(); auto.run(); &#125;&#125; 工厂模式解释工厂模式显然是对简单工厂模式的一种改进或者说是完善，遵循开闭原则。一个抽象工厂类派生出多个具体工厂类，具体工厂类只能生产对应的具体产品在现实需求中，宝马工厂和奥迪工厂肯定是不同的工厂，所以对工厂也进行抽象,这样就方便扩展了，当又来一种汽车时，只需要另外开辟一个工厂，而不要对原来工厂进行修改。 UML 示例代码Car接口基类123public interface Car&#123; void run();&#125; BMW类123456public class BMW implements Car&#123; @Override public void run() &#123; System.out.println(\"BMW is run!\"); &#125; &#125; AUTO类123456public class AUTO implements Car&#123; @Override public void run() &#123; System.out.println(\"AUTO is run!\"); &#125; &#125; 工厂抽象接口1234public interface CarFactory&lt;T&gt;&#123; T Create();&#125; BMW工厂类123456public class BMWFactory implements CarFactor&lt;BMW&gt;&#123; public BMW create() &#123; return new BMW(); &#125;&#125; AUTO工厂类12345public interface AUTOFactory implements CarFactor&lt;AUTO&gt;&#123; public AUTO create() &#123; return new AUTO(); &#125;&#125; 具体调用12345678public class Test&#123; public static void main(String []args)&#123; AUTOFactory autoFactory = new AUTOFactory(); AUTO auto = autoFactory.create(); auto.run(); &#125;&#125; 抽象工厂模式解释抽象工厂模式跟工厂模式最大的区别可能就是把产品再进行抽象，也就是一个抽象工厂类派生出多个具体工厂类，而具体工厂类可以生产出多个具体产品因为在现实生活中，很多产品都是一系列的，一个产品族。还按照上面的汽车的案例分析，现实生活中，你需要一台宝马，不可能说就是一种类型宝马，那宝马公司就去玩蛋蛋了，用户可能根据排量、汽车空间、稳定性、安全性各方面进行选择。所以宝马公司必须推出各个型号的子产品，例如3系和5系两款车，3系里面又包含1.5L排量的和2.0L排量的，5系同理。在实现这个需求上，我们就要对产品进行抽象，然后具体工厂写出对应的生产策略。 UML 示例代码3系BMW抽象类123456789public abstract class BMW320i&#123; //排量 private float displacement; public BMW320i(float displacement)&#123; this.displacement = displacement; &#125; public abstract void run(); //省略GET、SET&#125; 5系BMW抽象类123456789public abstract class BMW532i&#123; //排量 private float displacement; public BMW532i(float displacement)&#123; this.displacement = displacement; &#125; public abstract void run(); //省略GET、SET&#125; 1.5L的BMW3系类12345678public class BMW320i150 extends BMW320i&#123; public BMW320i150(float displacement)&#123; super(displacement); &#125; public void run() &#123; System.out.printf(\"this is a\"+this.getDisplacement()+\"L 320i\"); &#125;&#125; 2.0L的BMW3系类12345678public class BMW320i200 extends BMW320i&#123; public BMW320i200(float displacement)&#123; super(displacement); &#125; public void run() &#123; System.out.printf(\"this is a\"+this.getDisplacement()+\"L 320i\"); &#125;&#125; 1.5L的BMW5系类12345678public class BMW532i150 extends BMW532i&#123; public BMW532i150(float displacement)&#123; super(displacement); &#125; public void run() &#123; System.out.printf(\"this is a\"+this.getDisplacement()+\"L 532i\"); &#125;&#125; 2.0L的BMW5系类12345678public class BMW532i200 extends BMW532i&#123; public BMW532i200(float displacement)&#123; super(displacement); &#125; public void run() &#123; System.out.printf(\"this is a\"+this.getDisplacement()+\"L 532i\"); &#125;&#125; 工厂抽象接口1234public interface AbstractFactory &#123; public BMW320i createBMW320i(); public BMW532i createBMW532i();&#125; 1.5L抽象工厂类12345678910public class BMW150Factory implements AbstractFactory&#123; public BMW320i createBMW320i() &#123; return new BMW320i150(1.5f); &#125; public BMW532i createBMW532i() &#123; return new BMW532i150(1.5f); &#125;&#125; 2.0L抽象工厂类123456789public class BMW200Factory implements AbstractFactory &#123; public BMW320i createBMW320i() &#123; return new BMW320i200(2.0f); &#125; public BMW532i createBMW532i() &#123; return new BMW532i200(2.0f); &#125;&#125; 具体调用123456789101112131415public class test &#123; public static void main(String []args)&#123; BMW150Factory bmw150Factory = new BMW150Factory(); BMW200Factory bmw200Factory = new BMW200Factory(); BMW320i Bmw320i200 = bmw200Factory.createBMW320i(); BMW532i Bmw532i150 = bmw150Factory.createBMW532i(); Bmw320i200.run(); Bmw532i150.run(); /**结果：this is a 2.0L 320i * this is a 1.5L 532i */ &#125;&#125; 总结其实不管是工厂模式还是抽象工厂模式，其目的是一致的，就是利用抽象进行解耦，也没有必要说一定要在乎用工厂还是抽象工厂，完全要根据现实需求来确定方案。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://www.icepear.cn/categories/设计模式/"}],"tags":[{"name":"工厂模式","slug":"工厂模式","permalink":"https://www.icepear.cn/tags/工厂模式/"}]},{"title":"设计模式（Design Pattern）","slug":"designpattern/DesignPattern","date":"2017-03-10T07:30:02.000Z","updated":"2017-10-16T08:57:18.742Z","comments":true,"path":"2017/03/10/designpattern/DesignPattern/","link":"","permalink":"https://www.icepear.cn/2017/03/10/designpattern/DesignPattern/","excerpt":"设计模式是前人通过不断实践总结出来的经验。在日常编码也时有用到，更多的体现是在各大框架设计里面。之前自己学习过，但没有通过自己总结出来，接下来，我将系统的总结设计模式，加深自己对设计模式的理解","text":"设计模式是前人通过不断实践总结出来的经验。在日常编码也时有用到，更多的体现是在各大框架设计里面。之前自己学习过，但没有通过自己总结出来，接下来，我将系统的总结设计模式，加深自己对设计模式的理解 设计模式分类一、创建型模式：1.工厂模式 2.抽象工厂模式 3.单例模式 4.建造者模式 5.原型模式 二、结构型模式1.适配器模式 2.桥接模式 3.过滤器模式 4.代理模式 5.组合模式 6.装饰器模式 7.外观模式 8.享元模式 三、行为型模式1.责任链模式 2.命令模式 3.解释器模式 4.迭代器模式 5.备忘录模式 6.中介者模式 7.观察者模式 8.状态模式 9.空对象模式 10.策略模式 11.模板方法模式 12.访问者模式 六大原则一、单一职责原则每个类的职责应该是单一的，不能让一个类负责做个业务。比如说:一个类负责职责A和职责B，当职责A的需求变更时，需要修改职责A的代码，可能会导致职责B的代码出现问题为了避免出现这样的问题，所以要一个类对应一个职责 二、开闭原则对扩展开放，对修改关闭比如说:一个创建水果的类，本来可以创建香蕉、西瓜两个水果。如果这个类要新加创建芒果的方法，就得对这个类进行修改，如果再加其他水果，又得对该类进行方法的新增。所以可以对香蕉、西瓜等水果进行抽象，创建水果的类只提供创建方法，要新加芒果时，只需要扩展一个芒果类即可，不需要对创建水果类进行修改。开闭原则的关键就在于抽象二字 三、里氏代换原则任何基类出现的地方，其子类也可以出现，替代其使用不会是出现错误换种方式说就是，我喜欢狗，所以我一定喜欢动物；但我喜欢动物，我不一定喜欢狗。里氏代换原则其实是对开闭原则的补充也就是抽象的具体实现，而实现需要注意的也就是抽象时需要注意的情况: 1. 子类必须实现父类的抽象方法，不能实现非抽象方法 2. 子类可以增加自己的方法 四、依赖倒置原则抽象不应该依赖于细节，细节应当依赖于抽象。换言之，要针对接口编程，而不是针对实现编程 五、接口隔离原则使用多个专门的接口，而不使用单一的总接口比方说鸟和壁虎都属于动物，都实现动物接口，按理动物接口要包括飞行方法、爬行方法，但鸟类实现接口之后具有爬行方法、显然不合适。所以要拆分成，飞行动物接口和爬行动物接口。 六、迪米特原则(最少知道原则)一个软件实体应当尽可能少地与其他实体发生相互作用 迪米特法则要求我们在设计系统时，应该尽量减少对象之间的交互，如果两个对象之间不必彼此直接通信，那么这两个对象就不应当发生任何直接的相互作用，如果其中的一个对象需要调用另一个对象的某一个方法的话，可以通过第三者转发这个调用。简言之，就是通过引入一个合理的第三者来降低现有对象之间的耦合度。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://www.icepear.cn/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://www.icepear.cn/tags/设计模式/"}]},{"title":"SpringBoot学习-基本使用","slug":"springboot/SpringBoot1","date":"2016-12-09T11:30:02.000Z","updated":"2020-05-12T08:43:45.001Z","comments":true,"path":"2016/12/09/springboot/SpringBoot1/","link":"","permalink":"https://www.icepear.cn/2016/12/09/springboot/SpringBoot1/","excerpt":"在您第1次接触和学习Spring框架的时候，是否因为其繁杂的配置而退却了？在你第n次使用Spring框架的时候，是否觉得一堆反复黏贴的配置有一些厌烦？那么您就不妨来试试使用Spring Boot来让你更易上手，更简单快捷地构建Spring应用！Spring Boot让我们的Spring应用变的更轻量化。比如：你可以仅仅依靠一个Java类来运行一个Spring引用。你也可以打包你的应用为jar并通过使用java -jar来运行你的Spring Web应用。","text":"在您第1次接触和学习Spring框架的时候，是否因为其繁杂的配置而退却了？在你第n次使用Spring框架的时候，是否觉得一堆反复黏贴的配置有一些厌烦？那么您就不妨来试试使用Spring Boot来让你更易上手，更简单快捷地构建Spring应用！Spring Boot让我们的Spring应用变的更轻量化。比如：你可以仅仅依靠一个Java类来运行一个Spring引用。你也可以打包你的应用为jar并通过使用java -jar来运行你的Spring Web应用。 使用SpringBoot开始废话不多讲，为什么使用SpringBoot，就一个字：“爽”。快速入门，精简配置，开箱即用，独立运行这些优点绝对会让你爱上它，当然最重要的一点就是微服务 构建项目使用maven构建，一般继承 spring-boot-starter-parent 项目来获取合适的默认设置只需要简单地设置 parent 为：12345&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.4.0.RELEASE&lt;/version&gt;&lt;/parent&gt; 该父项目提供以下特性： 默认编译级别为Java 1.6 源码编码为UTF-8 一个依赖管理节点,允许你省略普通依赖的 标签,继承自 spring-boot-dependencies POM。 合适的资源过滤 合适的插件配置（ exec插件， surefire， Git commit ID， shade） 针对 application.properties 和 application.yml 的资源过滤改变属性可以使用 标签，例如123456&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;//项目编码格式 &lt;java.version&gt;1.8&lt;/java.version&gt;//改变java编译版本 &lt;docker.image.prefix&gt;willmin&lt;/docker.image.prefix&gt;//其他属性配置 &lt;docker.plugin.version&gt;0.4.12&lt;/docker.plugin.version&gt;&lt;/properties&gt; 打包插件让springboot应用独立运行，需要将应用导成可执行的jar，可以利用Spring Boot Maven插件，在中配置在pom中写入：12345678&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 依赖项目列表在pom中可以轻易引用springboot的各种依赖，所有的starters遵循一个相似的命名模式： spring-boot-starter-* 是一种特殊类型的应用程序，该命名结构旨在帮你找到需要的starter。表 13.1. Spring Boot application starters 名称 描述 spring-boot-starter 核心Spring Boot starter， 包括自动配置支持， 日志和YAML spring-boot-starter-actuator 生产准备的特性， 用于帮你监控和管理应用 spring-boot-starter-amqp 对”高级消息队列协议”的支持， 通过 spring-rabbit 实现 spring-boot-starter-aop 对面向切面编程的支持， 包括 spring-aop 和AspectJ spring-boot-starter-test 对常用测试依赖的支持， 包括JUnit, Hamcrest和Mockito， 还有 spring-test 模块 spring-boot-starter-web 对全栈web开发的支持， 包括Tomcat和 spring-webmvc spring-boot-starter-websocket 对WebSocket开发的支持 spring-boot-starter-mail 对 javax.mail 的支持 spring-boot-starter-mobile 对 spring-mobile 的支持 spring-boot-starter-mustache 对Mustache模板引擎的支持 spring-boot-starter-redis 对REDIS键值数据存储的支持， 包括 spring-redis spring-boot-starter-security 对 spring-security 的支持 spring-boot-starter-jdbc 对JDBC数据库的支持 spring-boot-starter-data-jpa 对”Java持久化API”的支持， 包括 spring-data-jpa ， spring-orm 和Hibernate spring-boot-starter-data-rest 对通过REST暴露Spring Data仓库的支持， 通过 spring-data-rest-webmvc 实现 spring-boot-starter-thymeleaf 对Thymeleaf模板引擎的支持， 包括和Spring的集成 spring-boot-starter-velocity 对Velocity模板引擎的支持 spring-boot-starter-batch 对Spring Batch的支持， 包括HSQLDB数据库 spring-boot-starter-cloudconnectors 对Spring Cloud Connectors的支持， 简化在云平台下(例如，Cloud Foundry和Heroku)服务的连接 spring-boot-starter-dataelasticsearch 对Elasticsearch搜索和分析引擎的支持， 包括 spring-data-elasticsearch spring-boot-starter-datagemfire 对GemFire分布式数据存储的支持， 包括 spring-data-gemfire spring-boot-starter-datamongodb 对MongoDB NOSQL数据库的支持， 包括 spring-data-mongodb spring-boot-starter-data-solr 对Apache Solr搜索平台的支持， 包括 spring-data-solr spring-boot-starter-freemarker 对FreeMarker模板引擎的支持 spring-boot-starter-groovytemplates 对Groovy模板引擎的支持 spring-boot-starter-hateoas 对基于HATEOAS的RESTful服务的支持， 通过 spring-hateoas 实现 spring-boot-starter-hornetq 对”Java消息服务API”的支持， 通过HornetQ实现 spring-boot-starter-integration 对普通 spring-integration 模块的支持 spring-boot-starter-jersey 对Jersey RESTful Web服务框架的支持 spring-boot-starter-jtaatomikos 对JTA分布式事务的支持， 通过Atomikos实现 spring-boot-starter-jta-bitronix 对JTA分布式事务的支持， 通过Bitronix实现 spring-boot-starter-socialfacebook 对 spring-social-facebook 的支持 spring-boot-starter-sociallinkedin 对 spring-social-linkedin 的支持 spring-boot-starter-socialtwitter 对 spring-social-twitter 的支持 spring-boot-starter-ws 对Spring Web服务的支持 spring-boot-starter-jetty 导入Jetty HTTP引擎（ 作为Tomcat的替代） spring-boot-starter-log4j 对Log4J日志系统的支持 spring-boot-starter-logging 导入Spring Boot的默认日志系统（ Logback） spring-boot-starter-tomcat 导入Spring Boot的默认HTTP引擎（ Tomcat） 代码结构springboot应用并不要求任何特殊的代码结构，我一般是这么写的 1234567891011121314151617|-main |-java/com/icepear/项目名 |-web |-Controller |-service |-impl |-实现 |-接口 |-domain |-enums |-interfaces |-Repository.java |-实体.java |-docker |-Dockerfile |-resources |-application.yml","categories":[{"name":"springboot","slug":"springboot","permalink":"https://www.icepear.cn/categories/springboot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.icepear.cn/tags/SpringBoot/"}]},{"title":"Markdown学习","slug":"other/Markdown","date":"2016-12-08T07:30:02.000Z","updated":"2018-07-18T04:39:00.963Z","comments":true,"path":"2016/12/08/other/Markdown/","link":"","permalink":"https://www.icepear.cn/2016/12/08/other/Markdown/","excerpt":"Markdown 是一种轻量级的「标记语言」，它的优点很多，目前也被越来越多的写作爱好者，撰稿者广泛使用。看到这里请不要被「标记」、「语言」所迷惑，Markdown 的语法十分简单。常用的标记符号也不超过十个，这种相对于更为复杂的HTML 标记语言来说，Markdown 可谓是十分轻量的，学习成本也不需要太多，且一旦熟悉这种语法规则，会有一劳永逸的效果。","text":"Markdown 是一种轻量级的「标记语言」，它的优点很多，目前也被越来越多的写作爱好者，撰稿者广泛使用。看到这里请不要被「标记」、「语言」所迷惑，Markdown 的语法十分简单。常用的标记符号也不超过十个，这种相对于更为复杂的HTML 标记语言来说，Markdown 可谓是十分轻量的，学习成本也不需要太多，且一旦熟悉这种语法规则，会有一劳永逸的效果。 Markdown学习标题 #表示一级标题，##表示二级标题，多级标题依次累积 列表1.有序列表在文本前加入数字1.,2.,3.即可 1. 列表1 2. 列表2 2. 列表3 2.无序列表在文本前加入- - 列表1 - 列表2 - 列表3 注：-,1.和文本之间要保留一个字符的空格。 换行与缩进换行使用&lt;/br&gt;或者使用空行表示换行。缩进使用半方大的空白&amp;ensp;或&amp;#8194;也可以用全方大的空白&amp;emsp;或&amp;#8195;例如： &amp;ensp;你好&lt;/br&gt;&amp;emsp;世界 显示：&ensp;你好&emsp;世界 链接格式为:[文本](链接),例如 [google链接](https://www.google.com) 显示如：google链接 图片格式为：![](图片链接),例如 ![](http://g3.ykimg.com/0130391F4555C2DEFE9F592DF60A8431D4D237-366F-F0C2-ED67-4475501D05FC) 显示为： 分割线使用 *** 三个星 * * * - - - 三个带空格的中划线 ___ 连续三个下划线 __________ 多个下划线 &lt;/pre&gt; 区块引用使用&gt;,例如 &gt; 你好&lt;/br&gt; &gt; 世界&lt;/br&gt; &gt; I`m coder 显示： 你好世界I`m coder 代码区块单句代码可以使用’ ‘(也就是键盘~这个按钮)区块使用标签&lt;pre&gt;和&lt;code&gt;嵌套，例如： `你好` &lt;pre&gt;&lt;code&gt;这是一个代码区块。&lt;/code&gt;&lt;/pre&gt; 显示如： 你好 这是一个代码区块。 粗体和斜体粗体的格式为**文本**，斜体的格式为*文本*例如: **你好**&lt;/br&gt; *世界* 显示:你好世界 表格格式如下: | dog | bird | cat | | - | - | - | | foo | foo | foo | | bar | bar | bar | | baz | baz | baz | 显示如下 dog bird cat foo foo foo bar bar bar baz baz baz 格式如下: | dog | bird | cat | | - | :-: | -: | | foo | foo | foo | | bar | bar | bar | | baz | baz | baz | 显示如下 dog bird cat foo foo foo bar bar bar baz baz baz","categories":[{"name":"other","slug":"other","permalink":"https://www.icepear.cn/categories/other/"}],"tags":[{"name":"Markdown","slug":"Markdown","permalink":"https://www.icepear.cn/tags/Markdown/"}]}]}