{"meta":{"title":"冰梨","subtitle":null,"description":null,"author":"rim-wood","url":"http://www.icepear.cn"},"pages":[{"title":"个人简介","date":"2018-03-26T12:50:35.615Z","updated":"2018-03-26T12:50:35.614Z","comments":true,"path":"about/index.html","permalink":"http://www.icepear.cn/about/index.html","excerpt":"","text":"&emsp;吴黎明，Rim·Wood，95后，本科毕业于湖南长沙大学，16年毕业从事儿童机器人行业，现在医疗血站领域从事java开发&emsp;本科研读软件工程专业-java方向。喜欢折腾，对新技术永远激情，永远热泪盈眶。"},{"title":"分类","date":"2017-10-09T03:04:58.294Z","updated":"2017-10-09T03:04:58.294Z","comments":true,"path":"categories/index.html","permalink":"http://www.icepear.cn/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2017-10-09T03:04:58.295Z","updated":"2017-10-09T03:04:58.295Z","comments":true,"path":"tags/index.html","permalink":"http://www.icepear.cn/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"mysql 学习笔记（一）","slug":"mysql/mysql-intorduce","date":"2018-07-13T11:30:02.000Z","updated":"2018-07-18T10:34:13.684Z","comments":true,"path":"2018/07/13/mysql/mysql-intorduce/","link":"","permalink":"http://www.icepear.cn/2018/07/13/mysql/mysql-intorduce/","excerpt":"mysql 常用函数，使用sql必然避免不了使用函数，函数往往能让你的工作事半功倍，常用的函数包括：字符串的处理，数值的运算，日期函数，流程控制。","text":"mysql 常用函数，使用sql必然避免不了使用函数，函数往往能让你的工作事半功倍，常用的函数包括：字符串的处理，数值的运算，日期函数，流程控制。 字符串函数 函数 功能 CONCAT(s1,s2,…,sn) 连接 s1，s2 …sn 为一个字符串 INSERT(str,x,y,instr) 将字符串str从第x位开始到y位的子串替换成instr REPLACE(str,a,b) 用字符串b替换字符串str中所有出现的字符串a SUBSTRING(str,x,y) 截取字符串str从x位置到y位置的子串 LOWER(str) 将字符串str中所有的字符变为小写 UPPER(str) 将字符串str中所有的字符变为大写 LEFT(str,x) 返回字符串str最左边的x个字符 RIGHT(str,x) 返回字符串str最右边的x个字符 LPAD(str,n,pad) 用字符串pad对str最左边进行填充，直到长度为n个字符长度 RPAD(str,n,pad) 用字符串pad对str最右边进行填充，直到长度为n个字符长度 LTRIM(str) 去掉字符串左侧的空格 RTRIM(str) 去掉字符串行尾的空格 TRIM(str) 去掉字符串行头和行尾的空格 REPEAT(str,x) 返回str重复x次的结果 STRCMP(s1,s2) 比较字符串s1和s2 字符串的拼接、替换、裁剪这些函数是最常见的，务必牢记 CONCAT(s1,s2,…,sn) 拼接字符串 下面例子将aa，bb，cc三个字符串拼接，另外任何字符串与NULL连接的结果都将是NULL 12345678select concat('aa','bb','cc'),concat('aa',null)+-------------------------+----------------------+| concat('aa','bb','cc') | concat('aa',null) |+-------------------------+----------------------+| aabbcc | NULL |+-------------------------+----------------------+1 row in set(0.05 sec) INSERT、REPLACE 两个函数都是替换字符串","categories":[{"name":"mysql","slug":"mysql","permalink":"http://www.icepear.cn/categories/mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://www.icepear.cn/tags/Mysql/"}]},{"title":"redis 配置解析","slug":"other/redis-conf","date":"2018-06-21T11:30:02.000Z","updated":"2018-07-18T10:40:27.225Z","comments":true,"path":"2018/06/21/other/redis-conf/","link":"","permalink":"http://www.icepear.cn/2018/06/21/other/redis-conf/","excerpt":"拿着原始的redis.conf进行一一解析，应该算是最全的解析版本了","text":"拿着原始的redis.conf进行一一解析，应该算是最全的解析版本了 下载链接文件的下载链接 配置文件 配置内容看不完，就先下载下来慢慢看 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779780781782783784785786787788789790791792793794795796797798799800801802803804805806807808809810811812813814815816817818819820821822823824825826827828829830831832833834835836837838839840841842843844845846847848849850851852853854855856857858859860861862863864865866867868869# Redis 配置样例## 为了读取配置文件，Redis必须以文件路径作为第一个参数来启动：## ./redis-server /path/to/redis.conf# 当需要内存大小时，可以使用1k 5GB 4M等通常的形式指定它，如下所示：## 1k =&gt; 1000 bytes# 1kb =&gt; 1024 bytes# 1m =&gt; 1000000 bytes# 1mb =&gt; 1024*1024 bytes# 1g =&gt; 1000000000 bytes# 1gb =&gt; 1024*1024*1024 bytes## 单位不区分大小写，所以1GB 1Gb 1gB都是一样的。################################## INCLUDES配置文件 #################################### 在这里包含一个或多个其他配置文件。 如果您有一个标准模板可用于所有Redis服务器，# 但也需要自定义几个每服务器设置，这非常有用。 包含文件可以包含其他文件，所以明智地使用它。# “include”不会被来自admin或Redis Sentinel的命令“CONFIG REWRITE”重写。 # 由于Redis总是使用最后一条处理过的行作为配置指令的值，因此最好将include包含在此文件的开头，以避免在运行时覆盖配置更改。## include /path/to/local.conf# include /path/to/other.conf################################## MODULES模块加载 ###################################### 启动时加载模块。 如果服务器无法加载模块，则会中止。 可以使用多个loadmodule指令## loadmodule /path/to/my_module.so# loadmodule /path/to/other_module.so################################## NETWORK网络配置 ###################################### 默认情况下，如果没有指定“绑定”配置指令，则Redis监听来自服务器上可用的所有网络接口的连接。 # 可以使用“bind”配置指令监听一个或多个选定的接口，然后使用一个或多个IP地址。## 例子:## bind 192.168.1.100 10.0.0.1# bind 127.0.0.1 ::1## ~~~ WARNING ~~~ # 如果运行Redis的计算机直接暴露在互联网上，绑定到所有接口是危险的，并会将实例暴露给互联网上的每个人。 # 因此，默认情况下，我们取消注释以下绑定指令，这将强制Redis仅侦听IPv4回溯接口地址#（这意味着Redis将只能接受与运行在同一台计算机上的客户端的连接）。## 如果您确定您希望您的实例能够聆听所有接口，只需像下面这样即可。# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~bind 127.0.0.1# 保护模式是一层安全保护措施，以避免在互联网上保持打开的Redis实例被访问和利用。## 当保护模式打开时，如果：## 1) 服务器没有明确地使用&quot;bind&quot;绑定到一组地址# 2) 没有配置密码。## 服务器只接受来自IPv4和IPv6环回地址127.0.0.1和:: 1以及来自Unix域套接字的客户端的连接。## 默认情况下启用保护模式。protected-mode yes# 接受指定端口上的连接，默认值为6379如果指定端口0，则Redis不会侦听TCP套接字。port 6379# TCP listen() backlog.## 在高请求每秒的环境中，您需要高的backlog以避免缓慢的客户端连接问题。 # 请注意，Linux内核会将其自动截断为/ proc / sys / net / core / somaxconn的值，# 因此请确保同时提高somaxconn和tcp_max_syn_backlog的值以获得所需的效果。tcp-backlog 511# Unix socket.## 指定将用于侦听传入连接的Unix socket的路径。 没有默认设置，因此Redis在未指定时不会在unix socket上侦听。## unixsocket /tmp/redis.sock# unixsocketperm 700# 客户端空闲N秒后关闭连接（0禁用）timeout 0# TCP keepalive. 心跳检测## 如果非零，则在没有通信的情况下使用SO_KEEPALIVE向客户端发送TCP ACK。 # 这是有用的，原因有两个：## 1) 检测死掉的资源共享者# 2) 从中间网络设备的角度来看，连接是活着的。## 在Linux上，指定的值（以秒为单位）是用于发送ACK的时间段。# 请注意，要关闭连接，需要两倍的时间。# 在其他内核上，时间取决于内核配置。## 这个选项的合理值是300秒，这是新的# Redis默认从Redis 3.2.1开始。tcp-keepalive 300################################# 一般配置 ###################################### 默认情况下，Redis不会作为守护进程运行。 如果您需要，请使用&quot;yes&quot;。# 请注意，当守护进程时，Redis将在/var/run/redis.pid中写入一个pid文件。daemonize no# 如果您从upstart或systemd运行Redis，则Redis可以与您的监督树进行交互。选项:# supervised no - 没有监督互动# supervised upstart - 通过将Redis置于SIGSTOP模式来发信号# supervised systemd - 通过将READY = 1写入$ NOTIFY_SOCKET来系统化信号# supervised auto - 检测 upstart or systemd 方法基于UPSTART_JOB or NOTIFY_SOCKET 环境变量# 注意：这些监督方法只会发出“过程已准备就绪”的信号。 他们不能将连续的活跃回馈给你的supervisor。supervised no# 如果指定了pid文件，则Redis将其写入启动时指定的位置，并在退出时将其删除。# 当服务器运行非守护进程时，如果配置中没有指定pid文件，则不会创建pid文件。 # 当服务器被守护进程时，即使未指定，也会使用pid文件，默认为“/var/run/redis.pid”。# 如果Redis不能创建它，创建一个pid文件是最好的选择pidfile /var/run/redis_6379.pid# 服务器日志级别:# debug (对开发/测试有用)# verbose (比debug级别精简)# notice (适度详细，用在生产中)# warning (只记录非常重要/关键的消息)loglevel notice# 指定日志文件名称 空字符串可用于强制Redis log标准输出。请注意，如果您使用标准输出进行日志记录但守护进程，则日志将被发送到/dev/nulllogfile &quot;&quot;# 要启用logging到系统 logger，只需将&apos;syslog-enabled&apos;设置为yes，并可以选择更新其他syslog参数以满足您的需求。# syslog-enabled no# 指定系统日志标识。# syslog-ident redis# 指定系统日志功能。 必须是USER或local0至local7。# syslog-facility local0# 设置数据库的数量，默认值是16。# 默认数据库是DB 0，您可以使用SELECT &lt;dbid&gt;在每个连接的基础上切换不同的数据库，databases 16# 默认情况下，Redis只有在log是标准输出并且标准输出是TTY时才显示ASCII logo。 基本上这意味着通常只有在交互式会话中才会显示logo。always-show-logo yes################################ SNAPSHOTTING快照配置 ################################## 保存DB到磁盘:# # save &lt;seconds&gt; &lt;changes&gt;## 如果发生针对数据库的给定秒数和给定数量的写操作，将保存数据库。## 例如:# after 900 sec (15 min) if at least 1 key changed# after 300 sec (5 min) if at least 10 keys changed# after 60 sec if at least 10000 keys changed## 注意: 您可以通过注释掉所有“保存”行来完全禁用保存。也可以用 save &quot;&quot;save 900 1save 300 10save 60 10000# 默认情况下，如果启用了RDB快照（至少有一个保存点）并且最新的后台保存失败，Redis将停止接受写入。# 可以让用户意识到数据不能正确的保存在磁盘上，否则没人会去关注这一错误的发生## 如果后台保存过程将再次开始工作，则Redis将自动再次允许写入。## 但是，如果您已设置了对Redis服务器和持久性的适当监控，则可能需要禁用此功能，以便即使磁盘，权限等问题仍然存在，Redis仍将照常继续工作。stop-writes-on-bgsave-error yes# 在转储.rdb数据库时使用LZF压缩字符串对象？对于默认设置为&apos;是&apos;，因为它几乎总是可以的。# 如果您想要在保存子节点中保存一些CPU，请将其设置为“否”，但如果您具有可压缩值或密钥，则数据集可能会更大。rdbcompression yes# 从版本5的RDB开始，CRC64校验和被放置在文件的末尾。# 这使得该格式更能抵抗腐败，但在保存和加载RDB文件时，性能会受到影响（大约为10％），因此您可以禁用它以获得最佳性能。rdbchecksum yes# 转储数据库的文件名dbfilename dump.rdb# 存储的文件目录dir ./################################# 主从复制 ################################## 主从复制。 使用slaveof将Redis实例作为另一个Redis服务器的副本## 1) Redis复制是异步的，但是如果它看起来没有连接至少给定数量的slave，您可以配置master来停止接受写入。# 2) 如果复制链接在相对较短的时间内丢失，则Redis从节点能够与主节点执行部分重新同步。 您可能需要根据您的需要配置合理的值来配置复制积压大小# 3) 复制是自动的，不需要用户干预。在网络分区后slave自动尝试重新连接到master并与它们重新同步## slaveof &lt;masterip&gt; &lt;masterport&gt;# 如果主站受密码保护（使用下面的“requirepass”配置指令），可以在开始复制同步过程之前告诉从站进行认证，否则主站将拒绝从站请求。## masterauth &lt;master-password&gt;# 当slave失去与master的连接时，或者复制仍在进行时，slave可以采取两种不同的方式：## 1) 如果slave-serve-stale-data设置为&apos;yes&apos;（缺省值），则从设备仍然会回应客户端请求，可能会使用过时数据，或者如果这是第一次同步，数据集可能只是空的。## 2) 如果slave-serve-stale-data设置为&apos;no&apos;，则从设备将回复一个错误“SYNC with master in progress”，除了INFO和SLAVEOF之外的所有类型的命令。#slave-serve-stale-data yes# 您可以配置一个从设备实例来接受写入与否。 针对从属实例写入数据可能对于存储一些短暂数据非常有用#（因为写入从属服务器上的数据在与主服务器重新同步后很容易被删除），但是如果客户端因错误配置而写入数据，也可能会导致问题。## 从Redis 2.6后 默认情况是只读的。slave-read-only yes# 复制SYNC策略: disk or socket.## -------------------------------------------------------# WARNING: DISKLESS 是目前的测试参数# -------------------------------------------------------## 新的slaves和重新连接的因为接收差异无法继续复制进程,需要做所谓的 &quot;full synchronization&quot;.RDB文件从maste 传输到slaves。# 传输可以以两种不同的方式发生：## 1) Disk-backed: Redis master创建一个将RDB文件写入磁盘的新进程。 之后，文件由父进程传递到从服务器。# 2) Diskless: Redis master创建一个新的进程，直接将RDB文件写入从套接字，而不用接触磁盘。## 使用 disk-backed 复制, 当生成RDB文件时，只要生成RDB文件的当前子节点完成其工作，就可以将更多的从属节点排队并与RDB文件一起提供服务。# 使用diskless复制，一旦传输开始，到达的新从站将排队，并且当当前端口终止时将开始新的传输。# 使用diskless复制，在开始传输之前，主设备等待可配置的时间量（以秒为单位），可以等待多个从设备到达后并行的传输。## 对于慢速磁盘和快速（大带宽）网络 diskless 复制效果更好repl-diskless-sync no# 启用 diskless 时, 服务器等待一段时间后才会通过套接字向从站传送RDB文件，这个等待时间是可配置的。 # 这一点很重要，因为一旦传送开始，就不可能再为一个新到达的从站服务。从站则要排队等待下一次RDB传送。因此服务器等待一段时间以期更多的从站到达。# 延迟时间以秒为单位，默认为5秒。要关掉这一功能，只需将它设置为0秒，传送会立即启动repl-diskless-sync-delay 5# 从站以一个预先设置好的时间间隔向服务器发送PING。这个时间间隔可以通过repl_ping_slave_period选项改变。默认值是10秒。# repl-ping-slave-period 10# 该选项为以下内容设置备份的超时时间：## 1) slaves角度，同步批量传输的I/O.# 2) slave角度，master超时(数据, ping).# 3) master角度，slave超时 (REPLCONF ACK pings).## 确认这个值比定义的repl-ping-slave-period要大，否则每次主站和从站之间通信低速时都会被检测为超时。## repl-timeout 60# 同步之后是否禁用slave上的TCP_NODELAY？## 假如设置成yes，则redis会合并小的TCP包从而节省带宽，但会增加同步延迟（40ms），造成master与slave数据不一致# 假如设置成no，则redis master会立即发送同步数据，没有延迟## 默认情况下，我们针对低延迟进行了优化，但在非常高并发量条件下，或者当主设备和从设备距离很远时，将此设置为“yes”可能是一个好主意。repl-disable-tcp-nodelay no# 设置备份的工作储备大小。工作储备是一个缓冲区，当从站断开一段时间的情况时，# 它替从站接收存储数据，因此当从站重连时，通常不需要完全备份，只需要一个部分同步就可以，即把从站断开时错过的一部分数据接收。 # 工作储备越大，从站可以断开并稍后执行部分同步的断开时间就越长。 # 只要有一个从站连接，就会立刻分配一个工作储备。# repl-backlog-size 1mb# 主站有一段时间没有与从站连接，对应的工作储备就会自动释放。接下来这个选项用于配置释放前等待的秒数，秒数从断开的那一刻开始计算。 ## 请注意，从站永远不会释放积压超时，因为它们可能在稍后被提升为主站，并且应该能够正确地与从站“部分重新同步”：因此它们应该始终积累积压。## 值为0表示不释放。## repl-backlog-ttl 3600# 从站优先级是可以从redis的INFO命令输出中查到的一个整数。当主站不能正常工作时，redis sentinel使用它来选择一个从站并将它提升为主站。 # 低优先级的从站被认为更适合于提升，因此如果有三个从站优先级分别是10， 100， 25，sentinel会选择优先级为10的从站，因为它的优先级最低。 # 然而优先级值为0的从站不能执行主站的角色，因此优先级为0的从站永远不会被redis sentinel提升。 # 默认优先级是100slave-priority 100# 主站可以停止接受写请求，当与它连接的从站少于N个，滞后少于M秒。N个从站必须是在线状态。 # 延迟的秒数必须&lt;=所定义的值，延迟秒数是从最后一次收到的来自从站的ping开始计算。ping通常是每秒一次。 # 这一选项并不保证N个备份都会接受写请求，但是会限制在指定秒数内由于从站数量不够导致的写操作丢失的情况。 # 设置某一个为0表示禁用这一功能。 # 默认情况下default min-slaves-to-write设置为0（禁用）而min-slaves-max-lag设置为10。# 如果想要至少3个从站且延迟少于10秒，这样写：## min-slaves-to-write 3# min-slaves-max-lag 10# Redis master能够以不同的方式列出所连接slave的地址和端口。 # 例如，“INFO replication”部分提供此信息，除了其他工具之外，Redis Sentinel还使用该信息来发现slave实例。# 此信息可用的另一个地方在masterser的“ROLE”命令的输出中。# 通常由slave报告的列出的IP和地址,通过以下方式获得：# IP：通过检查slave与master连接使用的套接字的对等体地址自动检测地址。# 端口：端口在复制握手期间由slavet通信，并且通常是slave正在使用列出连接的端口。# 然而，当使用端口转发或网络地址转换（NAT）时，slave实际上可以通过(不同的IP和端口对)来到达。 slave可以使用以下两个选项，以便向master报告一组特定的IP和端口，# 以便INFO和ROLE将报告这些值。# 如果你需要仅覆盖端口或IP地址，则没必要使用这两个选项。# 注意：在Docker默认网络模式下，使用-p参数做端口映射，就需要配置一下从服务器redis.conf中的slave-announce-ip 和 slave-announce-port，对应外网的IP和外网端口。# Sentinel的配置文件sentinel.conf 也需要配置sentinel announce-ip 和 sentinel announce-port ，对应外网的IP和外网端口。# 当然，如果Docker配置成host网络模式，就不需要配置了，但建议最好不要用host模式# slave-announce-ip 5.5.5.5# slave-announce-port 1234################################## SECURITY安全性 #################################### 密码设置#requirepass icepear123456# 作为服务端的redis-server，我们常常需要禁用以上命令来使服务器更加安全。## 例如:## rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52## 在上面的例子中，CONFIG命令被重命名为一个不可猜测的名字。# 也可以通过将其重命名为空字符串来完全禁用它（或任何其他命令），如下例所示：## rename-command CONFIG &quot;&quot;################################### CLIENTS客户端 ##################################### 设置能连上redis的最大客户端连接数量。默认是10000个客户端连接。由于redis不区分连接是客户端连接还是内部打开文件或者和slave连接等，# 所以maxclients最小建议设置到32。如果超过了maxclients，redis会给新的连接发送’max number of clients reached’，并关闭连接。## maxclients 10000############################## MEMORY MANAGEMENT 内存管理 ################################# 将内存使用限制设置为指定的字节数。 达到内存限制时，Redis将尝试根据所选驱逐策略删除密钥（请参阅maxmemory-policy）。## 如果Redis无法根据策略删除密钥，或者如果策略设置为“noviction”吗，Redis将开始以错误的形式回复将使用更多内存的命令，如SET，LPUSH等，并将继续回复GET等只读命令。## 当使用Redis作为LRU或LFU缓存时，或者为实例设置硬内存限制（使用&apos;noviction&apos;策略）时，此选项通常很有用。## 警告：如果您的从站连接到启用了maxmemory的实例，则从已用存储器计数中减去用于馈送从站的输出缓冲区的大小。# 因此网络问题/ resyncs不会触发导致密钥被清除的一个循环，并且从属的输出缓冲区充满了被删除的DEL键以及触发删除更多密钥的等等，直到数据库完全清空。## 简而言之，如果你有slave，建议你为maxmemory设置一个下限，以便系统上有一些空闲的RAM用于从属输出缓冲区（但如果策略是&apos;noviction&apos;则不需要）。# 如果不设置maxmemory或者设置为0，64位系统不限制内存，32位系统最多使用3GB内存。# maxmemory &lt;bytes&gt;# 内存删除策略: 当达到maxmemory时，Redis将如何选择要删除的内容。 您可以选择八种行为：# 从Redis4.0开始，一个新的叫做最少频率使用驱逐模型是可用的。此模型在某些场景下可能会工作的更好（提供一个更好的命中/失误比率），# 因为使用LFU Redis将试图追踪所访问目标的频率，以便极少使用的驱逐而经常使用的则有更高机会保留在内存中。## volatile-lru -&gt; 在设置了过期时间的键空间中，优先移除最近未使用的key。# allkeys-lru -&gt; 优先移除最近未使用的key。# volatile-lfu -&gt; 在设置了过期时间的键空间中，移除使用频次最少的key# allkeys-lfu -&gt; 移除使用频次最少的key# volatile-random -&gt; 在设置了过期时间的键空间中，随机移除# allkeys-random -&gt; 随机删除 # volatile-ttl -&gt; 在设置了过期时间的键空间中，具有更早过期时间的key优先移除。# noeviction -&gt; 当内存使用达到阈值的时候，所有引起申请内存的命令会报错## LRU 最近未使用# LFU 使用频次最少## LRU，LFU和volatile-ttl都是使用近似随机算法实现的。(没有绝对的随机算法，哈哈)## 注意: 默认值是: noeviction，当没有合适的驱逐算法时，Redis将在写入操作时返回错误## 这些命令是: set setnx setex append# incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd# sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby# zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby# getset mset msetnx exec sort## maxmemory-policy noeviction# LRU，LFU和最小TTL算法不是精确算法，而是近似算法（为了节省内存），因此您可以调整它以获得速度或准确性。 对于默认值，# Redis将检查五个键并选择最近使用的键，您可以使用以下配置指令更改样本大小。## 默认值5会产生足够好的结果。 10非常接近真正的LRU，但成本更高。 3更快但不是很准确。## maxmemory-samples 5############################# LAZY FREEING 懒释放##################################### 这是4.0加入的新特性# Redis有两个原函数来删除键。 一个被称为DEL并且是对象的阻塞删除。就是服务器停止处理新命令用同步方式回收与对象关联的所有内存# 如果删除的键与一个小对象关联，执行DEL命令所需的时间非常短，并且与Redis中的大多数其他O（1）或O（log_N）命令相当 However if the key is associated with an# 但是，如果key与包含数百万个元素的聚合值关联，则服务器可能会阻塞很长时间（甚至几秒）以完成操作。## 由于上述原因，Redis还提供非阻塞删除原语，例如UNLINK（非阻塞DEL）和FLUSHALL和FLUSHDB命令的ASYNC选项，以便在后台回收内存。 # 这些命令在不变的时间内执行。 另一个线程将尽可能快地增量释放背景中的对象。## DEL, UNLINK and ASYNC option of FLUSHALL and FLUSHDB 选项由用户控制。 这取决于应用程序的设计，当然你得了解什么时候使用。 # 但是，Redis服务器有时必须删除key或刷新整个数据库，这将对其他操作产生影响# 具体来说，Redis会在以下情况下自动删除对象：## 1) 在删除时，由于maxmemory和maxmemory策略配置的原因，为了为新数据腾出空间，而不超过指定的内存限制。## 2) 由于过期：必须从存储器中删除具有关联时间的密钥（请参阅EXPIRE命令）## 3) 由于存储数据的命令的副作用可能已经存在。 例如，RENAME命令可能会在旧密钥内容被另一个替换时删除旧密钥内容。 # 同样，SUNIONSTORE或SORT with STORE选项可能会删除现有密钥。 SET命令本身会删除指定键的所有旧内容，以便将其替换为指定的字符串。## 4) 在复制期间，当从服务器与主服务器执行完全重新同步时，整个数据库的内容将被删除，以便加载刚刚传输的RDB文件。## 在上述所有情况下，默认情况下都是以阻塞的方式删除对象，就像调用DEL一样。 要开启调整为“yes”# 但是，您可以专门配置每个案例，以便使用以下配置指令以非阻塞方式释放内存，就像调用UNLINK一样：lazyfree-lazy-eviction nolazyfree-lazy-expire nolazyfree-lazy-server-del noslave-lazy-flush no############################## APPEND ONLY MODE 持久化模式################################ 默认情况下，Redis异步转储磁盘上的数据集。 这种模式在许多应用程序中已经足够了，但Redis进程或停电可能会导致几分钟的写入丢失（取决于配置的保存点）。## 仅追加文件是一种替代的持久模式，可提供更好的耐用性。例如，使用默认数据fsync策略（稍后在配置文件中看到）# 可以同时启用AOF和RDB持久性，是没有问题的。 如果在启动时启用AOF，则Redis将加载AOF，即具有更好的持久性保证的文件。## 查看http://redis.io/topics/persistence 获取更多内容.appendonly no# AOF文件的名称appendfilename &quot;appendonly.aof&quot;# fsync()函数调用告诉操作系统在磁盘上实际写入数据，而不是等待输出缓冲区中的更多数据。 # 有些操作系统会真正在磁盘上刷新数据，其他一些操作系统只会尽量做到这一点。## Redis支持三种不同的模式：## no: 不要fsync，只需让操作系统在需要时刷新数据。 更快。# always: 每次写入追加日志后的fsync。 慢，最安全。# everysec: 每秒只有一次fsync。 折中。## 默认值是“everysec”，因为这通常是速度和数据安全性之间的折中方案。# 您应该了解您是否可以将其放宽至“否”，以便操作系统在需要时刷新输出缓冲区以获得更好的性能（但是如果您可以忍受某些数据丢失的想法，请考虑快照的默认持久性模式），# 或者相反你可以使用 always，慢但是安全## 更多详细信息参考:# http://antirez.com/post/redis-persistence-demystified.html## 如果不确定, 使用 &quot;everysec&quot;.# appendfsync no# appendfsync alwaysappendfsync everysec# 当AOF fsync策略设置为always或everysec，并且后台保存进程（后台保存或AOF日志后台重写）正在对磁盘执行大量I/O时，# 在某些Linux配置中，Redis可能会在fsync（）调用上阻塞太久。 请注意，目前没有解决此问题的方法，因为即使在其他线程中执行fsync也会阻止我们的同步写入操作的调用。## 为了减轻这个问题，可以使用下面的选项来防止在BGSAVE或BGREWRITEAOF进程中在主进程中调用fsync()。## 这意味着，当另一个child正在保存时，Redis的持久性与“appendfsync none”相同。 实际上，这意味着在最坏的情况下（使用默认的Linux设置）可能会丢失高达30秒的日志。## 如果您有延迟问题，请将其转为“yes”。 否则，将其视为“no”，从持久性角度来看这是最安全的选择。# # 什么意思呢，同时在执行bgrewriteaof操作和主进程写aof文件的操作，两者都会操作磁盘，而bgrewriteaof往往会涉及大量磁盘操作，# 这样就会造成主进程在写aof文件的时候出现阻塞的情形，现在no-appendfsync-on-rewrite参数出场了。如果该参数设置为no，是最安全的方式，# 不会丢失数据，但是要忍受阻塞的问题。如果设置为yes呢？这就相当于将appendfsync设置为no，这说明并没有执行磁盘操作，只是写入了缓冲区，# 因此这样并不会造成阻塞（因为没有竞争磁盘），但是如果这个时候redis挂掉，就会丢失数据。丢失多少数据呢？在linux的操作系统的默认设置下，最多会丢失30s的数据。# 因此，如果应用系统无法忍受延迟，而可以容忍少量的数据丢失，则设置为yes。如果应用系统无法忍受数据丢失，则设置为no。no-appendfsync-on-rewrite no# 自动重写AOF文件# 当AOF日志大小按指定的百分比增长时，Redis能够自动重写日志文件，隐式调用BGREWRITEAOF。## 这是如何工作的：Redis记得最近一次重写后AOF文件的大小（如果重启后没有发生重写，则使用启动时AOF的大小）。## 上次AOF的大小与当前大小进行比较。 如果当前的大小大于指定的百分比，则触发重写。 此外，您还需要指定要重写的AOF文件的最小值，# 就是即使达到了百分比增加但文件仍然很小，这可以避免重写AOF## 指定百分比为零以禁用自动AOF重写功能。auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb# Redis启动加载aof文件，如果发现末尾命令不完整则自动截掉，成功加载前面正确的数据。# 如果设置为no，遇到此类情况，Redis启动失败，用redis-check-aof 工具手工修复。aof-load-truncated yes# 混合 RDB-AOF 持久化格式 # Redis 4.0 新增了 RDB-AOF 混合持久化格式， 这是一个可选的功能， 在开启了这个功能之后， AOF 重写产生的文件将同时包含 RDB 格式的内容和 AOF 格式的内容， # 其中 RDB 格式的内容用于记录已有的数据， 而 AOF 格式的内存则用于记录最近发生了变化的数据， # 这样 Redis 就可以同时兼有 RDB 持久化和 AOF 持久化的优点 —— 既能够快速地生成重写文件， 也能够在出现问题时， 快速地载入数据。aof-use-rdb-preamble no################################ LUA SCRIPTING Lua 脚本################################ 一个Lua脚本最长的执行时间，单位为毫秒，如果为0或负数表示无限执行时间，默认为5000lua-time-limit 5000################################ REDIS CLUSTER redis集群 ################################# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++# WARNING EXPERIMENTAL: Redis Cluster is considered to be stable code, however# in order to mark it as &quot;mature&quot; we need to wait for a non trivial percentage# of users to deploy it in production.# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++## 开启集群模式# cluster-enabled yes# 集群节点配置文件# cluster-config-file nodes-6379.conf# 集群节点超时时间限制# cluster-node-timeout 15000# 在进行故障转移的时候全部slave都会请求申请为master，但是有些slave可能与master断开连接一段时间了导致数据过于陈旧，不应该被提升为master。# 该参数就是用来判断slave节点与master断线的时间是否过长。判断方法是：# 比较slave断开连接的时间和# (node-timeout * slave-validity-factor)+ repl-ping-slave-period# 如果节点超时时间为三十秒, 并且slave-validity-factor为10，假设默认的repl-ping-slave-period是10秒，即如果超过310秒slave将不会尝试进行故障转移## cluster-slave-validity-factor 10# 一个主节点在拥有多少个好的从节点的时候就要割让一个从节点出来。例如这个参数若被设为 2，那么只有当一个主节点拥有 2 个可工作的从节点时，它的一个从节点会尝试迁移。## cluster-migration-barrier 1 # yes表示当负责一个主节点宕机并且下线没有相应的从库进行故障恢复时，整个集群不可用# no表示当负责一个插槽的主库下线且没有相应的从库进行故障恢复时，集群仍然可用。## cluster-require-full-coverage yes# 此选项设置为yes时，可防止从站在主站故障期间尝试故障切换其主站## 这在不同情况下非常有用，特别是在多数据中心操作的情况下，如果不是在发生全面的DC故障的情况下，我们希望一方不会被提升。## cluster-slave-no-failover no# 文档见 http://redis.io web site.########################## CLUSTER DOCKER/NAT support docker集群网络支持 ######################### 在某些部署中，Redis群集节点地址发现失败，因为地址是NAT或由于端口被转发（典型情况是Docker和其他容器）。## 为了使Redis Cluster在这样的环境中工作，需要每个节点都知道其公共地址的静态配置。提供了以下配置：## * cluster-announce-ip# * cluster-announce-port# * cluster-announce-bus-port## 如果以上选项未使用，则将使用正常的Redis集群自动检测。## 请注意，在重新映射时，总线端口可能不在客户端端口+ 10000的固定偏移量处，因此您可以根据它们如何重新映射来指定任何端口和总线端口。 # 如果未设置总线端口，则通常会使用10000的固定偏移量。## Example:## cluster-announce-ip 10.1.1.5# cluster-announce-port 6379# cluster-announce-bus-port 6380################################## SLOW LOG 慢日志#################################### Redis Slow Log是一个系统，用于记录超过指定执行时间的查询。 执行时间不包括像客户端连接，发送回复等I / O操作，# 而只是实际执行命令所需的时间（这是命令执行的唯一阶段，其中线程被阻止并且可以在此期间不提供其他请求）。## 只有query执行时间大于slowlog-log-slower-than的才会定义成慢查询，才会被slowlog进行记录。# slowlog-log-slower-than设置的单位是微妙，默认是10000微妙，也就是10ms # slowlog-max-len表示慢查询最大的条数，当slowlog超过设定的最大值后，会将最早的slowlog删除，是个FIFO队列slowlog-max-len 128################################ LATENCY MONITOR 监控############################### Redis延迟监视子系统在运行时对不同的操作进行采样，以收集与Redis实例的可能延迟来源有关的数据。## 通过 LATENCY命令 可以打印一些图样和获取一些报告，方便监控## 这个系统仅仅记录那个执行时间大于或等于预定时间（毫秒）的操作,这个预定时间是通过latency-monitor-threshold配置来指定的，## 默认情况下，阈值设置为0，即禁用redis监控。实际上启用该监控功能，对redis所增加的成本很少。不过对于一个运行良好的redis，是没有必要打开该监控功能。latency-monitor-threshold 0############################# EVENT NOTIFICATION 事件通知############################### Redis可以通知Pub / Sub客户端有关key发生的事件。 此功能记录在http://redis.io/topics/notifications## 例如，如果启用密钥空间事件通知，并且客户机对存储在数据库0中的密钥“foo”执行DEL操作，# 则将通过Pub / Sub发布两条消息：## PUBLISH __keyspace@0__:foo del# PUBLISH __keyevent@0__:del foo## 可以选择Redis通知的事件类别，每个类别都由一个字符标识：## K Keyspace events, published with __keyspace@&lt;db&gt;__ prefix.# E Keyevent events, published with __keyevent@&lt;db&gt;__ prefix.# g Generic commands (non-type specific) like DEL, EXPIRE, RENAME, ...# $ String commands# l List commands# s Set commands# h Hash commands# z Sorted set commands# x Expired events (events generated every time a key expires)# e Evicted events (events generated when a key is evicted for maxmemory)# A Alias for g$lshzxe, so that the &quot;AKE&quot; string means all the events.## 你可以像下面一样组合几个字符表示那些事件将被通知## notify-keyspace-events Elg## 如果你想使用__keyevent@&lt;db&gt;__的前缀，并发布过期的键的事件可以用：## notify-keyspace-events Ex## 默认情况下，采用空字符串所有通知都被禁用，因为大多数用户不需要此功能，并且该功能有一定的开销。 # 请注意，如果您未指定K或E中的至少一个，则不会传送任何事件。notify-keyspace-events &quot;&quot;############################### ADVANCED CONFIG 高级设置 ################################ Hashes are encoded using a memory efficient data structure when they have a# small number of entries, and the biggest entry does not exceed a given# threshold. These thresholds can be configured using the following directives.hash-max-ziplist-entries 512hash-max-ziplist-value 64# Lists are also encoded in a special way to save a lot of space.# The number of entries allowed per internal list node can be specified# as a fixed maximum size or a maximum number of elements.# For a fixed maximum size, use -5 through -1, meaning:# -5: max size: 64 Kb &lt;-- not recommended for normal workloads# -4: max size: 32 Kb &lt;-- not recommended# -3: max size: 16 Kb &lt;-- probably not recommended# -2: max size: 8 Kb &lt;-- good# -1: max size: 4 Kb &lt;-- good# Positive numbers mean store up to _exactly_ that number of elements# per list node.# The highest performing option is usually -2 (8 Kb size) or -1 (4 Kb size),# but if your use case is unique, adjust the settings as necessary.list-max-ziplist-size -2# Lists may also be compressed.# Compress depth is the number of quicklist ziplist nodes from *each* side of# the list to *exclude* from compression. The head and tail of the list# are always uncompressed for fast push/pop operations. Settings are:# 0: disable all list compression# 1: depth 1 means &quot;don&apos;t start compressing until after 1 node into the list,# going from either the head or tail&quot;# So: [head]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[tail]# [head], [tail] will always be uncompressed; inner nodes will compress.# 2: [head]-&gt;[next]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[prev]-&gt;[tail]# 2 here means: don&apos;t compress head or head-&gt;next or tail-&gt;prev or tail,# but compress all nodes between them.# 3: [head]-&gt;[next]-&gt;[next]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[prev]-&gt;[prev]-&gt;[tail]# etc.list-compress-depth 0# Sets have a special encoding in just one case: when a set is composed# of just strings that happen to be integers in radix 10 in the range# of 64 bit signed integers.# The following configuration setting sets the limit in the size of the# set in order to use this special memory saving encoding.set-max-intset-entries 512# Similarly to hashes and lists, sorted sets are also specially encoded in# order to save a lot of space. This encoding is only used when the length and# elements of a sorted set are below the following limits:zset-max-ziplist-entries 128zset-max-ziplist-value 64# HyperLogLog sparse representation bytes limit. The limit includes the# 16 bytes header. When an HyperLogLog using the sparse representation crosses# this limit, it is converted into the dense representation.## A value greater than 16000 is totally useless, since at that point the# dense representation is more memory efficient.## The suggested value is ~ 3000 in order to have the benefits of# the space efficient encoding without slowing down too much PFADD,# which is O(N) with the sparse encoding. The value can be raised to# ~ 10000 when CPU is not a concern, but space is, and the data set is# composed of many HyperLogLogs with cardinality in the 0 - 15000 range.hll-sparse-max-bytes 3000# Active rehashing uses 1 millisecond every 100 milliseconds of CPU time in# order to help rehashing the main Redis hash table (the one mapping top-level# keys to values). The hash table implementation Redis uses (see dict.c)# performs a lazy rehashing: the more operation you run into a hash table# that is rehashing, the more rehashing &quot;steps&quot; are performed, so if the# server is idle the rehashing is never complete and some more memory is used# by the hash table.## The default is to use this millisecond 10 times every second in order to# actively rehash the main dictionaries, freeing memory when possible.## If unsure:# use &quot;activerehashing no&quot; if you have hard latency requirements and it is# not a good thing in your environment that Redis can reply from time to time# to queries with 2 milliseconds delay.## use &quot;activerehashing yes&quot; if you don&apos;t have such hard requirements but# want to free memory asap when possible.activerehashing yes# The client output buffer limits can be used to force disconnection of clients# that are not reading data from the server fast enough for some reason (a# common reason is that a Pub/Sub client can&apos;t consume messages as fast as the# publisher can produce them).## The limit can be set differently for the three different classes of clients:## normal -&gt; normal clients including MONITOR clients# slave -&gt; slave clients# pubsub -&gt; clients subscribed to at least one pubsub channel or pattern## The syntax of every client-output-buffer-limit directive is the following:## client-output-buffer-limit &lt;class&gt; &lt;hard limit&gt; &lt;soft limit&gt; &lt;soft seconds&gt;## A client is immediately disconnected once the hard limit is reached, or if# the soft limit is reached and remains reached for the specified number of# seconds (continuously).# So for instance if the hard limit is 32 megabytes and the soft limit is# 16 megabytes / 10 seconds, the client will get disconnected immediately# if the size of the output buffers reach 32 megabytes, but will also get# disconnected if the client reaches 16 megabytes and continuously overcomes# the limit for 10 seconds.## By default normal clients are not limited because they don&apos;t receive data# without asking (in a push way), but just after a request, so only# asynchronous clients may create a scenario where data is requested faster# than it can read.## Instead there is a default limit for pubsub and slave clients, since# subscribers and slaves receive data in a push fashion.## Both the hard or the soft limit can be disabled by setting them to zero.client-output-buffer-limit normal 0 0 0client-output-buffer-limit slave 256mb 64mb 60client-output-buffer-limit pubsub 32mb 8mb 60# Client query buffers accumulate new commands. They are limited to a fixed# amount by default in order to avoid that a protocol desynchronization (for# instance due to a bug in the client) will lead to unbound memory usage in# the query buffer. However you can configure it here if you have very special# needs, such us huge multi/exec requests or alike.## client-query-buffer-limit 1gb# In the Redis protocol, bulk requests, that are, elements representing single# strings, are normally limited ot 512 mb. However you can change this limit# here.## proto-max-bulk-len 512mb# Redis calls an internal function to perform many background tasks, like# closing connections of clients in timeout, purging expired keys that are# never requested, and so forth.## Not all tasks are performed with the same frequency, but Redis checks for# tasks to perform according to the specified &quot;hz&quot; value.## By default &quot;hz&quot; is set to 10. Raising the value will use more CPU when# Redis is idle, but at the same time will make Redis more responsive when# there are many keys expiring at the same time, and timeouts may be# handled with more precision.## The range is between 1 and 500, however a value over 100 is usually not# a good idea. Most users should use the default of 10 and raise this up to# 100 only in environments where very low latency is required.hz 10# When a child rewrites the AOF file, if the following option is enabled# the file will be fsync-ed every 32 MB of data generated. This is useful# in order to commit the file to the disk more incrementally and avoid# big latency spikes.aof-rewrite-incremental-fsync yes# Redis LFU eviction (see maxmemory setting) can be tuned. However it is a good# idea to start with the default settings and only change them after investigating# how to improve the performances and how the keys LFU change over time, which# is possible to inspect via the OBJECT FREQ command.## There are two tunable parameters in the Redis LFU implementation: the# counter logarithm factor and the counter decay time. It is important to# understand what the two parameters mean before changing them.## The LFU counter is just 8 bits per key, it&apos;s maximum value is 255, so Redis# uses a probabilistic increment with logarithmic behavior. Given the value# of the old counter, when a key is accessed, the counter is incremented in# this way:## 1. A random number R between 0 and 1 is extracted.# 2. A probability P is calculated as 1/(old_value*lfu_log_factor+1).# 3. The counter is incremented only if R &lt; P.## The default lfu-log-factor is 10. This is a table of how the frequency# counter changes with a different number of accesses with different# logarithmic factors:## +--------+------------+------------+------------+------------+------------+# | factor | 100 hits | 1000 hits | 100K hits | 1M hits | 10M hits |# +--------+------------+------------+------------+------------+------------+# | 0 | 104 | 255 | 255 | 255 | 255 |# +--------+------------+------------+------------+------------+------------+# | 1 | 18 | 49 | 255 | 255 | 255 |# +--------+------------+------------+------------+------------+------------+# | 10 | 10 | 18 | 142 | 255 | 255 |# +--------+------------+------------+------------+------------+------------+# | 100 | 8 | 11 | 49 | 143 | 255 |# +--------+------------+------------+------------+------------+------------+## NOTE: The above table was obtained by running the following commands:## redis-benchmark -n 1000000 incr foo# redis-cli object freq foo## NOTE 2: The counter initial value is 5 in order to give new objects a chance# to accumulate hits.## The counter decay time is the time, in minutes, that must elapse in order# for the key counter to be divided by two (or decremented if it has a value# less &lt;= 10).## The default value for the lfu-decay-time is 1. A Special value of 0 means to# decay the counter every time it happens to be scanned.## lfu-log-factor 10# lfu-decay-time 1########################### ACTIVE DEFRAGMENTATION 自动碎片整理######################### WARNING 此功能是实验性的。但是在生产过程中也进行了压力测试，并且由多位工程师手动测试一段时间。## 什么是自动碎片整理?# -------------------------------## 碎片整理允许Redis服务器压缩存储器中小分配和释放数据之间的空间，从而允许回收内存。## 碎片是每个分配器都会发生的自然过程（但幸运的是，Jemalloc并不如此），以及某些工作负载。 # 通常情况下，需要重新启动服务器以降低碎片，或至少清除所有数据并重新创建。 # 然而，由于Oran Agra为Redis 4.0实现的这个特性，这个过程可以在运行时以“热”的方式发生，而服务器并不会停止。## 基本上，当碎片超过特定级别时（请参阅下面的配置选项）# Redis将开始通过利用某些特定的Jemalloc功能（为了理解分配是否导致分段并将其分配到更好的位置）而在连续内存区域中创建值的新副本，# 并且同时将释放 旧的数据副本。 此过程对所有键重复递增将导致碎片回落到正常值。## 重要了解的几点：## 1. 此功能在默认情况下处于禁用状态，只有在编译Redis时才能使用我们随Redis源代码一起提供的Jemalloc副本。 这是Linux版本的默认设置。## 2. 如果您没有碎片问题，则永远不需要启用此功能。## 3. 一旦遇到碎片，您可以在需要时使用命令“CONFIG SET activedefrag yes”启用此功能。## 配置参数能够微调碎片整理过程的行为。 如果您不确定它们的含义，最好保持默认值不变。# 开启碎片整理# activedefrag yes# 最小量的碎片浪费来启动主动碎片整理# active-defrag-ignore-bytes 100mb# 碎片启动主动碎片整理的最小百分比# active-defrag-threshold-lower 10# 我们使用最大努力的最大碎片百分比# active-defrag-threshold-upper 100# 在CPU百分比中进行碎片整理的最小努力# active-defrag-cycle-min 25# 在CPU百分比中进行碎片整理的最大努力# active-defrag-cycle-max 75","categories":[{"name":"other","slug":"other","permalink":"http://www.icepear.cn/categories/other/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://www.icepear.cn/tags/Redis/"}]},{"title":"mysql 配置解析","slug":"mysql/mysql-conf","date":"2018-06-20T11:30:02.000Z","updated":"2018-07-13T04:01:13.382Z","comments":true,"path":"2018/06/20/mysql/mysql-conf/","link":"","permalink":"http://www.icepear.cn/2018/06/20/mysql/mysql-conf/","excerpt":"最近对mysql的配置进行了了解，通过一些文档，所以把配置的一些参数都罗列了一下","text":"最近对mysql的配置进行了了解，通过一些文档，所以把配置的一些参数都罗列了一下 下载链接文件的下载链接 配置文件 配置内容123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280# 自用Docker MySql5.7配置文件my.cnf设置 # 可参考https://dev.mysql.com/doc/refman/8.0/en/server-system-variables.html[mysqld]pid-file = /var/run/mysqld/mysqld.pidsocket = /var/run/mysqld/mysqld.sockdatadir = /var/lib/mysql# 支持符号链接，就是可以通过软连接的方式，管理其他目录的数据库，最好不要开启，当一个磁盘或分区空间不够时，# 可以开启该参数将数据存储到其他的磁盘或分区。使用命令 ln -s /dr1/databases/test /path/to/datadir# 参考 https://dev.mysql.com/doc/refman/8.0/en/symbolic-links-to-databases.htmlsymbolic-links=0# 此变量用于限制数据导入和导出操作的效果，例如由LOAD DATA和SELECT ... INTO OUTFILE语句和LOAD_FILE（）函数执行的操作。# 这些操作只允许拥有FILE权限的用户使用。NULL值为禁用导入导出secure-file-priv= NULLskip-host-cache# 只能用IP地址检查客户端的登录，不用主机名skip-name-resolve#####################基础设置################## Mysql服务的唯一编号 每个mysql服务Id需唯一server-id = 1# 服务端口号 默认3306port = 3306# 用户名 默认root# user = mysql# 默认值为本地地址# bind_address = 127.0.0.1# 主要用于MyISAM存储引擎,如果多台服务器连接一个数据库则建议注释下面内容# skip-external-locking# 设置autocommit=0，则用户将一直处于某个事务中，直到执行一条commit提交或rollback语句才会结束当前事务重新开始一个新的事务。# set autocommit=0的好处是在频繁开启事务的场景下，减少一次begin的交互。autocommit = 0# utf8mb4编码是utf8编码的超集，兼容utf8，并且能存储4字节的表情字符。 # 采用utf8mb4编码的好处是：存储与获取数据的时候，不用再考虑表情字符的编码与解码问题。character_set_server=utf8mb4# 数据库字符集对应一些排序等规则，注意要和character-set-server对应collation-server = utf8mb4_general_ci# 设置client连接mysql时的字符集,防止乱码init_connect=&apos;SET NAMES utf8mb4&apos;# 事务隔离级别，默认为可重复读，mysql默认可重复读级别（此级别下可能参数很多间隙锁，影响性能）transaction_isolation = READ-COMMITTED# 是否区分大小写，0区分，1不区分，2，表名存储以规定格式存，但比较还是用小写lower_case_table_names = 1# 最大连接数max_connections = 800# 在MySQL暂时停止响应新请求之前的短时间内多少个请求可以被存在堆栈中# 官方建议back_log = 50 + (max_connections / 5),封顶数为900back_log = 210# 最大错误连接数，对于同一主机，如果有超出该参数值个数的中断错误连接，则该主机将被禁止连接。# 如需对该主机进行解禁，执行：FLUSH HOST。max_connect_errors = 1000# TIMESTAMP如果没有显示声明NOT NULL，允许NULL值explicit_defaults_for_timestamp = true# SQL数据包发送的大小，如果有BLOB对象建议修改成1Gmax_allowed_packet = 128M# MySQL连接闲置超过一定时间后(单位：秒)将会被强行关闭# MySQL默认的wait_timeout 值为8个小时, interactive_timeout参数需要同时配置才能生效interactive_timeout = 1800wait_timeout = 1800# 临时目录 比如load data infile会用到tmpdir = /tmp# 内部内存临时表的最大值 ，默认64M，设置成128M。# 比如大数据量的group by ,order by时可能用到临时表，# 超过了这个值将写入磁盘，系统IO压力增大tmp_table_size = 134217728max_heap_table_size = 134217728# MySQL读入缓冲区的大小，该参数对应的分配内存是每连接独占（以字节为单位）。# 如果您执行多次连续扫描，则可能需要增加此值，该值默认为131072.此变量的值应为4KB的倍数。# 如果设置的值不是4KB的倍数，则其值将舍入到4KB的最接近倍数。现在都是InnerDB存储引擎，设置作用不大read_buffer_size = 8388608# MySQL的随机读缓冲区大小，将该变量设置为较大的值可以大大提高ORDER BY的性能。# 但是，这是为每个客户端分配的缓冲区，因此您不应将全局变量设置为较大的值。# 相反，只需从需要运行大型查询的客户端中更改会话变量。默认值256kb 所以设值2Mread_rnd_buffer_size = 2097152# MySQL在完成某些join（连接）需求的时候，为了减少参与join的“被驱动表”的读取次数以提高性能，需要使用到join buffer来协助完成join操作# 当join buffer 太小，MySQL不会将该buffer存入磁盘文件而是先将join buffer中的结果与需求join的表进行操作，# 然后清空join buffer中的数据，继续将剩余的结果集写入次buffer中，默认值262144，对应的也是每个独占连接join_buffer_size = 8388608# MySQL的顺序读缓冲区大小 order by或group by时用到，建议先用4M试一下，对应的也是每个独占连接sort_buffer_size = 4194304#一般数据库中没什么大的事务，设成1~2M，默认32kbbinlog_cache_size = 524288####################日志设置########################## 数据库错误日志文件(针对docker)log_error = /home/log/error.log# 慢查询sql日志设置slow_query_log = 1slow_query_log_file = /home/log/slow.log# 检查未使用到索引的sqllog_queries_not_using_indexes = 1# 针对log_queries_not_using_indexes开启后，记录慢sql的频次、每分钟记录的条数log_throttle_queries_not_using_indexes = 5# 作为从库时生效,从库复制中如何有慢sql也将被记录log_slow_slave_statements = 1# 慢查询执行的秒数，必须达到此值可被记录long_query_time = 8# 检索的行数必须达到此值才可被记为慢查询min_examined_row_limit = 1000# mysql binlog日志文件保存的过期时间，过期后自动删除expire_logs_days = 7####################主从复制设置########################## 参考https://dev.mysql.com/doc/refman/5.7/en/replication-options.html# 将master.info和relay.info保存在表中master_info_repository = TABLErelay_log_info_repository = TABLE# 开启mysql binlog二进制日志功能log_bin = /home/log/bin.log# 当每进行n次事务提交之后，MySQL将进行一次fsync之类的磁盘同步指令来将binlog_cache中的数据强制写入磁盘。设置为零是让系统自行决定# 为1时安全性高，只丢失一次事物数据，消耗同样也大sync_binlog = 5# 从服务器的更新是否写入二进制日志，从库必须开启了二进制日志功能log_slave_updates = 1# 开启全局事务ID，GTID能够保证让一个从服务器到其他的从服务器那里实现数据复制而且能够实现数据整合的gtid_mode = on# 开启gtid，必须主从全开enforce_gtid_consistency = 1# 开启简单gtid，开启此项会提升mysql执行恢复的性能binlog_gtid_simple_recovery = 1# 从服务器的更新是否写入二进制日志log_slave_updates = 1# 三种模式 STATEMENT（有可能主从数据不一致，日质量小）版本小于5.7.6的默认值；ROW（产生大量二进制日志）版本大于5.7.7的默认值、MIXEDbinlog_format = row# 对于binlog_format = ROW模式时，减少记录日志的内容，只记录受影响的列# full（记录所有列）默认# minimal（仅记录更改的列和标识行所需的列）# noblob（记录所有列，除了不需要的blob和文本列）binlog_row_image = minimal# relay-log日志记录的是从服务器I/O线程将主服务器的二进制日志读取过来记录到从服务器本地文件，然后SQL线程会读取relay-log日志的内容并应用到从服务器relay_log = /home/log/relay.log# 作为从库时生效,中继日志relay-log可以自我修复relay_log_recovery = 1# 作为从库时生效,主从复制时忽略的错误slave_skip_errors = ddl_exist_errors#######################Innodb设置######################### 参考 https://dev.mysql.com/doc/refman/5.7/en/innodb-parameters.html# 这个参数在一开始初始化时就要加入my.cnf里，如果已经创建了表，再修改，启动MySQL会报错。最好为8K#innodb_page_size = 16384innodb_page_size = 8192# 数据缓冲区buffer pool大小，建议使用物理内存的 75%innodb_buffer_pool_size = 8G# 缓冲池实例数量，当buffer_pool的值较大的时候为1，较小的设置为8innodb_buffer_pool_instances = 8# 运行时load缓冲池，快速预热缓冲池，将buffer pool的内容（文件页的索引）dump到文件中，然后快速load到buffer pool中。# 避免了数据库的预热过程，提高了应用访问的性能 默认值(&gt;= 5.7.7) 开启;默认值(&lt;= 5.7.6)关闭。innodb_buffer_pool_load_at_startup = 1# 运行时dump缓冲池 默认值(&gt;= 5.7.7) 开启;默认值(&lt;= 5.7.6)关闭。innodb_buffer_pool_dump_at_shutdown = 1# 在innodb中处理用户查询后，其结果在内存空间的缓冲池已经发生变化，但是还未记录到磁盘。这种页面称为脏页，将脏页记录到磁盘的过程称为刷脏innodb_lru_scan_depth = 2000# 参数设置innodb后台任务每秒执行的I / O操作数量的上限，默认值200，好的硬盘可适当调高innodb_io_capacity = 4000# 突破innodb_io_capacity后的上限值innodb_io_capacity_max = 8000# 事务等待获取资源等待的最长时间，超过这个时间还未分配到资源则会返回应用失败，默认50sinnodb_lock_wait_timeout = 30# 设置redoLog文件所在目录, redoLog记录事务具体操作内容，默认为data的home目录：# 系统不会创建该目录，请确保目录已经存在#innodb_log_group_home_dir = /home/log/redolog# 设置undoLog文件所在目录, undoLog用于事务回滚操作#innodb_undo_directory = /home/log/undolog# 这个参数控制着innodb数据文件及redo log的打开、刷写模式# fsync InnoDB 使用fsync（）系统调用来刷新数据和日志文件。fsync是默认设置。# O_DIRECT 不经过系统缓存直接存入磁盘，减少操作系统级别VFS的缓存和Innodb本身的buffer缓存之间的冲突，适用于某些GNU/Linux versions, FreeBSD, and Solaris.# 根据官方提示还有其他选项好像都不可用，Docker官方镜像不支持O_DIRECT#innodb_flush_method = O_DIRECT# 表空间innodb文件格式。支持的文件格式是Antelope和Barracuda# Antelope是原始的innodb文件格式，它支持冗余和紧凑的行格式。# Barracuda是较新的文件格式，它支持压缩和动态行格式。默认值(&gt;= 5.7.7) Barracuda 默认值(&lt;= 5.7.6) Antelope# 但是这两个选项都被弃用了，在后面版本会删除# innodb_file_format = Barracuda# innodb_file_format_max = Barracuda# 当启用innodb_strict_mode时，innodb在某些情况下返回错误而不是警告。默认值(&gt;= 5.7.7) 开启；默认值(&lt;= 5.7.6) 关闭#innodb_strict_mode = 1# 当启用innodb_file_per_table（默认值 开启）时，innodb将每个新创建的表的数据和索引存储在单独的.ibd文件中，而不是系统表空间中。# 当这些表被删除或截断时，这些表的存储将被回收。缺点会导致单个表文件过大innodb_file_per_table = 1# undo日志回滚段 默认为128innodb_undo_logs = 128# 传统机械硬盘建议使用，而对于固态硬盘可以关闭#innodb_flush_neighbors = 1# 日志文件大小1G，默认48M innodb_log_file_size = 1073741842innodb_log_buffer_size = 16777216# 专用于innodb清除操作的后台线程的数量。最小值为1表示清除操作总是由后台线程执行，而不是主线程的一部分。# 在一个或多个后台线程中运行清除操作有助于减少innodb内部的争用，提高可伸缩性。将值增加到大于1会创建许多单独的清除线程，这可以提高在多个表上执行dml操作的系统的效率。# (&gt;= 5.7.8)默认值是4，(&lt;= 5.7.7)默认值是1，最大值是32。innodb_purge_threads = 4# 改为ON时，允许单列索引最大达到3072。否则最大为767，也已经弃用#innodb_large_prefix = 1# innodb中同时保持操作系统线程的数量小于或等于此变量（innodb使用操作系统线程处理用户事务）给出的限制。# 一旦线程数量达到此限制，额外的线程就会进入“先进先出”（fifo）队列中的等待状态以供执行。等待锁的线程数不计入并发执行线程数。# 值范围0-1000,0表示无限并发。如果工作负载的并发用户线程数小于64，建议用默认值0，否则需要视情况进行调整innodb_thread_concurrency = 0# 开启后会将所有的死锁记录到error_log中innodb_print_all_deadlocks = 1# 用于在创建innodb索引期间对数据进行排序的排序缓冲区的大小，仅用于索引创建期间的合并排序，而不用于以后的索引维护操作。innodb_sort_buffer_size = 8338608","categories":[{"name":"mysql","slug":"mysql","permalink":"http://www.icepear.cn/categories/mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://www.icepear.cn/tags/Mysql/"}]},{"title":"原型模式（builder）","slug":"designpattern/prototype","date":"2018-03-16T10:30:00.000Z","updated":"2018-05-24T10:15:28.370Z","comments":true,"path":"2018/03/16/designpattern/prototype/","link":"","permalink":"http://www.icepear.cn/2018/03/16/designpattern/prototype/","excerpt":"原型模式是构造性模式中的一种，它的宗旨就是创建重复的对象，通过克隆，充分保障性能。","text":"原型模式是构造性模式中的一种，它的宗旨就是创建重复的对象，通过克隆，充分保障性能。 源代码地址源码连接 UML类图就不画了，就是通过clone出一个新对象 #源码分析小刚热衷于大保健，还是通过小刚大保健的例子说明见注释分析一个大保健服务1234567891011121314151617181920212223242526public class BigHealthCare implements Cloneable&#123; private String serviceName;//服务名称 public BigHealthCare(String serviceName) &#123; this.serviceName = serviceName; &#125; public String getServiceName() &#123; return serviceName; &#125; public void setServiceName(String serviceName) &#123; this.serviceName = serviceName; &#125; @Override public BigHealthCare clone() throws CloneNotSupportedException &#123; return new BigHealthCare(serviceName); &#125; @Override public String toString() &#123; return \"&#123;\" + \"\\\"serviceName\\\":\\\"\" + serviceName + \"\\\"\" + \"&#125;\"; &#125;&#125; 小刚要做大保健1234567891011121314151617181920212223242526272829public class Test &#123; public static void main(String args[])&#123; //小刚要做大保健服务，但是大保健服务有很多种，有洗脚、按摩、papapa。 //小刚呼叫了一号技师，说要做个洗脚服务 BigHealthCare simpleBighealthcare = new BigHealthCare(\"洗脚\"); System.out.printf(\"一号技师给小刚做了个\"+simpleBighealthcare.getServiceName()+\"服务\\n\"); //小刚说一号技师不错，还想来个按摩，于是加了个服务 try &#123; BigHealthCare generalBighealthcare = simpleBighealthcare.clone(); generalBighealthcare.setServiceName(\"按摩\"); System.out.printf(\"一号技师给小刚做了个\"+generalBighealthcare.getServiceName()+\"服务\\n\"); &#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace(); &#125; //技师手法把小刚弄的欲罢不能，于是小刚还想加服务 try &#123; BigHealthCare specialBighealthcare = simpleBighealthcare.clone(); specialBighealthcare.setServiceName(\"papapa\"); System.out.printf(\"一号技师给小刚做了个\"+specialBighealthcare.getServiceName()+\"服务\\n\"); &#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace(); &#125; //那么问题来了小刚为什么要这么做呢，为什么不每次通过new一下叫个技师来呢？原因有二 //1.小刚服务做得正爽，也就是在run-time时期，可以实现动态加服务 //2.小刚觉得1号技师长得好，技术也好（保持对象原有状态），要是new了一个不好的来就不爽了（浪费资源）。 &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.icepear.cn/categories/设计模式/"}],"tags":[{"name":"原型模式","slug":"原型模式","permalink":"http://www.icepear.cn/tags/原型模式/"}]},{"title":"建造者模式（builder）","slug":"designpattern/builder","date":"2018-03-14T08:30:00.000Z","updated":"2018-05-24T10:15:18.399Z","comments":true,"path":"2018/03/14/designpattern/builder/","link":"","permalink":"http://www.icepear.cn/2018/03/14/designpattern/builder/","excerpt":"建造者模式属于设计模式中的构造性模式，也就是说该模式基本上是用在构建对象的时候。它的宗旨就是将一个复杂的事物，进行一步一步的构建，需要什么就拼接成什么。","text":"建造者模式属于设计模式中的构造性模式，也就是说该模式基本上是用在构建对象的时候。它的宗旨就是将一个复杂的事物，进行一步一步的构建，需要什么就拼接成什么。 源代码地址源码连接 UML类图如下： Derictor: 指挥人，哔哩吧啦说你这玩意儿要怎么建builder：抽象建造者，怎么建的一系列方法concreteBuilder：具体的劳动力，实现建造的方法product：具体的产品类 #源码分析给大家讲一个生动形象的例子，小刚喜欢大保健，没事就去洗洗脚按按摩。从这句话里面，我们就可以分析出一个模式。大保健：具体的产品小刚：享受服务的指挥人，要什么服务都由他决定老板：大保健服务的建造者 传统模式下，小刚要一个大保健服务是不是说：老板，做个大保健（new dabaojian()）服务就出来了。但是存在一个问题，这样叫出来的是个大保健，但是具体哪一些服务没有指定，老板肯定问你：都想做什么服务；那服务种类很多，不可能每次都是12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576new Dabaojian(\"洗脚\");new Dabaojian(\"洗脚\",\"按摩\");new Dabaojian(\"洗脚\",\"按摩\",\"papapa\");``` 服务千姿百态这样就会存在弊端。老板也想到这个问题了所以老板就会拼接各种服务给客人做成一个大保健具体见代码分析```javapublic class Bighealthcare &#123; private String xijiao; private String anmo; private String papapa; /** * 传统享受大保健服务就洗洗脚 * @param xijiao */ public Bighealthcare(String xijiao)&#123; this.xijiao = xijiao; &#125; /** * 舒服一点就加个按摩 * @param xijiao */ public Bighealthcare(String xijiao,String anmo)&#123; this.xijiao = xijiao; this.anmo = anmo; &#125; /** * 想更舒服就搞下特殊服务 * @param xijiao * @param anmo * @param papapa */ public Bighealthcare(String xijiao,String anmo,String papapa)&#123; this.xijiao = xijiao; this.anmo = anmo; this.papapa = papapa; &#125; /** * 建造者模式的大保健服务 */ public Bighealthcare(Builder builder)&#123; this.xijiao = builder.xijiao; this.anmo = builder.anmo; this.papapa = builder.papapa; &#125; protected static class Builder&#123; protected String xijiao; protected String anmo; protected String papapa; protected Builder xijiao(String xijiao)&#123; this.xijiao = xijiao; return this; &#125; protected Builder anmo(String anmo)&#123; this.anmo = anmo; return this; &#125; protected Builder papapa(String papapa)&#123; this.papapa = papapa; return this; &#125; protected Bighealthcare build()&#123; return new Bighealthcare(this); &#125; &#125; public void service()&#123; System.out.print(this.toString()); &#125; 小刚要做大保健了12345678910111213141516171819public class Test &#123; public static void main(String args[])&#123; //传统模式下的大保健服务 Bighealthcare tradition = new Bighealthcare(\"洗个脚\",\"按个摩\",\"ppp\"); tradition.service(); //建造器模式下的大保健服务，先构造一个大保健服务，具体要哪些项目可以一个个拼装，扩展方便 //运用《effective java》中说的，当构造方法过多时就应该要考虑使用构造器，其实就是建造者模式 //简单大保健 Bighealthcare simpleBighealthcare = new Bighealthcare.Builder().xijiao(\"洗个脚\").build(); simpleBighealthcare.service(); //一般大保健 Bighealthcare generalBighealthcare = new Bighealthcare.Builder().xijiao(\"洗个脚\").anmo(\"按个摩\").build(); generalBighealthcare.service(); //高级大保健 Bighealthcare specialBighealthcare = new Bighealthcare.Builder().xijiao(\"洗个脚\").anmo(\"按个摩\").papapa(\"ppp\").build(); specialBighealthcare.service(); &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.icepear.cn/categories/设计模式/"}],"tags":[{"name":"建造者模式","slug":"建造者模式","permalink":"http://www.icepear.cn/tags/建造者模式/"}]},{"title":"一张图带你理解sql的join","slug":"mysql/sql_join","date":"2017-08-15T10:00:00.000Z","updated":"2018-07-13T06:14:05.845Z","comments":true,"path":"2017/08/15/mysql/sql_join/","link":"","permalink":"http://www.icepear.cn/2017/08/15/mysql/sql_join/","excerpt":"在数据库查询中，连表查询是经常需要操作的，其关键字就是利用join，下面一张图带你充分理解各种join的意义","text":"在数据库查询中，连表查询是经常需要操作的，其关键字就是利用join，下面一张图带你充分理解各种join的意义","categories":[{"name":"mysql","slug":"mysql","permalink":"http://www.icepear.cn/categories/mysql/"}],"tags":[{"name":"SQL Mysql","slug":"SQL-Mysql","permalink":"http://www.icepear.cn/tags/SQL-Mysql/"}]},{"title":"接口安全策略","slug":"other/api-security","date":"2017-08-09T11:30:02.000Z","updated":"2018-04-20T07:07:22.324Z","comments":true,"path":"2017/08/09/other/api-security/","link":"","permalink":"http://www.icepear.cn/2017/08/09/other/api-security/","excerpt":"在做接口的时候，我们经常会对安全这方面进行考虑，包括认证授权，接口安全等方面，下面就介绍一种接口安全的设计，如果有什么其他好的设计，都可以在评论区提出交流","text":"在做接口的时候，我们经常会对安全这方面进行考虑，包括认证授权，接口安全等方面，下面就介绍一种接口安全的设计，如果有什么其他好的设计，都可以在评论区提出交流 背景为什么要对接口进行安全控制呢，主要是出于这几方面的因素 防伪装攻击 防篡改攻击 防重放攻击 防数据信息泄露 解决办法解决办法有很多，一般常见的做法是token校验然后加上HTTPS。针对这四种情况，假如接口没做任何安全策略是很容易被攻击的。对于第一种防伪装攻击，一般的接口都会带有token认证，可以过滤掉；对于第二种以及第三种，假如别人截获了请求，修改了参数，token机制是没办法做到安全的，所以有效的办法就是加密，加密的办法有很多。下面以图介绍我用的一种这种方法的步骤是 将请求参数（一般是json形式）加上约定好的salt进行AES加密，加密出来的是byte，一般用base64进行转码输出，也可做位偏移，得到一个加密字符串；然后加上后端的token，加上时间戳，进行MD5加密得到一个定长的sign字符串 将sign，toekn，时间戳，参数组成http请求去访问接口这样做的好处就是，针对第二三种攻击，别人拦击你的请求进行篡改，后端根据参数+约定好的salt进行AES加密再加上+token+时间戳进行MD5加密，与sign比对发现两个MD5不一致，就知道，肯定有人篡改了参数，就可以拒绝这样的请求。如果你不想参数直接暴露出来也可以进行AES加密传给后端。这样就可以避免第四种情况 总结以上都是自己的愚见，如果有更好的设计方法，欢迎交流学习","categories":[{"name":"security","slug":"security","permalink":"http://www.icepear.cn/categories/security/"}],"tags":[{"name":"api","slug":"api","permalink":"http://www.icepear.cn/tags/api/"},{"name":"security","slug":"security","permalink":"http://www.icepear.cn/tags/security/"}]},{"title":"go圣经阅读","slug":"other/gopl","date":"2017-08-09T10:30:02.000Z","updated":"2017-11-22T08:18:16.280Z","comments":true,"path":"2017/08/09/other/gopl/","link":"","permalink":"http://www.icepear.cn/2017/08/09/other/gopl/","excerpt":"学习一门新语言时，会有一种自然的倾向, 按照自己熟悉的语言的套路写新语言程序。学习Go语言的过程中，请警惕这种想法，尽量别这么做。我们会演示怎么写好Go语言程序，所以阅读了称之为《go圣经》这本书,并且利用思维导图的方式记录了重点。","text":"学习一门新语言时，会有一种自然的倾向, 按照自己熟悉的语言的套路写新语言程序。学习Go语言的过程中，请警惕这种想法，尽量别这么做。我们会演示怎么写好Go语言程序，所以阅读了称之为《go圣经》这本书,并且利用思维导图的方式记录了重点。","categories":[{"name":"go","slug":"go","permalink":"http://www.icepear.cn/categories/go/"}],"tags":[{"name":"go","slug":"go","permalink":"http://www.icepear.cn/tags/go/"}]},{"title":"HashMap源码记录","slug":"javautil/hashmap","date":"2017-06-15T10:30:00.000Z","updated":"2018-07-13T04:00:52.460Z","comments":true,"path":"2017/06/15/javautil/hashmap/","link":"","permalink":"http://www.icepear.cn/2017/06/15/javautil/hashmap/","excerpt":"hashmap在java里是出现频率较高的类，不管是工作还是面试，掌握hashmap的原理是很重要的，本文也将从整体到细节介绍hashmap","text":"hashmap在java里是出现频率较高的类，不管是工作还是面试，掌握hashmap的原理是很重要的，本文也将从整体到细节介绍hashmap 摘要hashmap在java里是出现频率较高的类，不管是工作还是面试，掌握hashmap的原理是很重要。随着JDK版本的更新，HashMap底层的实现进行了优化，例如引入红黑树的数据结构和扩容的优化等。本文结合JDK1.7和JDK1.8的区别，深入探讨HashMap的结构实现和功能原理。 简介java中Map数据结构定义了一个主要的接口：java.util.Map。主要实现这个接口的类是：HashMap、HashTable、LinkedHashMap、TreeMap。关系如下下面针对各个实现类的特点做一些说明： (1) HashMap： 访问速度快hashcode直接定位，但遍历顺序却是不确定的。 最多只允许一条记录的键为null，允许多条记录的值为null。 非线程安全，可以用 Collections的synchronizedMap方法使HashMap具有线程安全的能力，或者使用ConcurrentHashMap。 (2) Hashtable：没什么卵用，基本上与HashMap类似、虽然线程安全，但介于HashMap与ConcurrentHashMap之间，不上不下。 (3) LinkedHashMap：LinkedHashMap是HashMap的一个子类，保存了记录的插入顺序。 (4) TreeMap： 它保存的记录根据键排序，默认是按键值的升序排序，也可以指定排序的比较器，当用Iterator遍历TreeMap时，得到的记录是排过序的。 如果使用排序的映射，建议使用TreeMap。在使用TreeMap时，key必须实现Comparable接口或者在构造TreeMap传入自定义的Comparator，否则会在运行时抛出java.lang.ClassCastException类型的异常。 本文主要讲HashMap的实现原理，结合1.7和1.8主要从存储结构，常用方法，定位，扩容等方面展开 存储结构存储结构如图： HashMap在1.7中只用到了数组和链表，代码也只有一千多行。上图展示的是1.8的存储结构，在1.8中加入了红黑树，在链表大于8的时候转换为红黑树；扩容后导致红黑树节点在小于6时，又会转换成链表。代码量虽然翻倍了，带来的确实性能的提升。HashMap 1.8结构代码如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // 16 默认hashmap的容量static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; //hashmap最大的容量static final float DEFAULT_LOAD_FACTOR = 0.75f; // 负载因子，跟扩容有关，后面会提到static final int TREEIFY_THRESHOLD = 8; //转换成红黑树的阀值static final int UNTREEIFY_THRESHOLD = 6;//红黑树转成链表的阀值static final int MIN_TREEIFY_CAPACITY = 64;//转换成红黑树最小需要hash数组中的数量大于64// Node 节点static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; //hash值 final K key; // 键 V value; // 值 Node&lt;K,V&gt; next; // 链表下一个节点 ··· //一些默认函数省略掉 &#125;transient Node&lt;K,V&gt;[] table; // 数组transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet; //缓存了hashmap中的nodetransient int size; //存储的node数量transient int modCount; //结构修改次数，跟Fail-Fast机制有关int threshold; // 能负载的node数量（Capacity*loadFactor）初识值 16*0.75 =12final float loadFactor; //负载因子//构造函数，程序员传初始化容量和负载因子进来（一般不用）因为0.75这个值是经过大量的统计计算得出来的结论，一般不更改//也就是说容量到达Capacity的0.75时，进行扩容操作。不至于loadFactor过大，导致hash碰撞过多，太小，扩容次数太多影响性能public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);&#125;// 构造函数，初始化容量（最好也是2的N次幂）这个会影响hash定位public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125;//最常用的构造函数，使用默认的0.75作为负载因子public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; &#125;// 构造函数，传一个map进来，复制到本hashmappublic HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false);//这个函数将用到m这个map中的entrySet，目的是将m中的node通过put函数复制到本hashmap中&#125;//树节点static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt; &#123; TreeNode&lt;K,V&gt; parent; // 根节点 TreeNode&lt;K,V&gt; left; // 左节点 TreeNode&lt;K,V&gt; right; // 右节点 TreeNode&lt;K,V&gt; prev; // 删除后需要取消链接 boolean red; //一些红黑树操作的函数 ···&#125; 实现说明主要从hashmap的主要三个步骤进行说明，hash定位，插入，扩容 hash定位hash定位是HashMap比较核心的方法了，上面我们了解到HashMap的结构为数组，既然是数组，就会有下标，那么这个hash值就是数组的下标，也正是HashMap可以根据key快速查找定位到Value的原因下面看下1.7中hash的源码 12345678910111213final int hash(Object k) &#123; int h = hashSeed; if (0 != h &amp;&amp; k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h ^= k.hashCode(); h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);&#125;static int indexFor(int h, int length) &#123; return h &amp; (length-1);&#125; 在1.8中做了改进 1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 1.8中虽然取消了indexFor函数，但是在put和get的时候都通过了 tab[i = (n - 1) &amp; hash] 来定位，原理跟1.7是一样的可以看出，不管是哪个版本，算法大致分为 取key的hashcode，高位运算 取模运算为了让hash值均匀分布，会采用高位运算，让小的值的高位也参与运算;然后拿运算后key的hashcode对数组的长度进行模运算定位数组中的位置，但是细心一点就会发现，取模运算并没有使用%运算，因为模运算是很耗费性能的，所以采用与运算，可以说这个与运算设计的是相当精巧了。这也就是为什么数组的长度一定要是2的N次幂长度的原因，因为当length等于2的n次幂时，h&amp;(length-1)就等于h%length put实现我们知道HashMap的时间复杂度为O(1)，但是当Hash碰撞率过高时hashmap就会遍历链表，导致某些情况时间复杂度提高至O(n)；所以好的hash算法以及扩容机制是相当重要的，下面就讲讲hashmap插入值的原理单纯的代码加文字，表现力可能没那么强，所以采用文字加流程图的方式进行说明：流程图： 源码解释: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 第1步 判断table是否为null，如果为空进行扩容 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 第2步 判断table中hash值对应的位置是否有值，就是table[i],如果没值，就new一个Node节点存入 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); //第3步 else &#123; Node&lt;K,V&gt; e; K k; //第3步 如果table[i]有值，就判断table[i]的key是否和要插入的值的key相同，相同则令节点e等于table[i] if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //第4步 不相同则判断table[i]是否为树节点，为树节点则将新值插入红黑树,如果红黑树里面存在这个值，也令e等于这个树节点，否则e等于null else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); //第5步 key不相同也不是树节点，则按链表的方式处理，判断链表中是否存在这个值，存在则e等于这个节点，否则将这个值插入到链表，e等于null；插入后判断链表大小是否大于8，大于则转换为红黑树 else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; //第6步 判断e是否为空，不为空说明有相同key的节点，需要进行覆盖，并返回old值 if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; //第7步 如果是old值覆盖，则modCount不变，modCount只有在插入节点才会变化；最后判断table大小是否大于负载值threshold，大于则进行扩容 ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125; 相比较于1.7的插入操作，1.8的优化是引入红黑树，不至于在hash碰撞频繁的情况下，导致链表过长查询速度变慢的问题。在插入操作里最后就是扩容函数，想必很想知道hashmap是怎么扩容的，下面详细讲讲扩容原理 扩容resize就是更换容器，小桶放不下了得换个大桶。前面我们了解到，table是个数组，我们也知道数组是有大小的，不能动态的扩张，但是HashMap对象却可以不停的添加元素，这也真是resize帮我们做的，方法就是使用一个新的数组代替已有的容量小的数组。下面我们分析下resize的源码。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; //如果hashmap存在值 if (oldCap &gt; 0) &#123; // 超过最大值就不再扩充 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; //否则负载数量左移一位，翻倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; //负载量大于0，则用负载量替换容量 else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; //都为0则初始化容量和负载量 else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; //计算新的负载量上限 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;\"rawtypes\",\"unchecked\"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; //将原来的数据放入新的数组中 if (oldTab != null) &#123; //遍历老数组 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; //oldTab[j]存在数据 if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; //不是链表，直接定位值并插入 if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; //树节点操作，里面实现不细讲（实际上有点复杂） else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); //数组节点操作（非常精辟的一段操作，简直牛逼） else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125;","categories":[{"name":"java.util","slug":"java-util","permalink":"http://www.icepear.cn/categories/java-util/"}],"tags":[{"name":"HashMap Map","slug":"HashMap-Map","permalink":"http://www.icepear.cn/tags/HashMap-Map/"}]},{"title":"多线程高并发面试题（Multithreading & Concurrency）","slug":"concurrency/interview","date":"2017-06-10T11:30:02.000Z","updated":"2018-03-26T09:08:11.841Z","comments":true,"path":"2017/06/10/concurrency/interview/","link":"","permalink":"http://www.icepear.cn/2017/06/10/concurrency/interview/","excerpt":"线程是java面试问题中的热门话题之一，下面总结了一些Java多线程以及并发访问问题和答案，毕竟多线程和并发性都是并存的。","text":"线程是java面试问题中的热门话题之一，下面总结了一些Java多线程以及并发访问问题和答案，毕竟多线程和并发性都是并存的。 多线程和并发多线程Process和Thread之间的区别 进程是一个独立的运行环境，能够看做是一个程序或者应用，java运行环境运行作为一个简单的包含不同的类和程序的进程集。 而线程可以叫做一个轻量级的进程，线程可以看作是进程中的一个执行任务，线程需要较少的资源来创建并存在于进程中，线程共享进程资源 多线程编程的优点多线程编程可以并发的执行，提高性能，因为某些线程会等待获取某些资源所以cpu不会闲置，多线程共享堆内存，所以创建多线程比创建多进程要好，举个例子就是Servlets的性能要比CGI要好 用户线程和守护线程有什么不同首先都是线程，区别是用户线程dead后，JVM就会退出，不管是否还有守护线程，因为守护线程本来就是守护用户线程的，用户线程都死了，守护线程也没有存在的意义，所以JVM就退出了。还有就是守护线程创建的子线程也是守护线程 在java中怎么创建一个线程 通过实现Runnable接口，重写run方法，线程通过New Thread(new 线程类())的方式创建，通过调用start方法启动 通过extend一个Thread类，重写run方法，通过new 线程类()的方式创建，通过调用start方法启动我们可以直接调用run方法，像普通方法那样，但是这时，线程是没有启动的，只有通过start方法，线程才会启动如果你的类提供更多的功能，建议实现Runnable接口。毕竟java是多实现，单继承，所以优先Runnable 线程的生命周期有哪些创建，就绪，运行，阻塞，死亡这五种方式 当new出线程类时，线程处于创建状态 当调用start方法时，线程处于就绪状态 当run方法执行时，线程处于运行状态 当线程因为某些原因放弃cpu资源时，处于阻塞状态。直到重新进入就绪状态，才有机会再次运行 当线程run方法执行完了，或者运行过程中异常中断了，或者调用了stop方法，就会退出run方法，此时线程就死亡了 怎样理解线程的优先级每个线程都有优先级，通常优先级较高的线程在执行时优先，但这个要取决于操作系统相关的线程调度程序实现。我们可以定义线程的优先级，线程优先级是一个int，从1到10,1的优先级最低，10最高。但不能保证优先级较低的线程之前一定执行优先级较高的线程。 什么是线程调度和时间分片线程调度器是一个操作系统服务，它负责为Runnable状态的线程分配CPU时间。一旦创建一个线程并启动它，它的执行便依赖于线程调度器的实现。时间分片是指将可用的CPU时间分配给可用的Runnable线程的过程。分配CPU时间可以基于线程优先级或者线程等待的时间。线程调度并不受到Java虚拟机控制，所以由应用程序来控制它是更好的选择（也就是说不要让的程序依赖于线程的优先级） 如何确保main（）是Java程序中最后完成的线程我们可以使用Thread join（）方法来确保在完成主函数之前程序创建的所有线程都已经死亡 线程间通信方式主要是通过线程间内存共享，通过类的wait(),notify(),notifyAll()方法进行，这些方法都应该在同步方法或同步块中调用。 怎么确保线程安全 同步是最简单也是最广泛的线程安全工具 使用java.util.concurrent.atomic下的Atomic Wrapper类，例如AtomicInteger 使用java.util.concurrent.locks包中的类 使用线程安全的集合类，也在java.util.concurrent中，例如ConcurrentHashMap 将volatile关键字与变量一起使用，使每个线程都从内存中读取数据，而不是从线程缓存中读取数据。 volatile 关键字当使用volatile 关键字定义变量时，所有的线程将从主内存中读取而不是从线程的本地缓存读取，这就能确保变量在多线程的情况下也是同步的 同步块和同步方法那个更好更倾向于同步块的写法，因为同步块可以指定minitor对象锁定，可控制粒度更小。而同步方法会锁定整个对象，并且如果类中有多个同步块，即使它们不相关，也会阻止它们执行并将它们置于等待状态 创建守护线程的方法通常创建守护线程用于对系统不重要的功能，例如记录线程或监事线程来捕获系统资源细节和状态，最好避免IO操作的守护线程可以用Thread.setDaemon(true) 创建 ThreadLocal是什么ThreadLocal用于创建线程的局部变量，对象的所有线程共享它的变量，所以这个变量不是线程安全的，可以使用线程同步来达到线程的目的，但是如果想避免同步，就可以使用ThreadLocal变量，每个线程都有自己的ThreadLocal变量互不影响，可以使用get/set方法来设置和获取值 什么是死锁，怎么分析和避免死锁死锁是指两个或以上的线程永远处于阻塞状态。分析死锁，可以通过查看应用程序的java Thread dump，可以通过jstack工具查看状态为阻塞的线程，然后查看它正在等待的锁定的资源，每个资源都有一个唯一的ID，我们可以使用它找到哪个线程已经在对象上持有锁有以下准则可以避免死锁 避免嵌套锁定，这是大部分死锁的情况，也就是说尽量不要在锁定资源a的情况下，又去锁定资源b 只锁定需要锁定的东西，你应该只获取必须处理的资源的锁，如果我们只对某一个字段感兴趣，那么我们应该只锁定该特定字段而不是完整对象 避免无限等待，如果线程a必须等待线程b完成，尽量不要用sleep去控制，而是使用threa.join串行执行 什么是线程池，如何创建线程池根据系统自身的环境情况，有效的限制执行线程的数量，使得运行效果达到最佳。线程主要是通过控制执行的线程的数量，超出数量的线程排队等候，等待有任务执行完毕，再从队列最前面取出任务执行。创建线程池的方式有多种 java.util.concurrent.Executors 提供了线程池的静态实现方法,但一般不推荐这种写法 newFixedThreadPool();创建的线程池corePoolSize和maximumPoolSize值是相等的，它使用的LinkedBlockingQueue； newSingleThreadExecutor();将corePoolSize和maximumPoolSize都设置为1，也使用的LinkedBlockingQueue； newCachedThreadPool();将corePoolSize设置为0，将maximumPoolSize设置为Integer.MAX_VALUE，使用的SynchronousQueue，也就是说来了任务就创建线程运行，当线程空闲超过60秒，就销毁线程。 newScheduledThreadPool(); 用于创建一个线程池，线程池中得线程能够周期性地执行给定的任务 ThreadPoolExecutor类提供了更完善的线程池创建构造方法 ScheduledExecutorService 类提供了定期执行任务线程池 并发什么是原子操作，java并发api中的原子类是什么原子操作在一个任务单元中执行，不受其他操作的干扰。原子操作在多线程环境中是必需的，以避免数据不一致。比如int++ 就不是一个原子操作，因为再多线程的情况下，某个线程执行了加1，但其他线程可能读的还是旧的值，就会导致错误的结果。为了解决这个问题，我们必须保证count的增量操作是院子的，我们可以使用同步来达到目的，但java1.5以后在java.util.concurrent.atomic提供了int和long的包装类，可以用来实现这个原子操作，没有使用同步，有兴趣的可以深入了解实现 java并发api中的Lock接口是什么？与synchronize相比，它有什么好处？Lock 借口提供了更多广泛的锁定操作比使用synchronized，Lock结构更加灵活，可以有完全不同的属性，并且可以关联多个条件对象Lock有以下优点 可以让线程更公平 可以使线程在等待一个锁定对象时响应中断 可以去尝试获取锁定，但如果无法获取锁定时，则会立即返回或在超时后返回 可以以不同的顺序获取或释放不同范围内的lock 谈谈ExcutorExcutor 是在jdk 1.5 引入的，通过java.util.concurrent.Executor接口Excutor 主要是根据一组执行策略规范调用，调度，执行和控制异步任务创建多个线程并且没有达到最大阈值的限制会导致应用程序耗尽堆内存，所以创建线程池是一个比较好的解决方案，应为有限的线程可以被集中和重用，而Excutor就是为了更好的创建线程池设计的 什么是BlockingQueue，怎么通过BlockingQueue实现一个生产者消费者模型java.util.concurrent.BlockingQueue 是一个阻塞队列，阻塞必然有两种情况， 当队列满了的时候，进行入列操作会被阻塞 当队列空的时候，出列操作会被阻塞阻塞队列是线程安全的，所有排队方法本质上都是原子性的，使用内部锁或其他形式的并发控制阻塞队列主要也是用于生产者消费者问题，负责生产的线程不断的制造新对象并插入到阻塞队列中，直到达到这个队列的上限值。队列达到上限值之后生产线程将会被阻塞，直到消费的线程对这个队列进行消费。同理，负责消费的线程不断的从队列中消费对象，直到这个队列为空，当队列为空时，消费线程将会被阻塞，除非队列中有新的对象被插入。 谈谈Callable和FutureCallable相当于Runnable的一个扩展，不同于Runnable的是Callable是个泛型参数化接口，并能返回线程的执行结果，而且能在无法正常计算时抛出异常。Callable并不像Runnable那样通过Thread的start方法就能启动实现类的run方法，通常是利用ExecutorService的submit方法去启动call方法自执行任务，而ExecutorService的submit又可以返回一个Future类型的结果，因此Callable通常也与Future一起使用，还有一种方式是使用FutureTask封装Callable再由Thread去启动。所以Callable的好处是异步执行，还能返回结果，结合Future还能判断任务状态，取消任务 谈谈FutureTaskFutureTask是Future接口基类的实现类，可以和Executors一起用于异步处理，大多数情况下很少使用FutureTask类，但如果我们想要覆盖Future类的某些方法，并且保留基本实现，它就变得非常方便。我们可以扩展这个类，根据需求覆盖一些方法 谈谈Concurrent Collection类通常Collection类是快速失败的，这意味着当一个线程在使用iterator便利时，去修改集合，这个iterator.next()操作将抛出ConcurrentModificationException异常。而Concurrent Collection则不会出现这个问题，因为它就是为多线程设计的主要的类包括 ConcurrentHashMap, CopyOnWriteArrayList 和 CopyOnWriteArraySet 讲讲Executors类Executors 提供了很多静态使用方法，包括Executor, ExecutorService, ScheduledExecutorService, ThreadFactory, 以及 Callable，所以可以使用executors类在java中轻松创建线程池，这也是唯一支持可调用实现执行的类。 java8中并发改进了哪些？重要的改进包括： ConcurrentHashMap 的compute(), forEach(), forEachEntry(), forEachKey(), forEachValue(), merge(), reduce() 和 search() 等方法 加入了CompletableFuture ，使异步编程更优美 Executors 新增了 newWorkStealingPool 线程池方法","categories":[{"name":"多线程","slug":"多线程","permalink":"http://www.icepear.cn/categories/多线程/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"http://www.icepear.cn/tags/多线程/"},{"name":"高并发","slug":"高并发","permalink":"http://www.icepear.cn/tags/高并发/"},{"name":"面试","slug":"面试","permalink":"http://www.icepear.cn/tags/面试/"}]},{"title":"jenkins 持续集成","slug":"jenkins/jenkins","date":"2017-04-10T10:30:02.000Z","updated":"2018-04-20T06:30:34.292Z","comments":true,"path":"2017/04/10/jenkins/jenkins/","link":"","permalink":"http://www.icepear.cn/2017/04/10/jenkins/jenkins/","excerpt":"持续集成是DevOps不可或缺的一部分，可以减少大量的部署操作。之所以选择jenkins，其重要原因可能在于其开源免费，接下来进行详细介绍","text":"持续集成是DevOps不可或缺的一部分，可以减少大量的部署操作。之所以选择jenkins，其重要原因可能在于其开源免费，接下来进行详细介绍 JenkinsWhat is Jenkins? Jenkins is a self-contained, open source automation server which can be used to automate all sorts of tasks related to building, testing, and deploying software. Jenkins can be installed through native system packages, Docker, or even run standalone by any machine with a Java Runtime Environment (JRE) installed. 官方给出了两点定义,大概的意思就是: jenkins 是一个独立的开源自动化服务器，可用于自动化与构建，测试和部署软件相关的各种任务。 Jenkins可以通过本机系统软件包安装，Docker，甚至可以通过安装Java Runtime Environment（JRE）的任何机器独立运行。 构建现在主要的这类软件，我都习惯使用docker进行部署，当然官方也说了可以直接使用jre，根据个人习惯选择。介绍三种方法: docker方式(推荐) 下载镜像 1docker pull jenkins 运行实例 1docker run -p 8080:8080 -p 50000:50000 jenkins 如果想挂载数据到宿主机，就先创建一个目录 1docker run -p 8080:8080 -p 50000:50000 -v /your/home:/var/jenkins_home jenkins 这只是简单的运行，并不能用于实际，后面会细说 jre运行下载,然后运行 1java -jar jenkins.war 官方方式 Ubuntu 1234wget -q -O - https://pkg.jenkins.io/debian/jenkins.io.key | sudo apt-key add -sudo sh -c 'echo deb http://pkg.jenkins.io/debian-stable binary/ &gt; /etc/apt/sources.list.d/jenkins.list'sudo apt-get updatesudo apt-get install jenkins centos 123sudo wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.reposudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.keyyum install jenkins 你也可以在/etc/sysconfig/jenkins中修改参数 12JENKINS_USER=\"root\"JENKINS_PORT=\"8008\" 设置完成之后，运行 1service jenkins start 如果能成功启动,那么恭喜你。像我就没这么轻松了，一脚下去几个坑，md，只能默默地填上。 坑1: 本以为可以成功,查看/etc/log/jenkins/jenkins.log发现端口占用导致错误,我X,docker那边没停占用了8008 顺带记录一下查看端口占用命令，老是忘 查看端口占用： 12 netstat -anp | grep 8008 或者 lsof -i:8008 查看应用占用： 1ps -aux | grep docker 坑2: 端口解决了，结果尼玛还是失败,发现启动脚本里面的java路径没设置 1vi /etc/init.d/jenkins 打开脚本发现 12345678candidates=\"/etc/alternatives/java/usr/lib/jvm/java-1.8.0/bin/java/usr/lib/jvm/jre-1.8.0/bin/java/usr/lib/jvm/java-1.7.0/bin/java/usr/lib/jvm/jre-1.7.0/bin/java/usr/bin/java\" 尼玛，还要配java路径,加上之后是可以启动了。 坑3 你以为启动了就ok了,简直是葫芦娃救爷爷，一个一个来。发现访问不了，于是乎怀疑是防火墙问题 打开端口后，终于正常了 上图 细说docker方式运行以docker方式运行，主要是快速方便。搭建docker形式需要注意几点 需要自己编写dockerfile，安装所需的一些工具 如果利用jenkins构建docker镜像，就要考虑是使用dockerIndocker还是dockerOutdocker 如果项目使用docker，可以考虑镜像私服，搭建方法可以参考下面详细针对这几点说明。 编写dockerfile是必要的，为什么这么说呢，因为避免不了要使用docker，jenkins使用docker有两种方式，一种是在dockerfile中再安装一个docker就是所谓的dockerIndocker，但是很多都不太推荐这种用法，大部分还是选择将宿主机的docker挂载至jenkins容器内运行。那既然能挂载那为什么还要写dockerfile呢，因为你宿主机跟jenkins镜像引入的基础镜像里自带的一些包都有些差异，毕竟镜像不可能像宿主机一样完整。像我用的centos，直接将docker挂进容器里面用，jenkins运行docker命令就会提示包不存在1docker: error while loading shared libraries: libltdl.so.7: cannot open shared object file: No such file or directory 后面找了一下，其实就是少包参考链接所以最终还是编写dockerfile，然后安装缺少的包假如宿主机docker 的权限是root，直接挂进jenkins容器还是会存在权限问题运行docker权限错误12Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock:Get http://%2Fvar%2Frun%2Fdocker.sock/v1.27/containers/json: dial unix /var/run/docker.sock: connect: permission denied 参考链接办法就是看宿主机docker用户的GID是多少，然后镜像中对应添加一致的，就可以愉快的在jenkins容器中使用docker了，我的dockerfile如下：1234567891011121314151617FROM jenkins:latestUSER rootARG DOCKER_GID=991RUN groupadd -g $&#123;DOCKER_GID&#125; dockerRUN apt-get update \\ &amp;&amp; apt-get install -y sudo libltdl-dev expect \\ &amp;&amp; rm -rf /var/lib/apt/lists/*RUN usermod -aG docker jenkinsRUN echo \"jenkins ALL=NOPASSWD: ALL\" &gt;&gt; /etc/sudoersUSER jenkins jenkins自动部署也少不了maven，jdk一系列插件，建议是直接挂在宿主机使用的，运行命令如下：docker run -p 8008:8080 -p 50000:50000 –add-host stpass-15.com:192.168.110.15 –name jenkins \\ -v /home/wulm/jenkins:/var/jenkins_home \\ -v /home/wulm/jdk1.8.0_131:/usr/java/jdk1.8.0_131 \\ -v /var/maven:/var/maven \\ -v /root/.ssh:/jenkins/.ssh \\ -v /usr/bin/docker:/usr/bin/docker:ro \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -d myjenkins:1.0（注：–add-host 是为了让容器dns能识别到内网私服库的域名）","categories":[{"name":"jenkins","slug":"jenkins","permalink":"http://www.icepear.cn/categories/jenkins/"}],"tags":[{"name":"jenkins","slug":"jenkins","permalink":"http://www.icepear.cn/tags/jenkins/"},{"name":"持续集成","slug":"持续集成","permalink":"http://www.icepear.cn/tags/持续集成/"}]},{"title":"docker 私服库(V2)","slug":"other/docker-registry","date":"2017-04-09T10:30:02.000Z","updated":"2017-11-14T03:55:09.071Z","comments":true,"path":"2017/04/09/other/docker-registry/","link":"","permalink":"http://www.icepear.cn/2017/04/09/other/docker-registry/","excerpt":"搭建docker 私服库是持续集成的一部分，当然你可以使用公共库，但我更倾向于私服库，对团队内部来讲还是相当有益的，接下来详细记录如何搭建以及注意环节","text":"搭建docker 私服库是持续集成的一部分，当然你可以使用公共库，但我更倾向于私服库，对团队内部来讲还是相当有益的，接下来详细记录如何搭建以及注意环节 docker registry 搭建介绍registry是一种开源的,无状态，高度可扩展的服务器端应用程序，可存储和分发Docker映像。其实这些都是屁话，哈哈，只要了解私服库字面意思就知道是干嘛的了。V1就直接pass了，官方都抛弃了，直接用的是V2 搭建前提：先安装了docker，而且版本1.6以上 下载下载比较简单，通过docker下载镜像就行了1docker pull registry:2 简单运行下载之后，运行1docker run -d -p 5000:5000 --restart=always --name registry registry:2 这样一个私服库就跑起来了，但事实上这样基本上是没卵用的。官方文档说了A production-ready registry must be protected by TLS and should ideally use an access-control mechanism生产必须被TLS保护，合理的使用访问控制所以说了这么多其实没卵用，官方文档这么带我的，我也就这么写咯，所以还是看下面吧 安全运行 做TLS就要签名证书，所以第一步就是创建证书用openssl创建文件夹用于存放证书,也为了方便后续挂载至registry容器,官方也有1234$ mkdir -p certs$ openssl req \\ -newkey rsa:4096 -nodes -sha256 -keyout certs/domain.key \\ -x509 -days 365 -out certs/domain.crt 注意一定要输入CN（common name）之后的要用到(例如：myregistrydomain.com)创建之后，文件夹下就有两个文件：domain.crt domain.key 将证书添加至系统信任使用身份验证时，Docker的某些版本还要求在操作系统级别信任证书。centos:12$ cat certs/domain.crt » /etc/pki/tls/certs/ca-bundle.crt$ update-ca-trust ubuntu:12$ cp certs/domain.crt /usr/local/share/ca-certificates/myregistrydomain.com.crt$ update-ca-certificates 生成用户和密码光有TLS是不够的，还必须做到访问控制。实现访问限制的最简单方法是通过Native basic auth（这与其他Web服务器的基本身份验证机制非常相似）。 1234$ mkdir auth$ docker run \\ --entrypoint htpasswd \\ registry:2 -Bbn testuser testpassword &gt; auth/htpasswd 启动registry容器万事具备，只欠东风。现在只需要把容器启动起来，该挂载的挂载，改配的环境变量配上 12345678910111213docker run -d \\ -p 5000:5000 \\ --restart=always \\ --name registry \\ -v /home/docker-registry:/var/lib/registry \\ -v /home/wulm/auth:/auth \\ -e \"REGISTRY_AUTH=htpasswd\" \\ -e \"REGISTRY_AUTH_HTPASSWD_REALM=Registry Realm\" \\ -e REGISTRY_AUTH_HTPASSWD_PATH=/auth/htpasswd \\ -v /home/wulm/certs:/certs \\ -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/domain.crt \\ -e REGISTRY_HTTP_TLS_KEY=/certs/domain.key \\ registry:2 至此registry算是搭建成功了，但是真的成没成功还得测试，最简单的是直接访问前提是这个域名写到了你的hosts文件 客户端docker测试 在另外一台主机上测试私服库是否可用，才能真正测试出正确性。 首先将myregistrydomain.com域名（也就是你配置的域名）对应的IP一起写到你的hosts文件中，以便系统能够根据域名找到私服 1vi /etc/hosts 在文件末尾添加一行 然后不管以什么方法，将私服库上的证书搞到测试机上来,并且写到docker认证的目录下（/etc/docker/certs.d/） 12mkdir -p /etc/docker/certs.d/myregistrydomain.com:5000 建一个文件夹cp /certs/domain.crt /etc/docker/certs.d/myregistrydomain.com:5000 然后将证书放到这个目录下（假设证书已经从私服库上拷下来放到/certs/domain.crt中） 建议是重启一下docker 1systemctl restart docker 这会假如你测试机上跑了其他容器，那这些肯定都是挂了的，一个一个起有太麻烦，所以可以用下面的命令批量重启一下 1docker start $(docker ps -a | awk '&#123; print $1&#125;' | tail -n +2) 就可以测试登录了 1docker login myregistrydomain.com:5000 不出意外输入账号密码，会提示登录成功。good luck","categories":[{"name":"docker","slug":"docker","permalink":"http://www.icepear.cn/categories/docker/"}],"tags":[{"name":"持续集成","slug":"持续集成","permalink":"http://www.icepear.cn/tags/持续集成/"},{"name":"docker","slug":"docker","permalink":"http://www.icepear.cn/tags/docker/"}]},{"title":"linux 防火墙配置","slug":"other/firewalld","date":"2017-03-21T10:30:02.000Z","updated":"2017-10-17T09:45:41.723Z","comments":true,"path":"2017/03/21/other/firewalld/","link":"","permalink":"http://www.icepear.cn/2017/03/21/other/firewalld/","excerpt":"目前大多情况都使用CentOs7，但Centos升级到7之后，内置的防火墙已经从iptables变成了firewalld。所以两个都记录一下。","text":"目前大多情况都使用CentOs7，但Centos升级到7之后，内置的防火墙已经从iptables变成了firewalld。所以两个都记录一下。 linux 防火墙配置firewalldCentos7默认安装了firewalld，如果没有安装的话，可以使用 yum install firewalld firewalld-config进行安装。 常用命令123456789101112启动防火墙 systemctl start firewalld 禁用防火墙 systemctl stop firewalld设置开机启动 systemctl enable firewalld停止并禁用开机启动 sytemctl disable firewalld重启防火墙 firewall-cmd --reload查看状态 systemctl status firewalld 或者 firewall-cmd --state 其他命令1234567891011121314151617181920212223查看版本 firewall-cmd --version查看帮助 firewall-cmd --help查看区域信息 firewall-cmd --get-active-zones查看指定接口所属区域信息 firewall-cmd --get-zone-of-interface=eth0拒绝所有包 firewall-cmd --panic-on取消拒绝状态 firewall-cmd --panic-off查看是否拒绝 firewall-cmd --query-panic将接口添加到区域(默认接口都在public) firewall-cmd --zone=public --add-interface=eth0(永久生效再加上 --permanent 然后reload防火墙)设置默认接口区域 firewall-cmd --set-default-zone=public(立即生效，无需重启)更新防火墙规则 firewall-cmd --reload 无需断开连接 或firewall-cmd --complete-reload 需要断开连接，类似重启服务 打开端口12345查看指定区域所有打开的端口 firewall-cmd --zone=public --list-ports在指定区域打开端口 firewall-cmd --zone=public --add-port=80/tcp --permanent 需要重启防火墙 说明：–zone 作用域–add-port=8080/tcp 添加端口，格式为：端口/通讯协议–permanent #永久生效，没有此参数重启后失效 iptables常用命令123456789开启防火墙(即时生效，重启后失效)：service iptables start关闭防火墙(即时生效，重启后失效)：service iptables stop开启防火墙(重启后永久生效)：chkconfig iptables on关闭防火墙(重启后永久生效)：chkconfig iptables off重启防火墙:service iptables restartd 打开、查看端口1/etc/init.d/iptables status 打开某个端口(以8080为例)12345iptables -A INPUT -p tcp --dport 8080 -j ACCEPT 打开/etc/rc.d/init.d/iptables save 保存/etc/init.d/iptables restart 重启 其他方式可以通过修改/etc/sysconfig/iptables文件的方式开启端口，运行1vi /etc/sysconfig/iptables 增加一行1-A RH-Firewall-1-INPUT -m state –state NEW -m tcp -p tcp –dport 8080 -j ACCEPT 参数说明: –A 参数就看成是添加一条规则–p 指定是什么协议，我们常用的tcp 协议，当然也有udp，例如53端口的DNS–dport 就是目标端口，当数据从外部进入服务器为目标端口–sport 数据从服务器出去，则为数据源端口使用–j 就是指定是 ACCEPT -接收 或者 DROP 不接收","categories":[{"name":"other","slug":"other","permalink":"http://www.icepear.cn/categories/other/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://www.icepear.cn/tags/linux/"},{"name":"防火墙","slug":"防火墙","permalink":"http://www.icepear.cn/tags/防火墙/"}]},{"title":"单例模式（Singleton pattern）","slug":"designpattern/singleton","date":"2017-03-15T10:30:00.000Z","updated":"2018-03-27T01:33:49.815Z","comments":true,"path":"2017/03/15/designpattern/singleton/","link":"","permalink":"http://www.icepear.cn/2017/03/15/designpattern/singleton/","excerpt":"单例模式（Singleton Pattern）是 Java 中最简单的设计模式之一。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。单例类负责创建自己的对象，同时确保只有单个对象被创建。这个类提供了一种访问其唯一的对象的方式，可以直接访问，不需要实例化该类的对象。","text":"单例模式（Singleton Pattern）是 Java 中最简单的设计模式之一。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。单例类负责创建自己的对象，同时确保只有单个对象被创建。这个类提供了一种访问其唯一的对象的方式，可以直接访问，不需要实例化该类的对象。 简介单例模式是常用的设计模式之一，在spring中也大量采用到，单例模式一般分为饿汉式和饱汉式这两种实现，但除了这两种其实还可以细分到线程安全领域，所以也就还会有线程安全的实现方式 基本定律 私有的静态实例变量 私有的构造方法 公共的获取实例的方法满足这三个条件，基本就可以写出单例了。下面详细分析几种写法 单例模式的写法饿汉式，最常见实现（可用）这种写法比较简单，而且一般来讲也是线程安全的，因为在类装载的时候就完成了实例化，避免同步问题 1234567public class Singleton&#123; private final static Singleton instance = new Singleton(); private Singleton(); public Singleton getInstance()&#123; return instance; &#125;&#125; 饿汉式，静态代码块（可用）和上面基本类似，只是把实例化的过程抽离到了静态代码块中 12345678910public class Singleton&#123; private static Singleton instance; static&#123; instance = new Singleton(); &#125; private Singleton(); public Singleton getInstance()&#123; return instance; &#125;&#125; 饿汉式，静态内部类，推荐这种方式跟上两种虽然都采用类加载机制来保证实例化时只有一个线程，但是上两种的做法是只要类被加载就会被实例化，假如这个类没有被用到，就会浪费内存。这种方式的好处就是起到了懒加载的效果，静态内部类在singleton类被加载时并不会立即实例化，而是在需要时实例化，调用getInstance才会去装载内部类 123456789101112public class Singleton&#123; private Singleton(); private static class SingletonInstance&#123; private static final Singleton instance = new Singleton(); &#125; public static Singleton getInstance()&#123; return SingletonInstance.instance; &#125;&#125; 饱汉式，线程不安全（不可用）谈完饿汉再谈饱汉，饱汉一般的写法是，getInstance的时候我在实例化，当多个线程同时调用getInstance就会导致线程不安全12345678910111213public class Singleton &#123; private static Singleton instance; private Singleton() &#123;&#125; public static Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125;&#125; 饱汉式，线程安全（可用，但效率低）那怎么可以达到线程安全呢，实现也很简单，不就是getInstance会导致同步问题嘛，那就加一个同步方法，但是也不太推荐这种做法，毕竟每次都要同步效率是很低的12345678910111213public class Singleton &#123; private static Singleton instance; private Singleton() &#123;&#125; public static synchronized Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125;&#125; 饱汉式，线程安全升级（不可用）那同步效率低该怎么改进呢，于是想到就是静态代码块咯，效率会高一点吧123456789101112131415public class Singleton &#123; private static Singleton instance; private Singleton() &#123;&#125; public static Singleton getInstance() &#123; if (instance == null) &#123; synchronized (Singleton.class) &#123; instance = new Singleton(); &#125; &#125; return instance; &#125;&#125; 这样就没问题了吗？仔细想想，假如在判断if (instance == null)时，另外一个线程也放好判断完了，两个线程还是会同时实例化 饱汉式，双重检查，线程安全，推荐这时双重检测是最完美不过的了，首先保证实例的原子性，然后双重判断，这样就不会出现实例化多个的情况了1234567891011121314151617public class Singleton &#123; //volatile 保证变量的原子性，都是从主线程内存中读取 private static volatile Singleton instance; private Singleton() &#123;&#125; public static Singleton getInstance() &#123; if (instance == null) &#123; synchronized (Singleton.class) &#123; if (instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; 枚举，推荐jdk1.5 引入枚举后，使用枚举来实现单例模式。不仅能避免多线程同步问题，而且还能防止反序列化重新创建新的对象。123456public enum Singleton &#123; INSTANCE; public void whateverMethod() &#123; &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.icepear.cn/categories/设计模式/"}],"tags":[{"name":"单例模式","slug":"单例模式","permalink":"http://www.icepear.cn/tags/单例模式/"}]},{"title":"工厂模式（Factory Method）","slug":"designpattern/Factory","date":"2017-03-11T08:30:00.000Z","updated":"2017-10-16T08:57:22.038Z","comments":true,"path":"2017/03/11/designpattern/Factory/","link":"","permalink":"http://www.icepear.cn/2017/03/11/designpattern/Factory/","excerpt":"工厂模式是设计模式中比较基础也是比较常见的模式，一般用在创建对象上，所以属于创建型模式。工厂模式也分三种:简单工厂模式、工厂模式、抽象工厂模式。下面会对每个模式从解释、UML、代码进行详细说明","text":"工厂模式是设计模式中比较基础也是比较常见的模式，一般用在创建对象上，所以属于创建型模式。工厂模式也分三种:简单工厂模式、工厂模式、抽象工厂模式。下面会对每个模式从解释、UML、代码进行详细说明 工厂模式简单工厂模式解释简单工厂模式主要的意图就是抽象化实体类，让子类去决定实例化。在小米加步枪时代，你需要一辆马车，你需要自己去创造。而在飞机大炮时代，你需要一辆汽车，你就会找工厂造一台，如果需求再变通一点，甲需要宝马，乙需要奥迪。所以造车的工厂就要能造两种车，而简单工厂模式就符合这种需求。这个优点就是调用者创建对象只需通过工厂创建，扩展性高 UML图 示例代码Car接口基类123public interface Car&#123; void run();&#125; BMW类123456public class BMW implements Car&#123; @Override public void run() &#123; System.out.println(\"BMW is run!\"); &#125; &#125; AUTO类123456public class AUTO implements Car&#123; @Override public void run() &#123; System.out.println(\"AUTO is run!\"); &#125; &#125; 工厂类12345678910public class CarFactory&#123; public static BMW CreateBMW() &#123; return new BMW(); &#125; public static AUTO CreateAUTO() &#123; return new AUTO(); &#125;&#125; 具体调用123456789public class Test&#123; public static void main(String []args)&#123; BMW bmw = CarFactory.CreateBMW(); bmw.run(); AUTO auto = CarFactory.CreateAUTO(); auto.run(); &#125;&#125; 工厂模式解释工厂模式显然是对简单工厂模式的一种改进或者说是完善，遵循开闭原则。一个抽象工厂类派生出多个具体工厂类，具体工厂类只能生产对应的具体产品在现实需求中，宝马工厂和奥迪工厂肯定是不同的工厂，所以对工厂也进行抽象,这样就方便扩展了，当又来一种汽车时，只需要另外开辟一个工厂，而不要对原来工厂进行修改。 UML 示例代码Car接口基类123public interface Car&#123; void run();&#125; BMW类123456public class BMW implements Car&#123; @Override public void run() &#123; System.out.println(\"BMW is run!\"); &#125; &#125; AUTO类123456public class AUTO implements Car&#123; @Override public void run() &#123; System.out.println(\"AUTO is run!\"); &#125; &#125; 工厂抽象接口1234public interface CarFactory&lt;T&gt;&#123; T Create();&#125; BMW工厂类123456public class BMWFactory implements CarFactor&lt;BMW&gt;&#123; public BMW create() &#123; return new BMW(); &#125;&#125; AUTO工厂类12345public interface AUTOFactory implements CarFactor&lt;AUTO&gt;&#123; public AUTO create() &#123; return new AUTO(); &#125;&#125; 具体调用12345678public class Test&#123; public static void main(String []args)&#123; AUTOFactory autoFactory = new AUTOFactory(); AUTO auto = autoFactory.create(); auto.run(); &#125;&#125; 抽象工厂模式解释抽象工厂模式跟工厂模式最大的区别可能就是把产品再进行抽象，也就是一个抽象工厂类派生出多个具体工厂类，而具体工厂类可以生产出多个具体产品因为在现实生活中，很多产品都是一系列的，一个产品族。还按照上面的汽车的案例分析，现实生活中，你需要一台宝马，不可能说就是一种类型宝马，那宝马公司就去玩蛋蛋了，用户可能根据排量、汽车空间、稳定性、安全性各方面进行选择。所以宝马公司必须推出各个型号的子产品，例如3系和5系两款车，3系里面又包含1.5L排量的和2.0L排量的，5系同理。在实现这个需求上，我们就要对产品进行抽象，然后具体工厂写出对应的生产策略。 UML 示例代码3系BMW抽象类123456789public abstract class BMW320i&#123; //排量 private float displacement; public BMW320i(float displacement)&#123; this.displacement = displacement; &#125; public abstract void run(); //省略GET、SET&#125; 5系BMW抽象类123456789public abstract class BMW532i&#123; //排量 private float displacement; public BMW532i(float displacement)&#123; this.displacement = displacement; &#125; public abstract void run(); //省略GET、SET&#125; 1.5L的BMW3系类12345678public class BMW320i150 extends BMW320i&#123; public BMW320i150(float displacement)&#123; super(displacement); &#125; public void run() &#123; System.out.printf(\"this is a\"+this.getDisplacement()+\"L 320i\"); &#125;&#125; 2.0L的BMW3系类12345678public class BMW320i200 extends BMW320i&#123; public BMW320i200(float displacement)&#123; super(displacement); &#125; public void run() &#123; System.out.printf(\"this is a\"+this.getDisplacement()+\"L 320i\"); &#125;&#125; 1.5L的BMW5系类12345678public class BMW532i150 extends BMW532i&#123; public BMW532i150(float displacement)&#123; super(displacement); &#125; public void run() &#123; System.out.printf(\"this is a\"+this.getDisplacement()+\"L 532i\"); &#125;&#125; 2.0L的BMW5系类12345678public class BMW532i200 extends BMW532i&#123; public BMW532i200(float displacement)&#123; super(displacement); &#125; public void run() &#123; System.out.printf(\"this is a\"+this.getDisplacement()+\"L 532i\"); &#125;&#125; 工厂抽象接口1234public interface AbstractFactory &#123; public BMW320i createBMW320i(); public BMW532i createBMW532i();&#125; 1.5L抽象工厂类12345678910public class BMW150Factory implements AbstractFactory&#123; public BMW320i createBMW320i() &#123; return new BMW320i150(1.5f); &#125; public BMW532i createBMW532i() &#123; return new BMW532i150(1.5f); &#125;&#125; 2.0L抽象工厂类123456789public class BMW200Factory implements AbstractFactory &#123; public BMW320i createBMW320i() &#123; return new BMW320i200(2.0f); &#125; public BMW532i createBMW532i() &#123; return new BMW532i200(2.0f); &#125;&#125; 具体调用123456789101112131415public class test &#123; public static void main(String []args)&#123; BMW150Factory bmw150Factory = new BMW150Factory(); BMW200Factory bmw200Factory = new BMW200Factory(); BMW320i Bmw320i200 = bmw200Factory.createBMW320i(); BMW532i Bmw532i150 = bmw150Factory.createBMW532i(); Bmw320i200.run(); Bmw532i150.run(); /**结果：this is a 2.0L 320i * this is a 1.5L 532i */ &#125;&#125; 总结其实不管是工厂模式还是抽象工厂模式，其目的是一致的，就是利用抽象进行解耦，也没有必要说一定要在乎用工厂还是抽象工厂，完全要根据现实需求来确定方案。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.icepear.cn/categories/设计模式/"}],"tags":[{"name":"工厂模式","slug":"工厂模式","permalink":"http://www.icepear.cn/tags/工厂模式/"}]},{"title":"设计模式（Design Pattern）","slug":"designpattern/DesignPattern","date":"2017-03-10T07:30:02.000Z","updated":"2017-10-16T08:57:18.742Z","comments":true,"path":"2017/03/10/designpattern/DesignPattern/","link":"","permalink":"http://www.icepear.cn/2017/03/10/designpattern/DesignPattern/","excerpt":"设计模式是前人通过不断实践总结出来的经验。在日常编码也时有用到，更多的体现是在各大框架设计里面。之前自己学习过，但没有通过自己总结出来，接下来，我将系统的总结设计模式，加深自己对设计模式的理解","text":"设计模式是前人通过不断实践总结出来的经验。在日常编码也时有用到，更多的体现是在各大框架设计里面。之前自己学习过，但没有通过自己总结出来，接下来，我将系统的总结设计模式，加深自己对设计模式的理解 设计模式分类一、创建型模式：1.工厂模式 2.抽象工厂模式 3.单例模式 4.建造者模式 5.原型模式 二、结构型模式1.适配器模式 2.桥接模式 3.过滤器模式 4.代理模式 5.组合模式 6.装饰器模式 7.外观模式 8.享元模式 三、行为型模式1.责任链模式 2.命令模式 3.解释器模式 4.迭代器模式 5.备忘录模式 6.中介者模式 7.观察者模式 8.状态模式 9.空对象模式 10.策略模式 11.模板方法模式 12.访问者模式 六大原则一、单一职责原则每个类的职责应该是单一的，不能让一个类负责做个业务。比如说:一个类负责职责A和职责B，当职责A的需求变更时，需要修改职责A的代码，可能会导致职责B的代码出现问题为了避免出现这样的问题，所以要一个类对应一个职责 二、开闭原则对扩展开放，对修改关闭比如说:一个创建水果的类，本来可以创建香蕉、西瓜两个水果。如果这个类要新加创建芒果的方法，就得对这个类进行修改，如果再加其他水果，又得对该类进行方法的新增。所以可以对香蕉、西瓜等水果进行抽象，创建水果的类只提供创建方法，要新加芒果时，只需要扩展一个芒果类即可，不需要对创建水果类进行修改。开闭原则的关键就在于抽象二字 三、里氏代换原则任何基类出现的地方，其子类也可以出现，替代其使用不会是出现错误换种方式说就是，我喜欢狗，所以我一定喜欢动物；但我喜欢动物，我不一定喜欢狗。里氏代换原则其实是对开闭原则的补充也就是抽象的具体实现，而实现需要注意的也就是抽象时需要注意的情况: 1. 子类必须实现父类的抽象方法，不能实现非抽象方法 2. 子类可以增加自己的方法 四、依赖倒置原则抽象不应该依赖于细节，细节应当依赖于抽象。换言之，要针对接口编程，而不是针对实现编程 五、接口隔离原则使用多个专门的接口，而不使用单一的总接口比方说鸟和壁虎都属于动物，都实现动物接口，按理动物接口要包括飞行方法、爬行方法，但鸟类实现接口之后具有爬行方法、显然不合适。所以要拆分成，飞行动物接口和爬行动物接口。 六、迪米特原则(最少知道原则)一个软件实体应当尽可能少地与其他实体发生相互作用 迪米特法则要求我们在设计系统时，应该尽量减少对象之间的交互，如果两个对象之间不必彼此直接通信，那么这两个对象就不应当发生任何直接的相互作用，如果其中的一个对象需要调用另一个对象的某一个方法的话，可以通过第三者转发这个调用。简言之，就是通过引入一个合理的第三者来降低现有对象之间的耦合度。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.icepear.cn/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://www.icepear.cn/tags/设计模式/"}]},{"title":"SpringBoot学习-基本使用","slug":"springboot/SpringBoot1","date":"2016-12-09T11:30:02.000Z","updated":"2017-10-16T08:57:51.188Z","comments":true,"path":"2016/12/09/springboot/SpringBoot1/","link":"","permalink":"http://www.icepear.cn/2016/12/09/springboot/SpringBoot1/","excerpt":"在您第1次接触和学习Spring框架的时候，是否因为其繁杂的配置而退却了？在你第n次使用Spring框架的时候，是否觉得一堆反复黏贴的配置有一些厌烦？那么您就不妨来试试使用Spring Boot来让你更易上手，更简单快捷地构建Spring应用！Spring Boot让我们的Spring应用变的更轻量化。比如：你可以仅仅依靠一个Java类来运行一个Spring引用。你也可以打包你的应用为jar并通过使用java -jar来运行你的Spring Web应用。","text":"在您第1次接触和学习Spring框架的时候，是否因为其繁杂的配置而退却了？在你第n次使用Spring框架的时候，是否觉得一堆反复黏贴的配置有一些厌烦？那么您就不妨来试试使用Spring Boot来让你更易上手，更简单快捷地构建Spring应用！Spring Boot让我们的Spring应用变的更轻量化。比如：你可以仅仅依靠一个Java类来运行一个Spring引用。你也可以打包你的应用为jar并通过使用java -jar来运行你的Spring Web应用。 使用SpringBoot开始废话不多讲，为什么使用SpringBoot，就一个字：“爽”。快速入门，精简配置，开箱即用，独立运行这些优点绝对会让你爱上它，当然最重要的一点就是微服务 构建项目使用maven构建，一般继承 spring-boot-starter-parent 项目来获取合适的默认设置只需要简单地设置 parent 为：12345&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.4.0.RELEASE&lt;/version&gt;&lt;/parent&gt; 该父项目提供以下特性： 默认编译级别为Java 1.6 源码编码为UTF-8 一个依赖管理节点,允许你省略普通依赖的 标签,继承自 spring-boot-dependencies POM。 合适的资源过滤 合适的插件配置（ exec插件， surefire， Git commit ID， shade） 针对 application.properties 和 application.yml 的资源过滤改变属性可以使用 标签，例如123456&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;//项目编码格式 &lt;java.version&gt;1.8&lt;/java.version&gt;//改变java编译版本 &lt;docker.image.prefix&gt;willmin&lt;/docker.image.prefix&gt;//其他属性配置 &lt;docker.plugin.version&gt;0.4.12&lt;/docker.plugin.version&gt;&lt;/properties&gt; 打包插件让springboot应用独立运行，需要将应用导成可执行的jar，可以利用Spring Boot Maven插件，在中配置在pom中写入：12345678&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 依赖项目列表在pom中可以轻易引用springboot的各种依赖，所有的starters遵循一个相似的命名模式： spring-boot-starter-* 是一种特殊类型的应用程序，该命名结构旨在帮你找到需要的starter。表 13.1. Spring Boot application starters 名称 描述 spring-boot-starter 核心Spring Boot starter， 包括自动配置支持， 日志和YAML spring-boot-starter-actuator 生产准备的特性， 用于帮你监控和管理应用 spring-boot-starter-amqp 对”高级消息队列协议”的支持， 通过 spring-rabbit 实现 spring-boot-starter-aop 对面向切面编程的支持， 包括 spring-aop 和AspectJ spring-boot-starter-test 对常用测试依赖的支持， 包括JUnit, Hamcrest和Mockito， 还有 spring-test 模块 spring-boot-starter-web 对全栈web开发的支持， 包括Tomcat和 spring-webmvc spring-boot-starter-websocket 对WebSocket开发的支持 spring-boot-starter-mail 对 javax.mail 的支持 spring-boot-starter-mobile 对 spring-mobile 的支持 spring-boot-starter-mustache 对Mustache模板引擎的支持 spring-boot-starter-redis 对REDIS键值数据存储的支持， 包括 spring-redis spring-boot-starter-security 对 spring-security 的支持 spring-boot-starter-jdbc 对JDBC数据库的支持 spring-boot-starter-data-jpa 对”Java持久化API”的支持， 包括 spring-data-jpa ， spring-orm 和Hibernate spring-boot-starter-data-rest 对通过REST暴露Spring Data仓库的支持， 通过 spring-data-rest-webmvc 实现 spring-boot-starter-thymeleaf 对Thymeleaf模板引擎的支持， 包括和Spring的集成 spring-boot-starter-velocity 对Velocity模板引擎的支持 spring-boot-starter-batch 对Spring Batch的支持， 包括HSQLDB数据库 spring-boot-starter-cloudconnectors 对Spring Cloud Connectors的支持， 简化在云平台下(例如，Cloud Foundry和Heroku)服务的连接 spring-boot-starter-dataelasticsearch 对Elasticsearch搜索和分析引擎的支持， 包括 spring-data-elasticsearch spring-boot-starter-datagemfire 对GemFire分布式数据存储的支持， 包括 spring-data-gemfire spring-boot-starter-datamongodb 对MongoDB NOSQL数据库的支持， 包括 spring-data-mongodb spring-boot-starter-data-solr 对Apache Solr搜索平台的支持， 包括 spring-data-solr spring-boot-starter-freemarker 对FreeMarker模板引擎的支持 spring-boot-starter-groovytemplates 对Groovy模板引擎的支持 spring-boot-starter-hateoas 对基于HATEOAS的RESTful服务的支持， 通过 spring-hateoas 实现 spring-boot-starter-hornetq 对”Java消息服务API”的支持， 通过HornetQ实现 spring-boot-starter-integration 对普通 spring-integration 模块的支持 spring-boot-starter-jersey 对Jersey RESTful Web服务框架的支持 spring-boot-starter-jtaatomikos 对JTA分布式事务的支持， 通过Atomikos实现 spring-boot-starter-jta-bitronix 对JTA分布式事务的支持， 通过Bitronix实现 spring-boot-starter-socialfacebook 对 spring-social-facebook 的支持 spring-boot-starter-sociallinkedin 对 spring-social-linkedin 的支持 spring-boot-starter-socialtwitter 对 spring-social-twitter 的支持 spring-boot-starter-ws 对Spring Web服务的支持 spring-boot-starter-jetty 导入Jetty HTTP引擎（ 作为Tomcat的替代） spring-boot-starter-log4j 对Log4J日志系统的支持 spring-boot-starter-logging 导入Spring Boot的默认日志系统（ Logback） spring-boot-starter-tomcat 导入Spring Boot的默认HTTP引擎（ Tomcat） 代码结构springboot应用并不要求任何特殊的代码结构，我一般是这么写的 1234567891011121314151617|-main |-java/com/icepear/项目名 |-web |-Controller |-service |-impl |-实现 |-接口 |-domain |-enums |-interfaces |-Repository.java |-实体.java |-docker |-Dockerfile |-resources |-application.yml","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://www.icepear.cn/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://www.icepear.cn/tags/SpringBoot/"}]},{"title":"Markdown学习","slug":"other/Markdown","date":"2016-12-08T07:30:02.000Z","updated":"2018-07-18T04:39:00.963Z","comments":true,"path":"2016/12/08/other/Markdown/","link":"","permalink":"http://www.icepear.cn/2016/12/08/other/Markdown/","excerpt":"Markdown 是一种轻量级的「标记语言」，它的优点很多，目前也被越来越多的写作爱好者，撰稿者广泛使用。看到这里请不要被「标记」、「语言」所迷惑，Markdown 的语法十分简单。常用的标记符号也不超过十个，这种相对于更为复杂的HTML 标记语言来说，Markdown 可谓是十分轻量的，学习成本也不需要太多，且一旦熟悉这种语法规则，会有一劳永逸的效果。","text":"Markdown 是一种轻量级的「标记语言」，它的优点很多，目前也被越来越多的写作爱好者，撰稿者广泛使用。看到这里请不要被「标记」、「语言」所迷惑，Markdown 的语法十分简单。常用的标记符号也不超过十个，这种相对于更为复杂的HTML 标记语言来说，Markdown 可谓是十分轻量的，学习成本也不需要太多，且一旦熟悉这种语法规则，会有一劳永逸的效果。 Markdown学习标题 #表示一级标题，##表示二级标题，多级标题依次累积 列表1.有序列表在文本前加入数字1.,2.,3.即可 1. 列表1 2. 列表2 2. 列表3 2.无序列表在文本前加入- - 列表1 - 列表2 - 列表3 注：-,1.和文本之间要保留一个字符的空格。 换行与缩进换行使用&lt;/br&gt;或者使用空行表示换行。缩进使用半方大的空白&amp;ensp;或&amp;#8194;也可以用全方大的空白&amp;emsp;或&amp;#8195;例如： &amp;ensp;你好&lt;/br&gt;&amp;emsp;世界 显示：&ensp;你好&emsp;世界 链接格式为:[文本](链接),例如 [google链接](https://www.google.com) 显示如：google链接 图片格式为：![](图片链接),例如 ![](http://g3.ykimg.com/0130391F4555C2DEFE9F592DF60A8431D4D237-366F-F0C2-ED67-4475501D05FC) 显示为： 分割线使用 * 三个星 * * * - - - 三个带空格的中划线 ___ 连续三个下划线 __________ 多个下划线 &lt;/pre&gt; 区块引用使用&gt;,例如 &gt; 你好&lt;/br&gt; &gt; 世界&lt;/br&gt; &gt; I`m coder 显示： 你好世界I`m coder 代码区块单句代码可以使用’ ` &#39;(也就是键盘~这个按钮)&lt;/br&gt; 区块使用标签和`嵌套，例如： `你好` &lt;pre&gt;&lt;code&gt;这是一个代码区块。&lt;/code&gt;&lt;/pre&gt; 显示如： 你好 这是一个代码区块。 粗体和斜体粗体的格式为**文本**，斜体的格式为*文本*例如: **你好**&lt;/br&gt; *世界* 显示:你好世界 表格格式如下: | dog | bird | cat | | - | - | - | | foo | foo | foo | | bar | bar | bar | | baz | baz | baz | 显示如下 dog bird cat foo foo foo bar bar bar baz baz baz 格式如下: | dog | bird | cat | | - | :-: | -: | | foo | foo | foo | | bar | bar | bar | | baz | baz | baz | 显示如下 dog bird cat foo foo foo bar bar bar baz baz baz","categories":[{"name":"other","slug":"other","permalink":"http://www.icepear.cn/categories/other/"}],"tags":[{"name":"Markdown","slug":"Markdown","permalink":"http://www.icepear.cn/tags/Markdown/"}]}]}